{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2927e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n",
      "     |████████████████████████████████| 60.3 MB 53.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /home/myranda/miniconda3/lib/python3.7/site-packages (from opencv-python) (1.20.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.4.60\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766c125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMR Model \n",
    "# Goal: recognize images of music excerpts\n",
    "\n",
    "# Modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "class cnn_model(torch.nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(cnn_model, self).__init__()\n",
    "\n",
    "        kernel_size = [3,3]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size = kernel_size)\n",
    "        self.batch1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16,32, kernel_size = kernel_size)\n",
    "        self.batch2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size = kernel_size)\n",
    "        self.batch3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.act = nn.LeakyReLU()\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # FORWARD PASS\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        output = x\n",
    "\n",
    "        return x\n",
    "\n",
    "class rnn_model(torch.nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size):\n",
    "        super(rnn_model, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        #self.rnn = nn.LSTMCell(input_size = embed_size, hidden_size = hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size + 1)\n",
    "\n",
    "    def forward(self,x, input_size):\n",
    "\n",
    "        #h0 = torch.zeros(16, x.size(0), self.hidden_size).to(device)\n",
    "        #c0 = torch.zeros(16, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        h0 = torch.zeros(16,self.hidden_size,self.hidden_size)#.to(device)\n",
    "        c0 = torch.zeros(16, self.hidden_size,self.hidden_size)#.to(device)\n",
    "        \n",
    "        self.rnn = nn.LSTMCell(input_size = input_size, hidden_size = self.hidden_size)\n",
    "        out, _ = self.rnn(x, (h0, c0))\n",
    "\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2dde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super(BasicRNN, self).__init__()\n",
    "        \n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n",
    "        \n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        #X = X.permute(1, 0, 2) \n",
    "        \n",
    "        self.batch_size = X.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        # lstm_out => n_steps, batch_size, n_neurons (hidden states for each time step)\n",
    "        # self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\n",
    "        #lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
    "        out, self.hidden = nn.basic_rnn(n_inputs, n_neurons)\n",
    "        out = self.FC(self.hidden)\n",
    "        \n",
    "        return out#.view(-1, self.n_outputs) # batch_size X n_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a25c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctc_utils\n",
    "from primus import CTC_PriMuS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4608fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 70880 and validating with 7875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['000136122-1_2_1',\n",
       " '230003636-1_21_2',\n",
       " '000123529-1_1_2',\n",
       " '000118332-1_1_2',\n",
       " '000135764-1_1_1',\n",
       " '000110955-1_1_1',\n",
       " '190014525-1_1_1',\n",
       " '210000218-1_2_1',\n",
       " '000122545-1_1_2',\n",
       " '000106165-1_1_1',\n",
       " '000115764-1_1_1',\n",
       " '190101947-1_1_1',\n",
       " '000115976-11_1_1',\n",
       " '220014638-1_1_2',\n",
       " '000102615-1_1_2',\n",
       " '211005421-1_4_1',\n",
       " '000127845-1_2_1',\n",
       " '190015388-1_1_1',\n",
       " '200185762-1_1_1',\n",
       " '000120336-1_1_1',\n",
       " '190018598-1_1_1',\n",
       " '211004611-1_5_1',\n",
       " '000102431-1_1_1',\n",
       " '000136986-1_1_1',\n",
       " '000105383-1_1_1',\n",
       " '000140766-1_2_1',\n",
       " '000126811-1_1_1',\n",
       " '212003679-1_1_1',\n",
       " '211007011-1_12_1',\n",
       " '230001487-1_1_1',\n",
       " '110002343-1_2_1',\n",
       " '190003571-1_1_1',\n",
       " '100016392-1_1_1',\n",
       " '000100153-1_2_1',\n",
       " '230005816-1_1_1',\n",
       " '000104575-1_2_1',\n",
       " '180000107-1_8_1',\n",
       " '210097285-1_26_1',\n",
       " '211004455-1_2_1',\n",
       " '000114468-1_1_2',\n",
       " '190001219-1_1_1',\n",
       " '190001990-1_1_1',\n",
       " '000124874-1_1_1',\n",
       " '201004334-1_21_1',\n",
       " '000142431-1_1_1',\n",
       " '225001058-1_55_1',\n",
       " '190012417-1_1_1',\n",
       " '230002835-1_3_1',\n",
       " '220000595-1_1_1',\n",
       " '000136800-1_4_1',\n",
       " '000051662-1_1_1',\n",
       " '000116158-1_1_1',\n",
       " '000120935-1_1_2',\n",
       " '000127809-1_2_1',\n",
       " '225000829-1_23_2',\n",
       " '000131190-1_1_1',\n",
       " '230005208-1_2_1',\n",
       " '212001543-1_3_1',\n",
       " '100016327-1_1_1',\n",
       " '000104987-19_1_1',\n",
       " '000102330-1_1_2',\n",
       " '000101994-1_1_1',\n",
       " '000111843-1_2_1',\n",
       " '000115614-1_1_1',\n",
       " '212001050-1_1_1',\n",
       " '201008608-1_5_2',\n",
       " '190019046-1_1_1',\n",
       " '230000718-1_1_1',\n",
       " '000124601-1_2_1',\n",
       " '000111331-1_1_1',\n",
       " '225002232-1_1_1',\n",
       " '220014106-1_1_1',\n",
       " '150205702-1_2_1',\n",
       " '110001855-1_1_1',\n",
       " '110002697-1_2_2',\n",
       " '211006097-1_1_1',\n",
       " '000102096-1_1_1',\n",
       " '220017104-1_1_1',\n",
       " '211003879-1_22_1',\n",
       " '000103410-1_2_2',\n",
       " '000137463-1_3_1',\n",
       " '000102481-1_1_1',\n",
       " '000130473-1_1_1',\n",
       " '200043755-1_53_1',\n",
       " '100017379-1_1_1',\n",
       " '000107214-1_1_1',\n",
       " '190026386-1_1_1',\n",
       " '000119669-1_1_1',\n",
       " '000127773-1_1_1',\n",
       " '000105907-1_1_1',\n",
       " '000103460-1_2_2',\n",
       " '201004189-1_1_1',\n",
       " '000125491-1_1_1',\n",
       " '230001309-1_5_2',\n",
       " '000107486-1_1_1',\n",
       " '190007701-1_1_1',\n",
       " '220034706-1_1_1',\n",
       " '220015070-1_2_1',\n",
       " '000117750-1_1_1',\n",
       " '225000050-1_3_1',\n",
       " '200044669-1_19_1',\n",
       " '000104220-1_1_1',\n",
       " '000107881-1_1_1',\n",
       " '211006338-1_1_1',\n",
       " '000119214-1_1_1',\n",
       " '000108632-1_1_2',\n",
       " '210044722-1_2_1',\n",
       " '000106270-1_1_1',\n",
       " '000112047-1_1_1',\n",
       " '000122931-1_1_2',\n",
       " '000132574-1_2_2',\n",
       " '000128936-1_1_1',\n",
       " '230001424-1_6_1',\n",
       " '000100812-1_1_1',\n",
       " '000103302-1_1_1',\n",
       " '201001431-1_1_1',\n",
       " '230005554-1_7_1',\n",
       " '000113715-1_1_2',\n",
       " '100030926-1_1_1',\n",
       " '000115683-6_1_1',\n",
       " '000112614-1_1_1',\n",
       " '000122239-1_1_1',\n",
       " '210000067-1_5_1',\n",
       " '220034816-1_1_1',\n",
       " '000117199-1_1_1',\n",
       " '225000411-1_1_1',\n",
       " '000135549-1_1_1',\n",
       " '000107769-1_1_1',\n",
       " '000125475-1_1_1',\n",
       " '000125341-1_1_1',\n",
       " '000110513-1_1_1',\n",
       " '220010733-1_1_1',\n",
       " '000116941-1_1_1',\n",
       " '000125066-1_1_1',\n",
       " '230006481-1_1_1',\n",
       " '201001483-1_1_1',\n",
       " '220034192-1_3_1',\n",
       " '201009332-1_37_2',\n",
       " '100016196-1_1_1',\n",
       " '201009332-1_70_1',\n",
       " '000112549-1_1_1',\n",
       " '000127547-1_2_2',\n",
       " '000135922-1_2_1',\n",
       " '150200312-1_1_1',\n",
       " '230006110-1_1_1',\n",
       " '000131023-1_1_1',\n",
       " '201008785-1_1_2',\n",
       " '000100598-1_1_1',\n",
       " '230000877-1_1_1',\n",
       " '201009007-1_1_1',\n",
       " '110001766-1_1_2',\n",
       " '000124644-10_1_1',\n",
       " '150202195-1_1_1',\n",
       " '201002502-1_1_1',\n",
       " '100029464-1_1_1',\n",
       " '211005228-1_1_2',\n",
       " '000111669-1_1_1',\n",
       " '000125406-1_1_1',\n",
       " '230002310-1_2_1',\n",
       " '000109566-1_1_1',\n",
       " '000132254-1_1_1',\n",
       " '100500808-1_2_1',\n",
       " '220030339-1_1_1',\n",
       " '211010577-1_1_2',\n",
       " '220032277-1_14_1',\n",
       " '000110472-1_1_1',\n",
       " '000127624-1_1_1',\n",
       " '201005018-1_1_1',\n",
       " '225000296-1_1_3',\n",
       " '201009013-1_1_1',\n",
       " '100015729-1_1_1',\n",
       " '211004874-1_1_1',\n",
       " '100017230-1_1_1',\n",
       " '000126169-1_1_2',\n",
       " '190004733-1_1_1',\n",
       " '211002631-1_1_1',\n",
       " '000122002-1_1_1',\n",
       " '000106073-1_2_1',\n",
       " '000119764-1_1_1',\n",
       " '230004287-1_1_1',\n",
       " '000113453-1_1_1',\n",
       " '220016617-1_1_1',\n",
       " '000140881-5_1_1',\n",
       " '190024196-1_1_1',\n",
       " '220012142-1_1_1',\n",
       " '230003492-1_14_2',\n",
       " '000123478-1_1_1',\n",
       " '212002940-1_1_1',\n",
       " '230003723-1_1_2',\n",
       " '190025045-1_1_2',\n",
       " '201004767-1_24_2',\n",
       " '212003275-1_1_1',\n",
       " '000101316-1_1_1',\n",
       " '000117095-1_2_2',\n",
       " '220010518-1_2_2',\n",
       " '000105936-1_1_1',\n",
       " '000125916-1_1_2',\n",
       " '000109764-1_1_2',\n",
       " '000109670-1_1_1',\n",
       " '000102782-1_1_1',\n",
       " '201009309-1_27_2',\n",
       " '000113306-1_1_1',\n",
       " '000136394-1_1_1',\n",
       " '000112063-1_1_1',\n",
       " '201004006-1_2_2',\n",
       " '225001833-1_1_1',\n",
       " '000103473-1_1_2',\n",
       " '220016804-1_3_1',\n",
       " '201007038-1_19_1',\n",
       " '220016112-1_1_1',\n",
       " '212001401-1_4_1',\n",
       " '000110335-1_3_1',\n",
       " '190004211-1_1_1',\n",
       " '000105531-1_2_1',\n",
       " '230002494-1_2_1',\n",
       " '212001359-1_3_1',\n",
       " '190101844-1_1_1',\n",
       " '211004756-1_2_1',\n",
       " '000105392-1_1_1',\n",
       " '000111936-1_1_1',\n",
       " '211004918-1_2_1',\n",
       " '190005241-1_1_1',\n",
       " '000101321-1_1_1',\n",
       " '225003073-1_8_1',\n",
       " '150202492-1_1_1',\n",
       " '220030074-1_1_1',\n",
       " '212001433-1_2_1',\n",
       " '000121767-1_4_1',\n",
       " '225003344-1_1_1',\n",
       " '000117745-1_1_2',\n",
       " '110002958-1_15_1',\n",
       " '000105887-1_1_1',\n",
       " '230002636-1_1_1',\n",
       " '110001602-1_1_1',\n",
       " '150204614-1_1_1',\n",
       " '000123081-1_1_1',\n",
       " '000123096-1_1_1',\n",
       " '000108744-1_1_1',\n",
       " '200021901-1_26_1',\n",
       " '230001892-1_3_1',\n",
       " '000130361-1_1_1',\n",
       " '212003123-1_1_1',\n",
       " '000115452-1_1_1',\n",
       " '230004214-1_1_1',\n",
       " '230006391-1_1_1',\n",
       " '000119637-1_1_1',\n",
       " '000132426-1_1_1',\n",
       " '000110747-1_1_1',\n",
       " '000141729-1_1_1',\n",
       " '000131037-1_2_2',\n",
       " '000137748-1_1_1',\n",
       " '212001965-1_5_1',\n",
       " '201004211-1_7_1',\n",
       " '000128818-1_1_1',\n",
       " '000105895-1_1_1',\n",
       " '211008236-1_16_1',\n",
       " '000103410-1_1_1',\n",
       " '201002727-1_1_1',\n",
       " '000137346-1_1_2',\n",
       " '000117467-1_1_1',\n",
       " '211010728-1_1_2',\n",
       " '000139220-1_1_1',\n",
       " '000101774-1_1_1',\n",
       " '000100147-1_1_2',\n",
       " '230002833-1_19_2',\n",
       " '100030157-1_1_1',\n",
       " '100500687-1_4_1',\n",
       " '000103410-1_2_1',\n",
       " '211005526-1_2_1',\n",
       " '000138436-1_1_1',\n",
       " '000140778-1_1_1',\n",
       " '211008381-1_10_2',\n",
       " '211006571-1_1_1',\n",
       " '220011071-1_1_2',\n",
       " '212003384-1_1_1',\n",
       " '220030660-1_1_2',\n",
       " '000101226-1_1_2',\n",
       " '201004322-1_1_1',\n",
       " '230003748-1_5_2',\n",
       " '220011669-1_1_1',\n",
       " '000118335-1_1_1',\n",
       " '000137445-1_1_1',\n",
       " '000123511-1_1_1',\n",
       " '220015004-1_17_1',\n",
       " '230000245-1_7_1',\n",
       " '190027237-1_1_1',\n",
       " '225001215-1_1_1',\n",
       " '000138182-1_1_1',\n",
       " '190005011-1_1_1',\n",
       " '210000234-1_3_1',\n",
       " '201001374-1_1_1',\n",
       " '220017558-1_1_1',\n",
       " '100501038-1_1_1',\n",
       " '000105552-1_1_1',\n",
       " '212002506-1_2_1',\n",
       " '220032387-1_11_1',\n",
       " '000100861-1_1_1',\n",
       " '000132478-1_1_1',\n",
       " '100000009-1_1_1',\n",
       " '000114856-1_1_1',\n",
       " '000106217-1_1_1',\n",
       " '000104673-1_1_1',\n",
       " '201004145-1_1_1',\n",
       " '000118675-1_1_1',\n",
       " '000114515-1_1_1',\n",
       " '000114791-1_1_1',\n",
       " '000136807-1_2_1',\n",
       " '190004898-1_1_1',\n",
       " '211010131-1_45_2',\n",
       " '150204811-1_1_1',\n",
       " '220001000-1_1_2',\n",
       " '211010440-1_63_2',\n",
       " '220000459-1_2_1',\n",
       " '100030778-1_5_1',\n",
       " '000107215-1_1_1',\n",
       " '000104402-1_1_1',\n",
       " '211000618-1_1_1',\n",
       " '100030470-1_1_1',\n",
       " '000116992-1_1_1',\n",
       " '220019692-1_1_1',\n",
       " '100500254-1_1_1',\n",
       " '000119226-1_1_2',\n",
       " '000116784-1_1_1',\n",
       " '000116330-2_1_1',\n",
       " '201002433-1_7_1',\n",
       " '212002082-1_1_2',\n",
       " '000140694-1_1_1',\n",
       " '190004842-1_1_1',\n",
       " '220010603-1_1_1',\n",
       " '230003433-1_1_1',\n",
       " '000107616-1_1_1',\n",
       " '000106538-1_1_1',\n",
       " '000132079-1_1_2',\n",
       " '000107583-1_1_2',\n",
       " '000132965-1_1_1',\n",
       " '000123224-1_1_1',\n",
       " '225003080-1_9_1',\n",
       " '000107908-1_1_1',\n",
       " '190101275-1_1_1',\n",
       " '000113909-1_1_1',\n",
       " '230003137-1_1_1',\n",
       " '190002502-1_1_1',\n",
       " '201007643-1_1_1',\n",
       " '000108928-1_1_1',\n",
       " '100028709-1_9_1',\n",
       " '201002175-1_4_1',\n",
       " '000108065-1_1_2',\n",
       " '225003394-1_1_1',\n",
       " '220011114-1_1_1',\n",
       " '211001816-1_8_1',\n",
       " '000100609-1_1_1',\n",
       " '201002433-1_5_2',\n",
       " '230002040-1_1_2',\n",
       " '201004253-1_32_2',\n",
       " '100030746-1_3_1',\n",
       " '220018544-1_1_1',\n",
       " '000108004-1_1_1',\n",
       " '212002895-1_1_1',\n",
       " '000104648-1_1_1',\n",
       " '100030627-1_1_1',\n",
       " '230002997-1_1_2',\n",
       " '000112412-1_1_1',\n",
       " '211004896-1_6_2',\n",
       " '200043750-1_8_2',\n",
       " '220030796-1_1_1',\n",
       " '000136246-1_1_1',\n",
       " '000108162-1_1_1',\n",
       " '000116844-1_1_2',\n",
       " '210237501-1_5_1',\n",
       " '220034829-1_1_2',\n",
       " '211006342-1_1_2',\n",
       " '220034627-1_2_2',\n",
       " '110001439-1_1_1',\n",
       " '190002063-1_1_1',\n",
       " '200021222-1_1_1',\n",
       " '000124791-1_1_1',\n",
       " '230002245-1_5_1',\n",
       " '000111305-1_1_1',\n",
       " '190021519-1_1_1',\n",
       " '190010415-1_1_1',\n",
       " '150204398-1_1_1',\n",
       " '110002978-1_1_1',\n",
       " '000115811-1_1_1',\n",
       " '211001818-1_3_1',\n",
       " '000111883-1_1_1',\n",
       " '230000615-1_1_1',\n",
       " '000128361-1_1_1',\n",
       " '000111808-1_2_1',\n",
       " '190100372-1_1_1',\n",
       " '000119278-1_1_2',\n",
       " '000127226-1_1_1',\n",
       " '000132638-1_1_1',\n",
       " '211010253-1_1_1',\n",
       " '000124789-1_1_1',\n",
       " '000116669-9_1_1',\n",
       " '190014672-1_1_1',\n",
       " '150201885-1_2_1',\n",
       " '211003109-1_3_1',\n",
       " '220020152-1_1_1',\n",
       " '000140113-1_2_1',\n",
       " '000137006-1_2_1',\n",
       " '000116552-1_1_1',\n",
       " '220017318-1_18_2',\n",
       " '000120424-1_1_1',\n",
       " '000100261-1_1_1',\n",
       " '230003812-1_1_1',\n",
       " '100029295-1_1_1',\n",
       " '000135024-1_3_1',\n",
       " '000122154-1_2_2',\n",
       " '211003879-1_20_1',\n",
       " '000126727-1_1_1',\n",
       " '210021724-1_19_1',\n",
       " '000117140-1_1_2',\n",
       " '230002389-1_1_1',\n",
       " '230002929-1_3_1',\n",
       " '200021901-1_30_1',\n",
       " '212002579-1_1_1',\n",
       " '000115668-1_1_1',\n",
       " '000102805-1_1_1',\n",
       " '100500398-1_1_1',\n",
       " '000135416-1_1_1',\n",
       " '212003029-1_2_1',\n",
       " '000140112-1_1_1',\n",
       " '220018142-1_1_1',\n",
       " '212001351-1_4_1',\n",
       " '201002443-1_1_1',\n",
       " '220034047-1_6_1',\n",
       " '190005951-1_1_1',\n",
       " '190017890-1_1_1',\n",
       " '000136220-1_1_1',\n",
       " '000103368-1_1_1',\n",
       " '000130972-1_1_1',\n",
       " '212001394-1_3_1',\n",
       " '201005484-1_37_1',\n",
       " '000127309-1_1_1',\n",
       " '000128121-1_1_2',\n",
       " '000128977-1_1_1',\n",
       " '000138486-1_1_1',\n",
       " '000127866-1_1_2',\n",
       " '000109422-1_1_1',\n",
       " '230002759-1_4_2',\n",
       " '220016098-1_1_1',\n",
       " '000115415-1_1_1',\n",
       " '212003520-1_1_1',\n",
       " '000125576-1_1_1',\n",
       " '150205113-1_1_1',\n",
       " '000103281-1_1_2',\n",
       " '190016170-1_1_1',\n",
       " '000107640-1_3_1',\n",
       " '100015461-1_1_1',\n",
       " '150200686-1_1_1',\n",
       " '220001334-1_1_1',\n",
       " '000051757-1_1_1',\n",
       " '000136184-1_1_1',\n",
       " '000114012-1_1_1',\n",
       " '000110920-1_1_1',\n",
       " '000120998-1_1_1',\n",
       " '220034049-1_4_1',\n",
       " '000118345-1_1_1',\n",
       " '110000608-1_8_1',\n",
       " '000108528-1_1_1',\n",
       " '000118525-1_1_1',\n",
       " '201008026-1_1_2',\n",
       " '225003170-1_3_1',\n",
       " '212003235-1_3_1',\n",
       " '000135246-1_1_1',\n",
       " '220031222-1_1_1',\n",
       " '000112542-1_1_1',\n",
       " '230005710-1_1_1',\n",
       " '190004503-1_1_1',\n",
       " '000131146-1_1_1',\n",
       " '000118459-1_1_1',\n",
       " '211004301-1_27_2',\n",
       " '000110885-6_1_1',\n",
       " '230004460-1_1_1',\n",
       " '220010670-1_1_1',\n",
       " '000124613-1_1_1',\n",
       " '000104411-1_1_1',\n",
       " '211004298-1_1_1',\n",
       " '000122527-1_1_2',\n",
       " '000101131-1_1_1',\n",
       " '000135650-1_1_1',\n",
       " '000121720-1_1_1',\n",
       " '000131541-1_1_1',\n",
       " '000128237-1_1_1',\n",
       " '000138504-1_3_1',\n",
       " '000140223-1_1_1',\n",
       " '000112479-1_1_1',\n",
       " '000131776-1_1_1',\n",
       " '220020106-1_1_1',\n",
       " '000125755-2_1_1',\n",
       " '000118696-1_1_2',\n",
       " '000104055-1_1_1',\n",
       " '000100801-1_1_1',\n",
       " '000103961-1_2_1',\n",
       " '230002863-1_1_1',\n",
       " '190009608-1_1_1',\n",
       " '000140998-1_1_1',\n",
       " '201000288-1_1_1',\n",
       " '211002149-1_1_1',\n",
       " '220013494-1_1_2',\n",
       " '200043694-1_9_1',\n",
       " '000122759-1_1_2',\n",
       " '000110409-1_1_1',\n",
       " '190001545-1_1_1',\n",
       " '000106891-1_1_1',\n",
       " '201002407-1_2_1',\n",
       " '100015542-1_3_1',\n",
       " '201005394-1_1_1',\n",
       " '000117535-1_1_1',\n",
       " '000103319-1_1_1',\n",
       " '211001881-1_3_1',\n",
       " '000122913-1_1_1',\n",
       " '230002016-1_1_2',\n",
       " '201004906-1_1_1',\n",
       " '000108305-1_1_2',\n",
       " '000122953-1_1_1',\n",
       " '000100596-1_2_1',\n",
       " '000125702-1_1_1',\n",
       " '225001600-1_1_1',\n",
       " '180000116-1_1_1',\n",
       " '190013491-1_1_1',\n",
       " '000100352-1_1_1',\n",
       " '000125713-1_1_1',\n",
       " '000111839-1_1_2',\n",
       " '000136148-1_1_1',\n",
       " '000105327-1_1_1',\n",
       " '000120885-1_1_1',\n",
       " '211010368-1_8_2',\n",
       " '230001571-1_3_1',\n",
       " '000118643-1_1_1',\n",
       " '000123612-1_1_2',\n",
       " '212001289-1_1_1',\n",
       " '000130234-1_1_1',\n",
       " '000107600-1_1_2',\n",
       " '000104799-1_1_1',\n",
       " '201008384-1_1_1',\n",
       " '000109104-1_1_1',\n",
       " '000105164-1_1_1',\n",
       " '230003509-1_1_2',\n",
       " '212002921-1_7_1',\n",
       " '225002114-1_1_1',\n",
       " '000117086-1_1_1',\n",
       " '100030142-1_1_2',\n",
       " '150204085-1_1_1',\n",
       " '000107126-1_1_2',\n",
       " '000126138-1_1_1',\n",
       " '190002728-1_1_1',\n",
       " '000123441-1_1_1',\n",
       " '000109857-2_1_1',\n",
       " '000141655-1_1_2',\n",
       " '225000355-1_24_1',\n",
       " '000103167-1_1_1',\n",
       " '000108456-1_2_1',\n",
       " '190100007-1_1_1',\n",
       " '000104815-1_1_1',\n",
       " '220016091-1_1_1',\n",
       " '212003432-1_3_1',\n",
       " '100501104-1_1_2',\n",
       " '220016559-1_12_1',\n",
       " '000110187-1_1_1',\n",
       " '220018648-1_1_1',\n",
       " '000127272-1_1_2',\n",
       " '150204808-1_1_1',\n",
       " '212001983-1_2_1',\n",
       " '000110995-1_1_2',\n",
       " '230000099-1_10_1',\n",
       " '000139142-1_1_1',\n",
       " '000135119-11_1_1',\n",
       " '220015376-1_1_1',\n",
       " '230004816-1_1_1',\n",
       " '000101619-1_1_1',\n",
       " '000109889-1_2_1',\n",
       " '230003658-1_1_1',\n",
       " '000121768-1_2_1',\n",
       " '201008214-1_1_1',\n",
       " '110002396-1_1_1',\n",
       " '000113346-1_1_1',\n",
       " '000102524-1_1_2',\n",
       " '000102092-1_1_2',\n",
       " '000126646-1_1_1',\n",
       " '230000140-1_5_2',\n",
       " '000113851-1_2_2',\n",
       " '000124286-1_1_2',\n",
       " '210097320-1_10_1',\n",
       " '000108174-1_1_1',\n",
       " '000138070-1_1_2',\n",
       " '000136163-1_1_1',\n",
       " '220012147-1_1_1',\n",
       " '190023509-1_1_1',\n",
       " '220012566-1_4_1',\n",
       " '100501022-1_1_2',\n",
       " '100501158-1_3_2',\n",
       " '212001230-1_3_1',\n",
       " '220010584-1_1_1',\n",
       " '000115341-1_1_1',\n",
       " '000114672-1_1_2',\n",
       " '211003113-1_2_1',\n",
       " '220013352-1_1_1',\n",
       " '230003514-1_1_2',\n",
       " '100501022-1_9_3',\n",
       " '200021226-1_2_1',\n",
       " '000123411-1_1_1',\n",
       " '210097453-1_1_1',\n",
       " '220012759-1_1_1',\n",
       " '230000930-1_1_1',\n",
       " '211004578-1_8_2',\n",
       " '000100017-18_1_1',\n",
       " '190013567-1_1_1',\n",
       " '201002008-1_2_1',\n",
       " '000101701-1_1_1',\n",
       " '220032126-1_1_1',\n",
       " '220012615-1_1_2',\n",
       " '000117375-1_1_1',\n",
       " '211004661-1_3_2',\n",
       " '230003687-1_1_1',\n",
       " '000130131-1_1_1',\n",
       " '212001944-1_2_1',\n",
       " '220016202-1_7_1',\n",
       " '000107036-1_2_2',\n",
       " '000121437-1_1_1',\n",
       " '000121637-1_1_1',\n",
       " '230006331-1_9_1',\n",
       " '211005501-1_4_1',\n",
       " '220032478-1_1_1',\n",
       " '100500743-1_7_1',\n",
       " '220034042-1_1_1',\n",
       " '000131703-1_1_2',\n",
       " '000103445-1_1_2',\n",
       " '000120112-1_1_1',\n",
       " '000108694-8_1_1',\n",
       " '000121483-1_1_1',\n",
       " '000135921-1_5_1',\n",
       " '000127316-1_1_1',\n",
       " '000106387-1_1_1',\n",
       " '000118949-1_2_2',\n",
       " '000123589-24_1_1',\n",
       " '110000686-1_6_1',\n",
       " '110002227-1_1_2',\n",
       " '220010582-1_1_2',\n",
       " '225002059-1_1_2',\n",
       " '000122968-1_2_1',\n",
       " '230001223-1_1_2',\n",
       " '212001474-1_1_1',\n",
       " '211005831-1_1_2',\n",
       " '000103236-1_1_1',\n",
       " '000120364-1_1_1',\n",
       " '000126145-1_1_2',\n",
       " '230001335-1_1_1',\n",
       " '000100129-1_1_1',\n",
       " '200021895-1_30_1',\n",
       " '212002081-1_1_1',\n",
       " '220000140-1_5_1',\n",
       " '000121056-1_1_1',\n",
       " '000122083-1_1_1',\n",
       " '000126300-1_1_1',\n",
       " '230005781-1_1_1',\n",
       " '210097318-1_1_1',\n",
       " '000102048-1_1_1',\n",
       " '230002855-1_1_1',\n",
       " '225003072-1_2_1',\n",
       " '000135126-1_1_1',\n",
       " '000104147-1_1_1',\n",
       " '000101531-1_2_2',\n",
       " '211000613-1_1_2',\n",
       " '220013515-1_1_2',\n",
       " '000101417-1_1_1',\n",
       " '220016888-1_4_2',\n",
       " '190021936-1_1_1',\n",
       " '220012086-1_1_2',\n",
       " '220000572-1_4_2',\n",
       " '211000475-1_1_1',\n",
       " '100016978-1_1_1',\n",
       " '210017618-1_18_2',\n",
       " '212001634-1_2_1',\n",
       " '190101190-1_1_1',\n",
       " '220017055-1_1_1',\n",
       " '000102551-1_1_1',\n",
       " '210017608-1_42_1',\n",
       " '211008173-1_1_1',\n",
       " '000125761-2_1_1',\n",
       " '000117139-1_1_2',\n",
       " '230001932-1_1_2',\n",
       " '212001275-1_3_1',\n",
       " '000100742-1_1_1',\n",
       " '000140651-1_2_1',\n",
       " '211008381-1_11_1',\n",
       " '000111845-1_1_1',\n",
       " '110003233-1_1_1',\n",
       " '110002030-1_1_1',\n",
       " '100500920-1_7_2',\n",
       " '000100839-1_1_1',\n",
       " '190000981-1_1_1',\n",
       " '220010657-1_1_1',\n",
       " '000132699-1_1_1',\n",
       " '110002515-1_1_1',\n",
       " '220019032-1_1_1',\n",
       " '000118763-1_1_1',\n",
       " '211010492-1_2_1',\n",
       " '230001305-1_1_2',\n",
       " '220018034-1_1_1',\n",
       " '201009314-1_2_2',\n",
       " '150206093-1_1_1',\n",
       " '212003693-1_4_1',\n",
       " '220030773-1_1_1',\n",
       " '000107515-1_1_2',\n",
       " '230004924-1_2_2',\n",
       " '000111123-1_1_1',\n",
       " '000131630-1_2_1',\n",
       " '220031883-1_1_1',\n",
       " '000101431-1_2_1',\n",
       " '100030106-1_1_1',\n",
       " '220034034-1_5_1',\n",
       " '000121068-23_1_1',\n",
       " '000101458-1_2_2',\n",
       " '230001917-1_3_1',\n",
       " '220014930-1_1_1',\n",
       " '000139659-1_1_2',\n",
       " '200021336-1_75_1',\n",
       " '190012707-1_1_1',\n",
       " '190003784-1_1_1',\n",
       " '000120989-1_1_1',\n",
       " '000131002-1_1_1',\n",
       " '000125740-2_1_1',\n",
       " '000132453-1_1_1',\n",
       " '100017123-1_5_1',\n",
       " '000123958-1_1_2',\n",
       " '000135717-1_1_1',\n",
       " '000100359-1_1_1',\n",
       " '190019718-1_1_1',\n",
       " '190001272-1_1_1',\n",
       " '000110799-1_1_1',\n",
       " '230000085-1_2_2',\n",
       " '201008086-1_1_1',\n",
       " '220014261-1_45_2',\n",
       " '212001504-1_2_1',\n",
       " '000124585-1_1_1',\n",
       " '230001940-1_13_2',\n",
       " '150203374-1_2_1',\n",
       " '230001779-1_2_1',\n",
       " '000111417-1_3_1',\n",
       " '000137582-1_1_1',\n",
       " '000128058-1_1_1',\n",
       " '000125438-1_1_1',\n",
       " '000102536-1_1_2',\n",
       " '220016135-1_1_1',\n",
       " '000115965-1_1_2',\n",
       " '211008387-1_1_2',\n",
       " '000101973-1_1_1',\n",
       " '212003218-1_8_1',\n",
       " '000138133-1_1_1',\n",
       " '000120381-14_1_1',\n",
       " '110002743-1_1_1',\n",
       " '000111490-1_1_1',\n",
       " '120000104-1_7_1',\n",
       " '100029888-1_2_1',\n",
       " '000139827-1_1_1',\n",
       " '000123197-1_1_2',\n",
       " '201005195-1_2_1',\n",
       " '201008153-1_1_1',\n",
       " '110001556-1_1_1',\n",
       " '000119404-1_1_1',\n",
       " '000104621-1_1_1',\n",
       " '225000195-1_18_2',\n",
       " '201002741-1_3_1',\n",
       " '000128942-1_1_1',\n",
       " '000111992-1_1_1',\n",
       " '100500928-1_1_1',\n",
       " '000110450-1_1_1',\n",
       " '000131090-1_1_2',\n",
       " '230002236-1_1_1',\n",
       " '212001364-1_2_1',\n",
       " '000121771-1_2_1',\n",
       " '000103098-1_1_1',\n",
       " '190100821-1_13_1',\n",
       " '100016074-1_1_2',\n",
       " '210097476-1_1_1',\n",
       " '000119750-1_1_1',\n",
       " '211006725-1_1_1',\n",
       " '190000606-1_1_1',\n",
       " '000138725-1_2_1',\n",
       " '150203084-1_1_1',\n",
       " '000100871-1_1_1',\n",
       " '220015783-1_1_1',\n",
       " '190003262-1_1_1',\n",
       " '000127476-1_1_2',\n",
       " '000115788-1_1_1',\n",
       " '000127932-1_1_2',\n",
       " '100028765-1_1_1',\n",
       " '000110848-18_1_1',\n",
       " '190025038-1_1_1',\n",
       " '225002031-1_1_1',\n",
       " '201003183-1_1_1',\n",
       " '220016887-1_8_2',\n",
       " '190101477-1_1_1',\n",
       " '201004227-1_2_1',\n",
       " '000136017-4_1_1',\n",
       " '210021818-1_1_1',\n",
       " '220030076-1_1_2',\n",
       " '201004011-1_2_1',\n",
       " '000101160-1_1_2',\n",
       " '000122840-1_1_1',\n",
       " '201004292-1_21_1',\n",
       " '200219468-1_1_1',\n",
       " '000105489-1_1_1',\n",
       " '000113465-1_1_1',\n",
       " '000100649-1_1_1',\n",
       " '110002934-1_1_1',\n",
       " '212000179-1_2_1',\n",
       " '190022752-1_1_1',\n",
       " '000122923-1_1_1',\n",
       " '000107366-1_2_1',\n",
       " '000130995-1_1_1',\n",
       " '230001306-1_1_1',\n",
       " '230002433-1_1_2',\n",
       " '220034812-1_6_2',\n",
       " '211003566-1_1_1',\n",
       " '230000725-1_1_1',\n",
       " '000124320-1_1_1',\n",
       " '000106396-1_1_1',\n",
       " '000118787-1_1_1',\n",
       " '201007158-1_28_1',\n",
       " '201002772-1_1_1',\n",
       " '211005554-1_1_2',\n",
       " '230005050-1_4_2',\n",
       " '211001815-1_18_1',\n",
       " '100500967-1_10_1',\n",
       " '190026457-1_1_1',\n",
       " '000116407-1_1_1',\n",
       " '000125457-1_1_1',\n",
       " '220019412-1_1_2',\n",
       " '200044611-1_31_1',\n",
       " '000108443-1_1_1',\n",
       " '220016850-1_1_1',\n",
       " '100016377-1_1_1',\n",
       " '190001218-1_1_1',\n",
       " '110001553-1_2_1',\n",
       " '000142424-1_1_1',\n",
       " '000142190-1_1_1',\n",
       " '000114660-1_1_1',\n",
       " '000107158-1_1_1',\n",
       " '000112223-1_1_2',\n",
       " '201009258-1_54_1',\n",
       " '000118872-1_1_1',\n",
       " '190002122-1_1_1',\n",
       " '000116452-1_1_1',\n",
       " '000123911-1_1_1',\n",
       " '230005205-1_1_1',\n",
       " '211007188-1_3_1',\n",
       " '000127277-1_1_1',\n",
       " '220014213-1_1_2',\n",
       " '000104950-1_1_1',\n",
       " '220016205-1_1_2',\n",
       " '220034027-1_6_1',\n",
       " '000108605-1_1_1',\n",
       " '000109464-1_1_1',\n",
       " '220032105-1_1_1',\n",
       " '000117460-1_1_1',\n",
       " '000113438-1_1_1',\n",
       " '000100620-1_1_1',\n",
       " '210017618-1_10_1',\n",
       " '100016503-1_1_1',\n",
       " '201009150-1_1_1',\n",
       " '230003762-1_1_1',\n",
       " '220001535-1_28_2',\n",
       " '000107512-1_1_1',\n",
       " '000126069-1_1_1',\n",
       " '220030556-1_1_1',\n",
       " '110001722-1_1_1',\n",
       " '000136604-1_2_1',\n",
       " '000103277-1_1_1',\n",
       " '000125742-10_1_1',\n",
       " '000106546-1_1_1',\n",
       " '000111819-1_2_1',\n",
       " '190018160-1_1_1',\n",
       " '220034549-1_1_1',\n",
       " '110000641-1_1_1',\n",
       " '220017998-1_1_1',\n",
       " '220018898-1_1_1',\n",
       " '220030085-1_1_2',\n",
       " '190016556-1_1_1',\n",
       " '110003141-1_1_1',\n",
       " '000108214-1_1_2',\n",
       " '211008198-1_1_2',\n",
       " '211004222-1_1_1',\n",
       " '211000538-1_1_1',\n",
       " '150204069-1_1_1',\n",
       " '000116427-1_1_1',\n",
       " '000130530-1_1_1',\n",
       " '000125860-1_2_2',\n",
       " '230006326-1_1_1',\n",
       " '000112028-1_1_1',\n",
       " '230000083-1_37_1',\n",
       " '000117968-1_1_1',\n",
       " '190011564-1_1_1',\n",
       " '190020870-1_1_1',\n",
       " '000119041-1_1_1',\n",
       " '000118546-1_1_1',\n",
       " '000104444-1_1_2',\n",
       " '000112819-1_1_1',\n",
       " '000116984-1_1_1',\n",
       " '200021901-1_35_1',\n",
       " '190009815-1_1_1',\n",
       " '110001321-1_14_1',\n",
       " '150231859-1_1_1',\n",
       " '000113337-1_1_2',\n",
       " '000109671-1_1_1',\n",
       " '000128383-1_1_1',\n",
       " '230000706-1_1_1',\n",
       " '220019736-1_1_2',\n",
       " '100015422-1_1_1',\n",
       " '220013012-1_1_1',\n",
       " '000135564-1_1_1',\n",
       " '220000574-1_1_1',\n",
       " '000128929-11_1_1',\n",
       " '000127896-1_1_1',\n",
       " '000105013-1_1_1',\n",
       " '220012336-1_1_1',\n",
       " '190026877-1_1_1',\n",
       " '230001338-1_2_1',\n",
       " '190012403-1_1_1',\n",
       " '220034206-1_4_2',\n",
       " '000125225-1_1_1',\n",
       " '201008790-1_1_1',\n",
       " '150201715-1_1_1',\n",
       " '000125820-1_3_1',\n",
       " '220014186-1_59_1',\n",
       " '000127861-1_1_2',\n",
       " '000114747-1_1_1',\n",
       " '000106094-1_1_1',\n",
       " '000140579-1_3_1',\n",
       " '000118240-1_1_1',\n",
       " '100029867-1_1_1',\n",
       " '000100941-1_1_1',\n",
       " '000120576-1_1_1',\n",
       " '230004604-1_1_1',\n",
       " '000118164-1_1_1',\n",
       " '212002074-1_2_1',\n",
       " '000132594-1_1_2',\n",
       " '230002227-1_4_1',\n",
       " '190101126-1_1_1',\n",
       " '000138874-1_2_1',\n",
       " '000127015-1_1_1',\n",
       " '000130615-1_1_1',\n",
       " '000125516-1_1_1',\n",
       " '190022563-1_1_1',\n",
       " '220019392-1_2_1',\n",
       " '190022272-1_1_1',\n",
       " '200017539-1_1_1',\n",
       " '201004527-1_5_2',\n",
       " '000105175-1_1_1',\n",
       " '201004928-1_8_1',\n",
       " '100030617-1_1_1',\n",
       " '201008639-1_1_2',\n",
       " '000120749-3_1_1',\n",
       " '201001971-1_1_2',\n",
       " '210097091-1_5_1',\n",
       " '000131024-1_2_1',\n",
       " '000111848-1_1_1',\n",
       " '230005553-1_22_2',\n",
       " '000124090-1_1_1',\n",
       " '211005942-1_1_1',\n",
       " '000137249-1_1_1',\n",
       " '211002969-1_5_1',\n",
       " '190024448-1_1_1',\n",
       " '000130560-1_1_1',\n",
       " '230003856-1_1_1',\n",
       " '000125283-1_1_1',\n",
       " '000101368-1_1_1',\n",
       " '000137894-1_1_1',\n",
       " '190022133-1_1_1',\n",
       " '220019480-1_1_1',\n",
       " '220034810-1_3_2',\n",
       " '000131656-1_2_2',\n",
       " '000128145-1_2_1',\n",
       " '225001065-1_11_2',\n",
       " '000119049-1_1_1',\n",
       " '100030837-1_1_1',\n",
       " '211010119-1_1_1',\n",
       " '000104929-1_6_1',\n",
       " '220020011-1_1_1',\n",
       " '000125287-1_1_2',\n",
       " '110002319-1_1_2',\n",
       " '190014777-1_1_1',\n",
       " '201008131-1_1_1',\n",
       " '000105210-1_1_1',\n",
       " '000120808-1_1_1',\n",
       " '000105068-1_1_1',\n",
       " '201002918-1_1_1',\n",
       " '000102633-1_1_1',\n",
       " '211010694-1_5_1',\n",
       " '000114244-1_1_1',\n",
       " '000118308-1_1_1',\n",
       " '210000240-1_1_1',\n",
       " '220015832-1_1_1',\n",
       " '000110869-1_1_1',\n",
       " '210097244-1_2_1',\n",
       " '100015263-1_1_1',\n",
       " '000102813-1_1_1',\n",
       " '220010631-1_3_1',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "corpus = './Data/package'# PATH\n",
    "set = 'Data/train.txt' \n",
    "vocabulary = 'Data/vocabulary_semantic.txt'  \n",
    "save_model = './trained_\\semantic_model'\n",
    "\n",
    "primus = CTC_PriMuS(corpus, set, vocabulary, semantic = True, val_split = 0.1)\n",
    "primus.training_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bae68dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/myranda/Documents/DSI/ML/OMR'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a10988f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/package/000118390-1_1_2/000118390-1_1_2\n",
      "(155, 1639)\n"
     ]
    }
   ],
   "source": [
    "#IMAGE DEBUGGING\n",
    "sample_filepath = primus.training_list[0]\n",
    "sample_fullpath = corpus + '/' + sample_filepath + '/' + sample_filepath\n",
    "print(sample_fullpath)\n",
    "\n",
    "# Get image\n",
    "sample_img = cv2.imread(sample_fullpath + '.png', 0)\n",
    "print(sample_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "526143d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "# IMAGE DEBUGGING - MPL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "PATH = './Data/package/' + sample_filepath + '/' + sample_filepath\n",
    "\n",
    "img = mpimg.imread(PATH + '.png')\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc61e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 128\n",
    "max_epochs = 1\n",
    "dropout = 0.5\n",
    "\n",
    "batch_size = 16\n",
    "vocabulary_size = primus.vocabulary_size\n",
    "model_cnn = cnn_model(batch_size)\n",
    "model_rnn = rnn_model(embed_size = 512, hidden_size = 512, vocab_size = primus.vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cebc3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "\n",
    "learning_rate = 0.001\n",
    "criterion = torch.nn.CTCLoss()\n",
    "optimizer_cnn = optim.Adam(model_cnn.parameters(), lr = learning_rate) ## ADD MODEL PARAMS\n",
    "optimizer_rnn = optim.Adam(model_rnn.parameters(), lr = learning_rate)\n",
    "optimizer = optim.Adam(list(model_cnn.parameters()) + list(model_rnn.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b08e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed5b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default params\n",
    "# With image height of 128, width will be 1870\n",
    "params = dict()\n",
    "params['img_height'] = img_height\n",
    "params['img_width'] = None\n",
    "params['batch_size'] = 16\n",
    "params['img_channels'] = 1\n",
    "params['conv_blocks'] = 4\n",
    "params['conv_filter_n'] = [32, 64, 128, 256]\n",
    "params['conv_filter_size'] = [ [3,3], [3,3], [3,3], [3,3] ]\n",
    "params['conv_pooling_size'] = [ [2,2], [2,2], [2,2], [2,2] ]\n",
    "params['rnn_units'] = 512\n",
    "params['rnn_layers'] = 2\n",
    "params['vocabulary_size'] = vocabulary_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f57ffc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape for CTC loss\n",
    "input_shape = (None, params['img_height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a30f0340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 2017, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57bee88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 2153, 1])\n",
      "torch.Size([16, 64, 14, 267])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (14336x267 and 896x2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27213/1342245661.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#features = torch.permute(output, (3, 0, 2, 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#features = torch.reshape(features, (16, features.shape[0], 64 * 14)) # width, batch, features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moutput_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#Input and target shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_27213/1962396934.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, input_size)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m         )\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (14336x267 and 896x2048)"
     ]
    }
   ],
   "source": [
    "# Train using model_rnn\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    \n",
    "    train_acc = 0.\n",
    "    valid_acc = 0.\n",
    "    \n",
    "    for i in range(0, 70880 + 7875, 16):\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs']\n",
    "\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        output = model_cnn(tensor_data_reshape)\n",
    "        print(output.shape)\n",
    "        #output_size = 64 * 14 * output.shape[3]\n",
    "        output_size = output.shape[3]\n",
    "        # Reshape output for RNN\n",
    "        output = output.view(output.size(0), output.size(3), -1)\n",
    "        output = output.permute(0,2,1)\n",
    "        #features = torch.permute(output, (3, 0, 2, 1))\n",
    "        #features = torch.reshape(features, (16, features.shape[0], 64 * 14)) # width, batch, features\n",
    "        output_rnn = model_rnn(output, input_size = 64*14)\n",
    "        \n",
    "        #Input and target shape\n",
    "        input_shape = (None, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        target_shape = batch['seq_lengths']\n",
    "        \n",
    "        loss = criterion(output, targets, input_shape, target_shape)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Calc loss\n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0 # ADD ACCURACY\n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de3d587a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14336/896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c39c765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using Basic RNN\n",
    "\n",
    "# Setup\n",
    "BATCH_SIZE = 16\n",
    "IMG_HEIGHT = img_height\n",
    "N_EPOCHS = 1\n",
    "N_OUTPUTS = vocabulary_size + 1\n",
    "N_NEURONS = 512\n",
    "#N_INPUTS = 512\n",
    "N_INPUTS = 896\n",
    "model_cnn = cnn_model(BATCH_SIZE)\n",
    "basic_rnn = BasicRNN(BATCH_SIZE, 1, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
    "optimizer = optim.Adam(list(model_cnn.parameters()) + list(basic_rnn.parameters()))\n",
    "len_data = len(primus.training_list) + len(primus.validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "33116ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 14, 179])\n",
      "torch.Size([14, 179])\n",
      "torch.Size([179, 16, 896])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable LSTM object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9439/2840740796.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# width, batch, features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mrnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq_lengths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9439/4271976162.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#lstm_out, self.hidden = self.basic_rnn(X, self.hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m896\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable LSTM object"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    model_cnn.train()\n",
    "    basic_rnn.train()\n",
    "    \n",
    "    for i in range(0, len_data, BATCH_SIZE):\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        basic_rnn.hidden = basic_rnn.init_hidden()\n",
    "        \n",
    "        # Get inputs\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs'] # size (batch, height, width, channels)\n",
    "        #print(data)\n",
    "        #print(data.shape)\n",
    "        max_input_length = data.shape[2]\n",
    "        \n",
    "        # list of indices, values, shape\n",
    "        seq_len = int(batch['seq_lengths'][0])\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        #print(tuple(targets[2]))\n",
    "        #print(type(t[0]) for t in targets)\n",
    "        #targets = torch.sparse_coo_tensor(targets[0], targets[1], tuple(targets[2]))\n",
    "        targets_0 = torch.as_tensor((targets[0]))\n",
    "        #print(targets.shape)\n",
    "        #targets = torch.reshape(targets, (16, 1))\n",
    "        padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=max_input_length)\n",
    "        padded_targets_tensor = torch.tensor(padded_targets)\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        #print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        # forward, backward, optim\n",
    "        cnn_output = model_cnn(tensor_data_reshape)\n",
    "        output_size = 64 * 14 * cnn_output.shape[3]\n",
    "        #print(cnn_output.shape)\n",
    "        #print(cnn_output[0])\n",
    "        print(cnn_output[0].shape)\n",
    "        print(cnn_output[0][0].shape)\n",
    "        \n",
    "        # Change shape for rnn\n",
    "        output = torch.reshape(cnn_output, (cnn_output.shape[3], 16, 64 * 14)) # width, batch, features\n",
    "        print(output.shape)\n",
    "        rnn_output = basic_rnn(output)\n",
    "        print(rnn_output[0].shape)\n",
    "        print(batch['seq_lengths'])\n",
    "        \n",
    "        #rnn_output_reshape = torch.reshape(rnn_output, (cnn_output[0].shape[2], BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = torch.reshape(rnn_output[0], (1, BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = rnn_output[0].view(-1, BATCH_SIZE, N_OUTPUTS)\n",
    "        \n",
    "        \n",
    "        log_probs = nn.functional.log_softmax(rnn_output)\n",
    "        #Input and target shape\n",
    "        #print(rnn_output_reshape.shape)\n",
    "        input_shape = (BATCH_SIZE, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        input_len = tuple([1 for i in range (0, BATCH_SIZE)])\n",
    "        #print(input_shape)\n",
    "        target_shape = tuple(int(b) for b in batch['seq_lengths'])\n",
    "        \n",
    "        # MUST BE TENSOR, TENSOR, TUPLE, TUPLE OR TENSOR TENSOR TENSOR TENSOR\n",
    "        #loss = criterion(rnn_output_reshape, padded_targets_tensor, input_len, target_shape)\n",
    "        #loss = criterion(log_probs, padded_targets_tensor, input_len, target_shape)\n",
    "        loss = criterion(log_probs, padded_targets_tensor, target_shape, tuple(lengths))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0\n",
    "        print(\"Loss: %f\", train_loss)\n",
    "        \n",
    "    #model.eval()\n",
    "    print('training loss:')\n",
    "    print(train_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e9a3de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0c83b8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782.0"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28512/16\n",
    "# 16 times seq_len * n_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "60289bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128 * data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5f06f879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "320ec14a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 26 at dim 1 (got 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7287/2267183817.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 26 at dim 1 (got 20)"
     ]
    }
   ],
   "source": [
    "torch.as_tensor(tuple(batch['targets']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18c4f6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 36, 24, 31, 21, 18, 27, 31, 15, 26, 26, 18, 17, 15, 18, 38])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=125)\n",
    "len(padded_targets)\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f14537b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 125])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(padded_targets).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b76856f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.0000e+01, 2.3400e+02, 1.7790e+03, 1.5990e+03, 0.0000e+00, 1.0180e+03,\n",
       "          1.0180e+03, 1.0180e+03, 1.0180e+03, 1.6470e+03, 1.4830e+03, 1.2370e+03,\n",
       "          1.0360e+03, 0.0000e+00, 8.2300e+02, 6.0400e+02, 8.5300e+02, 4.0200e+02,\n",
       "          1.0180e+03, 6.0400e+02, 4.2600e+02, 1.6180e+03, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [7.0000e+00, 2.2800e+02, 1.7800e+03, 1.7220e+03, 9.8300e+02, 0.0000e+00,\n",
       "          9.8300e+02, 9.8300e+02, 0.0000e+00, 3.8100e+02, 5.6100e+02, 7.7900e+02,\n",
       "          0.0000e+00, 9.9200e+02, 7.9000e+02, 5.5600e+02, 0.0000e+00, 3.7400e+02,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.2900e+02, 1.7800e+03, 2.6600e+02, 0.0000e+00, 1.7270e+03,\n",
       "          1.5990e+03, 1.5990e+03, 8.2300e+02, 1.3030e+03, 1.0190e+03, 8.5300e+02,\n",
       "          0.0000e+00, 5.8100e+02, 1.5990e+03, 6.7800e+02, 8.2300e+02, 4.9000e+02,\n",
       "          1.5990e+03, 8.2400e+02, 1.0440e+03, 0.0000e+00, 5.9500e+02, 1.5990e+03,\n",
       "          1.5990e+03, 8.2300e+02, 1.3030e+03, 1.0190e+03, 1.4790e+03, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.3400e+02, 1.7570e+03, 5.6100e+02, 9.9200e+02, 1.6170e+03,\n",
       "          0.0000e+00, 1.1790e+03, 4.1800e+02, 0.0000e+00, 4.1800e+02, 1.6170e+03,\n",
       "          4.1800e+02, 0.0000e+00, 5.9000e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.3100e+02, 1.7790e+03, 4.3400e+02, 0.0000e+00, 4.3400e+02,\n",
       "          0.0000e+00, 4.3400e+02, 1.7410e+03, 0.0000e+00, 4.3400e+02, 0.0000e+00,\n",
       "          4.3400e+02, 0.0000e+00, 4.3400e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.2900e+02, 1.7800e+03, 1.7270e+03, 0.0000e+00, 2.6100e+02,\n",
       "          0.0000e+00, 1.3070e+03, 1.0360e+03, 8.4400e+02, 0.0000e+00, 8.2300e+02,\n",
       "          6.7800e+02, 6.8700e+02, 1.7220e+03, 0.0000e+00, 1.4610e+03, 1.3130e+03,\n",
       "          1.0360e+03, 0.0000e+00, 1.0180e+03, 8.2300e+02, 8.4400e+02, 1.7220e+03,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.3100e+02, 1.7790e+03, 2.6000e+02, 0.0000e+00, 8.3200e+02,\n",
       "          6.8200e+02, 0.0000e+00, 8.3200e+02, 1.0360e+03, 1.0360e+03, 0.0000e+00,\n",
       "          4.0800e+02, 4.1800e+02, 1.4260e+03, 0.0000e+00, 1.6060e+03, 1.4260e+03,\n",
       "          1.6170e+03, 0.0000e+00, 4.0800e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.2800e+02, 1.7800e+03, 1.0440e+03, 0.0000e+00, 1.0260e+03,\n",
       "          1.7410e+03, 1.0440e+03, 1.4330e+03, 1.6250e+03, 4.2600e+02, 6.0400e+02,\n",
       "          8.5100e+02, 1.0440e+03, 1.2320e+03, 0.0000e+00, 1.4590e+03, 1.7410e+03,\n",
       "          1.4770e+03, 4.2600e+02, 6.0400e+02, 8.5100e+02, 1.0440e+03, 1.2320e+03,\n",
       "          1.4770e+03, 1.6710e+03, 0.0000e+00, 4.4700e+02, 1.7410e+03, 4.4100e+02,\n",
       "          6.3100e+02, 4.6000e+02, 1.6710e+03, 1.4770e+03, 1.2320e+03, 1.0440e+03,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.2800e+02, 1.7570e+03, 6.2000e+02, 1.0750e+03, 8.8900e+02,\n",
       "          6.2000e+02, 6.2000e+02, 6.2000e+02, 6.2000e+02, 0.0000e+00, 6.2700e+02,\n",
       "          1.7270e+03, 1.7270e+03, 0.0000e+00, 8.7000e+02, 1.2520e+03, 8.8900e+02,\n",
       "          8.7000e+02, 8.7000e+02, 8.7000e+02, 8.7000e+02, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.2300e+02, 1.7510e+03, 1.4050e+03, 6.7800e+02, 1.4050e+03,\n",
       "          6.7800e+02, 0.0000e+00, 1.2400e+02, 8.5300e+02, 6.9200e+02, 8.5300e+02,\n",
       "          1.0440e+03, 8.4400e+02, 0.0000e+00, 1.4540e+03, 1.3030e+03, 8.2300e+02,\n",
       "          4.0200e+02, 0.0000e+00, 9.9000e+01, 6.9200e+02, 4.2600e+02, 6.9200e+02,\n",
       "          8.5300e+02, 6.8700e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [9.0000e+00, 2.3400e+02, 1.7570e+03, 1.6630e+03, 6.2700e+02, 6.3100e+02,\n",
       "          8.9100e+02, 1.0590e+03, 0.0000e+00, 6.2700e+02, 1.6630e+03, 4.5300e+02,\n",
       "          0.0000e+00, 6.2700e+02, 4.5300e+02, 1.6630e+03, 0.0000e+00, 1.4670e+03,\n",
       "          1.0360e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.2900e+02, 1.7510e+03, 2.8300e+02, 0.0000e+00, 1.3130e+03,\n",
       "          6.7900e+02, 6.9200e+02, 0.0000e+00, 1.6640e+03, 1.4790e+03, 1.3180e+03,\n",
       "          0.0000e+00, 8.2300e+02, 8.2300e+02, 1.7170e+03, 1.3030e+03, 0.0000e+00,\n",
       "          1.0360e+03, 1.7410e+03, 1.0440e+03, 5.1800e+02, 1.4790e+03, 1.0440e+03,\n",
       "          0.0000e+00, 1.3030e+03, 1.3030e+03, 1.7270e+03, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.2800e+02, 1.7510e+03, 1.0190e+03, 1.2320e+03, 1.4520e+03,\n",
       "          1.2320e+03, 0.0000e+00, 1.0180e+03, 4.0200e+02, 1.0180e+03, 1.7170e+03,\n",
       "          0.0000e+00, 1.4520e+03, 1.6710e+03, 4.4200e+02, 1.6710e+03, 0.0000e+00,\n",
       "          1.4510e+03, 1.0180e+03, 1.4510e+03, 1.7170e+03, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 1.7790e+03, 1.0270e+03, 8.4100e+02, 0.0000e+00, 1.0270e+03,\n",
       "          8.2300e+02, 5.8300e+02, 0.0000e+00, 8.3000e+02, 1.7270e+03, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [3.0000e+00, 1.7790e+03, 2.7200e+02, 0.0000e+00, 1.7220e+03, 1.7170e+03,\n",
       "          1.1740e+03, 4.0200e+02, 5.8300e+02, 0.0000e+00, 8.5300e+02, 4.2600e+02,\n",
       "          1.5960e+03, 4.2600e+02, 8.5300e+02, 5.8300e+02, 1.1740e+03, 1.7170e+03,\n",
       "          1.7270e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.2300e+02, 1.7800e+03, 2.6500e+02, 0.0000e+00, 1.7220e+03,\n",
       "          1.7270e+03, 1.6170e+03, 0.0000e+00, 8.2300e+02, 1.3030e+03, 1.0180e+03,\n",
       "          1.4540e+03, 1.3030e+03, 1.0180e+03, 0.0000e+00, 8.2300e+02, 6.7800e+02,\n",
       "          8.3200e+02, 6.7800e+02, 4.9000e+02, 0.0000e+00, 1.6170e+03, 1.4700e+03,\n",
       "          1.4700e+03, 1.0360e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " tensor([23, 18, 30, 15, 16, 25, 21, 37, 23, 27, 19, 29, 23, 11, 20, 27])]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_targets_list = [torch.tensor(padded_targets[i]) for i in range(0,len(padded_targets))]\n",
    "padded_targets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc2b5634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29, 31, 23, 26, 37, 27, 22, 23, 13, 20, 20, 21, 17, 30, 24, 25])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "665eb276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1743"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "fea5f53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1782])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ac729b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "31fdec5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1520"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(target_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "065a20f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ctc_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4756/326398514.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DEBUGGING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mctc_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mctc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctc_crnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ctc_model'"
     ]
    }
   ],
   "source": [
    "# DEBUGGING\n",
    "# Train\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    #model.train()\n",
    "    \n",
    "    for i in range(0, len_data, BATCH_SIZE):\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        basic_rnn.hidden = basic_rnn.init_hidden()\n",
    "        \n",
    "        # Get inputs\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs'] # size (batch, height, width, channels)\n",
    "        #print(data)\n",
    "        #print(data.shape)\n",
    "        max_input_length = data.shape[2]\n",
    "        \n",
    "        # list of indices, values, shape\n",
    "        seq_len = int(batch['seq_lengths'][0])\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        #print(tuple(targets[2]))\n",
    "        #print(type(t[0]) for t in targets)\n",
    "        #targets = torch.sparse_coo_tensor(targets[0], targets[1], tuple(targets[2]))\n",
    "        targets_0 = torch.as_tensor((targets[0]))\n",
    "        #print(targets.shape)\n",
    "        #targets = torch.reshape(targets, (16, 1))\n",
    "        padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=max_input_length)\n",
    "        padded_targets_tensor = torch.tensor(padded_targets)\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        #print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        # forward, backward, optim\n",
    "        cnn_output = model_cnn(tensor_data_reshape)\n",
    "        \n",
    "        # Change shape for rnn\n",
    "        output = cnn_output.view(cnn_output.size(0), cnn_output.size(1), -1)\n",
    "        print(output.shape)\n",
    "        output.permute(2,0,1)\n",
    "        rnn_output = basic_rnn(output)\n",
    "        print(rnn_output.shape)\n",
    "        #print(batch['seq_lengths'])\n",
    "        \n",
    "        #rnn_output_reshape = torch.reshape(rnn_output, (cnn_output[0].shape[2], BATCH_SIZE, N_OUTPUTS))\n",
    "        rnn_output_reshape = torch.reshape(rnn_output, (1, BATCH_SIZE, N_OUTPUTS))\n",
    "        \n",
    "        log_probs = nn.functional.log_softmax(rnn_output_reshape)\n",
    "        #Input and target shape\n",
    "        #print(rnn_output_reshape.shape)\n",
    "        input_shape = (BATCH_SIZE, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        input_len = tuple([1 for i in range (0, BATCH_SIZE)])\n",
    "        #print(input_shape)\n",
    "        target_shape = tuple(int(b) for b in batch['seq_lengths'])\n",
    "        \n",
    "        # MUST BE TENSOR, TENSOR, TUPLE, TUPLE OR TENSOR TENSOR TENSOR TENSOR\n",
    "        #loss = criterion(rnn_output_reshape, padded_targets_tensor, input_len, target_shape)\n",
    "        loss = criterion(log_probs, padded_targets_tensor, input_len, target_shape)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0\n",
    "        \n",
    "    #model.eval()\n",
    "    print('training loss:')\n",
    "    print(train_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f557b56a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:115] . file in archive is not in a subdirectory: semantic_model.data-00000-of-00001",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9439/3612140687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Models/Semantic-Model.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;31m# reset back to the original position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                     warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:115] . file in archive is not in a subdirectory: semantic_model.data-00000-of-00001"
     ]
    }
   ],
   "source": [
    "torch.load('./Models/Semantic-Model.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
