{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ddc401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/myranda/miniconda3/bin/python3.7\n",
      "3.7.10 | packaged by conda-forge | (default, Feb 19 2021, 16:07:37) \n",
      "[GCC 9.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d39482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/myranda/miniconda3/envs/python38\n",
      "\n",
      "  added / updated specs:\n",
      "    - opencv\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi            pkgs/main::certifi-2021.10.8-py38h06a~ --> conda-forge::certifi-2021.10.8-py38h578d9bd_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2021.10.26~ --> conda-forge::ca-certificates-2021.10.8-ha878542_0\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge opencv -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec2b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa24a515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/myranda/miniconda3/envs/python38/lib/python3.8/site-packages (4.5.4.60)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/myranda/.local/lib/python3.8/site-packages (from opencv-python) (1.19.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96990c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMR Model \n",
    "# Goal: recognize images of music excerpts\n",
    "\n",
    "# Modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "class cnn_model(torch.nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(cnn_model, self).__init__()\n",
    "\n",
    "        kernel_size = [3,3]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size = kernel_size)\n",
    "        self.batch1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16,32, kernel_size = kernel_size)\n",
    "        self.batch2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size = kernel_size)\n",
    "        self.batch3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.act = nn.LeakyReLU()\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # FORWARD PASS\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        output = x\n",
    "\n",
    "        return x\n",
    "\n",
    "class rnn_model(torch.nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size):\n",
    "        super(rnn_model, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        #self.rnn = nn.LSTMCell(input_size = embed_size, hidden_size = hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size + 1)\n",
    "\n",
    "    def forward(self,x, input_size):\n",
    "\n",
    "        #h0 = torch.zeros(16, x.size(0), self.hidden_size).to(device)\n",
    "        #c0 = torch.zeros(16, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        h0 = torch.zeros(16,self.hidden_size,self.hidden_size)#.to(device)\n",
    "        c0 = torch.zeros(16, self.hidden_size,self.hidden_size)#.to(device)\n",
    "        \n",
    "        self.rnn = nn.LSTMCell(input_size = input_size, hidden_size = self.hidden_size)\n",
    "        out, _ = self.rnn(x, (h0, c0))\n",
    "\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "750fd71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super(BasicRNN, self).__init__()\n",
    "        \n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n",
    "        \n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        #X = X.permute(1, 0, 2) \n",
    "        \n",
    "        self.batch_size = X.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        # lstm_out => n_steps, batch_size, n_neurons (hidden states for each time step)\n",
    "        # self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\n",
    "        #lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
    "        out, self.hidden = self.basic_rnn(self.n_inputs, self.n_neurons)\n",
    "        out = self.FC(self.hidden)\n",
    "        \n",
    "        return out#.view(-1, self.n_outputs) # batch_size X n_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2cf639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctc_utils\n",
    "from primus import CTC_PriMuS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0cfcf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 70880 and validating with 7875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['220000077-1_1_2',\n",
       " '211004581-1_4_1',\n",
       " '000116579-1_1_2',\n",
       " '230000244-1_11_2',\n",
       " '100500850-1_4_1',\n",
       " '000110862-1_1_2',\n",
       " '100016464-1_2_1',\n",
       " '000108487-1_1_1',\n",
       " '000128906-1_16_1',\n",
       " '211007096-1_12_2',\n",
       " '000120682-1_1_1',\n",
       " '000116205-1_1_1',\n",
       " '000118363-1_1_1',\n",
       " '000109865-1_1_1',\n",
       " '000122696-1_1_2',\n",
       " '220010733-1_1_1',\n",
       " '211004328-1_2_1',\n",
       " '000137543-1_2_1',\n",
       " '190027314-1_1_1',\n",
       " '000102007-1_1_2',\n",
       " '100500760-1_19_1',\n",
       " '230006216-1_2_1',\n",
       " '000121506-1_1_1',\n",
       " '000107566-1_1_1',\n",
       " '000127894-1_1_1',\n",
       " '000109826-1_1_2',\n",
       " '201010264-1_1_1',\n",
       " '000138546-1_1_1',\n",
       " '220013180-1_8_1',\n",
       " '220034310-1_1_2',\n",
       " '201001715-1_1_1',\n",
       " '000118685-1_1_2',\n",
       " '201007179-1_5_1',\n",
       " '000135553-1_1_1',\n",
       " '000104092-1_1_1',\n",
       " '211004761-1_3_1',\n",
       " '000101455-1_2_1',\n",
       " '110003161-6_1_1',\n",
       " '000111776-1_1_1',\n",
       " '000141444-1_1_1',\n",
       " '000112618-1_1_1',\n",
       " '000135661-1_1_2',\n",
       " '212002571-1_1_1',\n",
       " '000104184-1_1_1',\n",
       " '000135100-1_2_1',\n",
       " '150201729-1_1_1',\n",
       " '211004475-1_3_1',\n",
       " '000116071-1_1_1',\n",
       " '000118707-1_2_2',\n",
       " '000127829-1_1_1',\n",
       " '000107251-1_1_1',\n",
       " '000141471-1_1_1',\n",
       " '000101530-1_1_1',\n",
       " '201005043-1_1_2',\n",
       " '000102397-1_1_1',\n",
       " '230005154-1_1_1',\n",
       " '000105513-1_1_1',\n",
       " '100016378-1_1_1',\n",
       " '000122399-1_1_1',\n",
       " '000111945-1_1_1',\n",
       " '000124977-1_1_2',\n",
       " '000125522-1_1_1',\n",
       " '211004773-1_1_1',\n",
       " '220019032-1_1_1',\n",
       " '190003095-1_1_1',\n",
       " '190004441-1_1_1',\n",
       " '230006252-1_8_1',\n",
       " '100501051-1_2_1',\n",
       " '100500672-1_3_1',\n",
       " '000128230-1_1_1',\n",
       " '000111496-1_1_1',\n",
       " '000136283-1_1_1',\n",
       " '100030926-1_4_1',\n",
       " '201002092-1_1_2',\n",
       " '000103789-1_1_1',\n",
       " '000138962-1_1_1',\n",
       " '150202233-1_1_1',\n",
       " '220011746-1_1_2',\n",
       " '100198371-1_1_1',\n",
       " '000120113-1_1_1',\n",
       " '220031041-1_1_1',\n",
       " '220032464-1_1_2',\n",
       " '201004211-1_7_1',\n",
       " '000138766-1_3_1',\n",
       " '000117285-1_1_1',\n",
       " '000111406-1_1_2',\n",
       " '220018652-1_1_1',\n",
       " '220011780-1_1_2',\n",
       " '000115824-1_1_1',\n",
       " '220015246-1_1_2',\n",
       " '230000214-1_1_2',\n",
       " '000110642-1_1_1',\n",
       " '190005671-1_1_1',\n",
       " '110002189-1_1_1',\n",
       " '000100179-1_1_1',\n",
       " '000105061-17_1_1',\n",
       " '000135430-1_1_1',\n",
       " '000110627-1_1_1',\n",
       " '000140940-1_1_1',\n",
       " '220000704-1_8_1',\n",
       " '100029778-1_2_1',\n",
       " '000141371-1_1_1',\n",
       " '220032094-1_1_1',\n",
       " '000101103-1_1_1',\n",
       " '000115189-1_1_1',\n",
       " '000103052-1_1_2',\n",
       " '000120423-1_1_1',\n",
       " '100016214-1_1_1',\n",
       " '110000982-5_1_1',\n",
       " '201009278-1_4_2',\n",
       " '000142095-1_2_1',\n",
       " '000126323-1_1_1',\n",
       " '190009654-1_1_1',\n",
       " '211006873-1_5_1',\n",
       " '220034348-1_6_1',\n",
       " '220001288-1_5_1',\n",
       " '225000870-1_44_2',\n",
       " '211010440-1_29_2',\n",
       " '000119972-1_1_1',\n",
       " '000113910-1_1_2',\n",
       " '212002086-1_35_2',\n",
       " '000107599-1_1_1',\n",
       " '220010919-1_1_2',\n",
       " '220015224-1_6_1',\n",
       " '220030832-1_1_1',\n",
       " '000100367-11_1_1',\n",
       " '000130396-1_1_2',\n",
       " '000112438-1_1_1',\n",
       " '201008477-1_1_2',\n",
       " '000113151-1_1_1',\n",
       " '000123140-1_1_1',\n",
       " '000110031-1_1_1',\n",
       " '220016560-1_21_2',\n",
       " '225001717-1_1_1',\n",
       " '100030746-1_3_1',\n",
       " '000104616-1_1_1',\n",
       " '230005177-1_1_1',\n",
       " '230003411-1_3_2',\n",
       " '000123825-1_1_2',\n",
       " '201001167-1_4_1',\n",
       " '190006396-1_1_1',\n",
       " '220013415-1_1_1',\n",
       " '000109466-1_1_1',\n",
       " '210097277-1_3_1',\n",
       " '190014497-1_1_1',\n",
       " '110002957-1_41_1',\n",
       " '000127515-1_2_1',\n",
       " '000116591-17_1_1',\n",
       " '000138781-1_2_1',\n",
       " '000120570-1_1_1',\n",
       " '190003749-1_1_1',\n",
       " '210021729-1_2_1',\n",
       " '000105365-1_1_1',\n",
       " '211010568-1_12_1',\n",
       " '000122638-1_1_2',\n",
       " '220012819-1_1_2',\n",
       " '211004907-1_1_1',\n",
       " '000125991-1_1_1',\n",
       " '000101137-1_1_1',\n",
       " '000135523-1_1_1',\n",
       " '150203955-1_1_1',\n",
       " '190100662-1_1_1',\n",
       " '230003958-1_1_1',\n",
       " '225001022-1_14_1',\n",
       " '230006602-1_5_1',\n",
       " '220017766-1_1_2',\n",
       " '100500533-1_2_1',\n",
       " '000117755-1_1_2',\n",
       " '000123415-1_1_1',\n",
       " '211007076-1_3_1',\n",
       " '211007234-1_1_1',\n",
       " '000108302-3_1_1',\n",
       " '211007183-1_19_1',\n",
       " '000109904-1_1_1',\n",
       " '000051660-1_2_1',\n",
       " '000116105-1_1_1',\n",
       " '190012149-1_1_1',\n",
       " '225001350-1_1_1',\n",
       " '220016597-1_2_1',\n",
       " '000105483-1_1_1',\n",
       " '230003001-1_2_2',\n",
       " '212003050-1_2_1',\n",
       " '230005164-1_1_2',\n",
       " '000135899-1_2_1',\n",
       " '230001897-1_3_1',\n",
       " '220011786-1_32_2',\n",
       " '220014258-1_1_2',\n",
       " '211004984-1_1_1',\n",
       " '230003123-1_1_1',\n",
       " '000101518-1_11_1',\n",
       " '230001121-1_3_1',\n",
       " '000106955-1_1_1',\n",
       " '000108827-1_1_1',\n",
       " '220013322-1_4_2',\n",
       " '000112614-1_1_1',\n",
       " '211004873-1_9_1',\n",
       " '200043765-1_21_1',\n",
       " '211010355-1_1_1',\n",
       " '212002777-1_2_1',\n",
       " '000127610-1_2_1',\n",
       " '200043762-1_21_2',\n",
       " '225001086-1_1_1',\n",
       " '150202598-1_1_1',\n",
       " '190010415-1_1_1',\n",
       " '000120897-1_1_1',\n",
       " '000102697-1_1_1',\n",
       " '000113222-1_1_1',\n",
       " '220000716-1_1_1',\n",
       " '220016952-1_12_2',\n",
       " '000105061-11_1_1',\n",
       " '000109248-1_1_1',\n",
       " '201005047-1_1_1',\n",
       " '230001250-1_1_2',\n",
       " '000113909-1_1_1',\n",
       " '100198321-1_1_1',\n",
       " '000103459-1_1_2',\n",
       " '000100988-1_1_2',\n",
       " '211005510-1_7_1',\n",
       " '201002233-1_3_1',\n",
       " '230002034-1_14_2',\n",
       " '000107820-1_1_2',\n",
       " '000123581-1_1_1',\n",
       " '000122322-1_1_1',\n",
       " '000119252-1_1_1',\n",
       " '000117582-1_1_1',\n",
       " '000109861-4_1_1',\n",
       " '200021893-1_25_1',\n",
       " '201004906-1_10_1',\n",
       " '000107421-1_1_1',\n",
       " '230001963-1_5_1',\n",
       " '100500921-1_1_3',\n",
       " '230003435-1_2_1',\n",
       " '220001143-1_3_1',\n",
       " '000102572-1_2_2',\n",
       " '100219161-1_1_1',\n",
       " '211007016-1_1_2',\n",
       " '000103550-1_1_1',\n",
       " '210022073-1_6_1',\n",
       " '230006252-1_11_2',\n",
       " '212003700-1_1_1',\n",
       " '000136046-1_1_1',\n",
       " '000112403-1_1_1',\n",
       " '000128936-5_1_1',\n",
       " '190012134-1_1_2',\n",
       " '000105715-1_1_1',\n",
       " '212001999-1_4_1',\n",
       " '000106088-1_1_1',\n",
       " '220010674-1_5_1',\n",
       " '211007011-1_2_1',\n",
       " '000107777-1_2_1',\n",
       " '000119891-1_1_1',\n",
       " '000142143-1_2_1',\n",
       " '000123990-1_1_1',\n",
       " '220017670-1_1_1',\n",
       " '000106987-1_1_1',\n",
       " '000138164-1_1_1',\n",
       " '150202863-1_2_1',\n",
       " '000115290-1_1_2',\n",
       " '000120954-1_1_1',\n",
       " '000100693-1_1_1',\n",
       " '220000759-1_1_1',\n",
       " '210097334-1_1_1',\n",
       " '211004465-1_1_1',\n",
       " '000117871-1_1_2',\n",
       " '000109331-1_1_2',\n",
       " '201008015-1_9_1',\n",
       " '000111331-1_1_1',\n",
       " '000102059-1_1_2',\n",
       " '000118403-1_1_2',\n",
       " '000107960-1_1_1',\n",
       " '220011483-1_1_1',\n",
       " '212001655-1_1_1',\n",
       " '220030647-1_1_2',\n",
       " '220015183-1_1_1',\n",
       " '210022264-1_3_1',\n",
       " '000124640-1_1_1',\n",
       " '220034438-1_1_1',\n",
       " '201007922-1_31_1',\n",
       " '000132620-1_1_1',\n",
       " '000123842-1_1_1',\n",
       " '230000757-1_1_1',\n",
       " '000109724-1_1_2',\n",
       " '000108333-1_2_1',\n",
       " '000101011-1_1_2',\n",
       " '212001134-1_1_1',\n",
       " '110000443-1_1_1',\n",
       " '100198285-1_1_1',\n",
       " '000132204-1_1_1',\n",
       " '150006250-1_1_1',\n",
       " '000106444-1_1_2',\n",
       " '000116424-1_1_1',\n",
       " '225001257-1_1_1',\n",
       " '190002848-1_1_1',\n",
       " '000106390-1_1_1',\n",
       " '225000887-1_1_1',\n",
       " '000109824-1_1_1',\n",
       " '000118175-1_1_1',\n",
       " '000113936-1_1_1',\n",
       " '100500674-1_2_1',\n",
       " '230005192-1_3_1',\n",
       " '225000008-1_1_1',\n",
       " '100015782-1_1_1',\n",
       " '000113288-1_1_1',\n",
       " '000115119-1_2_1',\n",
       " '000112847-1_1_1',\n",
       " '000113396-1_1_1',\n",
       " '212003216-1_1_1',\n",
       " '000123595-1_1_2',\n",
       " '000125388-1_1_1',\n",
       " '110000073-1_1_1',\n",
       " '211003217-1_3_2',\n",
       " '000122639-1_1_1',\n",
       " '220001113-1_8_1',\n",
       " '230005675-1_2_1',\n",
       " '000125471-1_1_1',\n",
       " '220000211-1_2_1',\n",
       " '211005621-1_5_1',\n",
       " '211008185-1_1_2',\n",
       " '000107955-1_1_2',\n",
       " '210000302-1_7_1',\n",
       " '000117496-1_1_1',\n",
       " '000126828-1_1_2',\n",
       " '000140208-1_1_1',\n",
       " '220000129-1_1_2',\n",
       " '000116932-1_1_1',\n",
       " '150203162-1_1_1',\n",
       " '211005209-1_1_1',\n",
       " '212001548-1_2_1',\n",
       " '000112024-1_1_1',\n",
       " '220000012-1_2_1',\n",
       " '230005447-1_1_1',\n",
       " '230006550-1_1_1',\n",
       " '100500956-1_2_2',\n",
       " '220014536-1_1_2',\n",
       " '100029215-1_1_1',\n",
       " '000109130-1_1_1',\n",
       " '211004447-1_1_2',\n",
       " '220010145-1_2_2',\n",
       " '000123112-1_1_1',\n",
       " '170000292-1_1_1',\n",
       " '180000194-1_1_1',\n",
       " '100198368-1_1_1',\n",
       " '000101997-1_1_1',\n",
       " '000101549-1_1_1',\n",
       " '230006328-1_1_2',\n",
       " '201009308-1_67_2',\n",
       " '211003703-1_1_1',\n",
       " '000107987-1_1_1',\n",
       " '201009200-1_4_2',\n",
       " '000104406-1_1_1',\n",
       " '201009318-1_55_2',\n",
       " '150200803-1_1_1',\n",
       " '211010571-1_1_2',\n",
       " '000109498-1_1_1',\n",
       " '000104917-1_1_1',\n",
       " '000120614-1_1_1',\n",
       " '230000099-1_25_1',\n",
       " '200044188-1_1_1',\n",
       " '000119333-1_1_1',\n",
       " '220001230-1_3_1',\n",
       " '201001608-1_1_1',\n",
       " '201008060-1_1_2',\n",
       " '220016924-1_11_1',\n",
       " '230003660-1_3_1',\n",
       " '201002464-1_3_2',\n",
       " '220014396-1_1_1',\n",
       " '000126376-1_1_1',\n",
       " '000131042-1_2_1',\n",
       " '000130087-1_1_1',\n",
       " '000102517-1_1_1',\n",
       " '100030606-1_6_1',\n",
       " '201001552-1_1_1',\n",
       " '211003368-1_5_1',\n",
       " '230005102-1_3_1',\n",
       " '230000158-1_1_1',\n",
       " '230002750-1_2_1',\n",
       " '000135714-1_1_1',\n",
       " '000101619-1_1_1',\n",
       " '230004170-1_1_1',\n",
       " '000112579-1_1_1',\n",
       " '201003261-1_1_1',\n",
       " '000112806-1_1_1',\n",
       " '000130461-1_1_1',\n",
       " '225001862-1_1_2',\n",
       " '000119212-1_1_2',\n",
       " '000115962-1_1_2',\n",
       " '201007015-1_5_2',\n",
       " '000108661-1_1_1',\n",
       " '000117941-1_1_1',\n",
       " '211003087-1_4_1',\n",
       " '000122815-1_1_2',\n",
       " '000114219-1_1_1',\n",
       " '000130538-1_1_2',\n",
       " '000106215-1_1_1',\n",
       " '201009232-1_2_1',\n",
       " '110000584-1_1_1',\n",
       " '000132944-1_3_1',\n",
       " '000125441-1_1_1',\n",
       " '211004874-1_3_2',\n",
       " '220034810-1_5_2',\n",
       " '000125460-1_1_1',\n",
       " '220000477-1_1_1',\n",
       " '000101180-1_1_2',\n",
       " '211004179-1_1_1',\n",
       " '201005281-1_1_1',\n",
       " '000112868-1_3_2',\n",
       " '000122169-1_2_1',\n",
       " '000116340-1_1_1',\n",
       " '220031795-1_1_2',\n",
       " '190014812-1_1_1',\n",
       " '000109809-1_2_2',\n",
       " '000114468-1_1_1',\n",
       " '000103755-1_1_1',\n",
       " '230000196-1_3_1',\n",
       " '000123293-1_1_1',\n",
       " '211005388-1_2_2',\n",
       " '220018497-1_1_1',\n",
       " '000105118-1_1_1',\n",
       " '100016829-1_1_1',\n",
       " '000142116-1_1_2',\n",
       " '190027339-1_1_1',\n",
       " '000108028-1_1_2',\n",
       " '211004759-1_5_1',\n",
       " '000108772-3_1_1',\n",
       " '000132028-1_2_2',\n",
       " '000137554-1_1_1',\n",
       " '110003167-1_4_1',\n",
       " '100017273-1_1_1',\n",
       " '150204952-1_1_1',\n",
       " '230001993-1_2_1',\n",
       " '000107865-1_2_1',\n",
       " '110002959-1_1_1',\n",
       " '000140606-1_1_2',\n",
       " '000139261-1_1_1',\n",
       " '000124718-1_1_1',\n",
       " '000108837-1_1_1',\n",
       " '225001707-1_1_1',\n",
       " '000131714-1_1_1',\n",
       " '000124331-1_1_1',\n",
       " '220001230-1_2_2',\n",
       " '100500997-1_2_3',\n",
       " '100028709-1_9_1',\n",
       " '000119332-1_1_1',\n",
       " '000114572-1_1_1',\n",
       " '000113162-1_1_1',\n",
       " '201005263-1_1_1',\n",
       " '211000109-1_2_1',\n",
       " '000125356-1_1_1',\n",
       " '230000686-1_1_1',\n",
       " '211008488-1_12_1',\n",
       " '201004202-1_1_1',\n",
       " '211001880-1_1_1',\n",
       " '201010274-1_1_1',\n",
       " '000110409-1_1_2',\n",
       " '000112227-1_1_1',\n",
       " '230004081-1_1_1',\n",
       " '000108936-1_1_1',\n",
       " '210000102-1_1_2',\n",
       " '230003017-1_1_2',\n",
       " '000127372-1_1_1',\n",
       " '000107434-1_1_1',\n",
       " '220016123-1_7_2',\n",
       " '220016913-1_41_2',\n",
       " '211007092-1_7_2',\n",
       " '211008437-1_48_2',\n",
       " '201002886-1_1_2',\n",
       " '201003440-1_1_1',\n",
       " '230003401-1_6_1',\n",
       " '000121454-1_1_2',\n",
       " '000106298-1_1_1',\n",
       " '201009259-1_23_2',\n",
       " '190005330-1_1_1',\n",
       " '100015718-1_2_1',\n",
       " '201002375-1_1_1',\n",
       " '000102990-1_1_1',\n",
       " '000136049-1_1_1',\n",
       " '000137650-1_2_2',\n",
       " '000123375-1_1_1',\n",
       " '000140473-1_1_1',\n",
       " '220015683-1_1_1',\n",
       " '000112448-1_1_1',\n",
       " '000135375-1_1_1',\n",
       " '200021789-1_10_2',\n",
       " '000106868-1_2_1',\n",
       " '220034192-1_5_1',\n",
       " '150204398-1_1_1',\n",
       " '211007223-1_6_1',\n",
       " '211004468-1_1_2',\n",
       " '000141812-1_1_2',\n",
       " '212000015-1_1_1',\n",
       " '000110177-1_1_1',\n",
       " '201002392-1_5_2',\n",
       " '000120702-1_1_2',\n",
       " '210022096-1_5_1',\n",
       " '000116622-1_1_1',\n",
       " '150205899-1_1_1',\n",
       " '000125657-1_1_2',\n",
       " '211005324-1_4_1',\n",
       " '220010678-1_1_1',\n",
       " '220030769-1_1_1',\n",
       " '000118218-1_1_1',\n",
       " '000116899-1_1_2',\n",
       " '000101170-1_1_1',\n",
       " '000110378-1_1_2',\n",
       " '000116372-1_2_1',\n",
       " '000112352-1_1_1',\n",
       " '210045594-1_2_1',\n",
       " '100500598-1_2_3',\n",
       " '000112942-1_1_1',\n",
       " '211005421-1_4_1',\n",
       " '212002941-1_1_1',\n",
       " '100016129-1_1_1',\n",
       " '110003603-1_1_2',\n",
       " '220001400-1_1_1',\n",
       " '000104189-1_1_1',\n",
       " '220011005-1_4_1',\n",
       " '000109671-1_1_1',\n",
       " '000136335-1_1_1',\n",
       " '220016913-1_10_2',\n",
       " '000107943-1_1_1',\n",
       " '211008440-1_30_1',\n",
       " '000132641-1_1_2',\n",
       " '000140601-1_1_1',\n",
       " '000116608-1_1_1',\n",
       " '000131600-1_1_2',\n",
       " '230000927-1_1_1',\n",
       " '190017457-1_1_1',\n",
       " '150200088-1_1_1',\n",
       " '230005074-1_8_2',\n",
       " '000120523-1_1_2',\n",
       " '000133038-1_1_2',\n",
       " '000101370-1_1_1',\n",
       " '220000427-1_1_1',\n",
       " '140000110-1_1_1',\n",
       " '000102868-1_1_1',\n",
       " '220010515-1_2_1',\n",
       " '000105932-1_1_1',\n",
       " '000130340-1_2_1',\n",
       " '230003696-1_1_1',\n",
       " '210097473-1_16_1',\n",
       " '210097428-1_1_1',\n",
       " '220034543-1_1_1',\n",
       " '000111256-1_1_1',\n",
       " '220032133-1_1_2',\n",
       " '000130790-1_1_2',\n",
       " '000102334-1_1_1',\n",
       " '220010184-1_5_1',\n",
       " '000109892-1_1_1',\n",
       " '000102996-1_1_1',\n",
       " '230002202-1_3_2',\n",
       " '220000993-1_3_1',\n",
       " '000110840-1_1_1',\n",
       " '201004834-1_1_1',\n",
       " '211002814-1_1_1',\n",
       " '000120261-1_1_2',\n",
       " '000113255-1_1_1',\n",
       " '211004299-1_3_1',\n",
       " '211010510-1_1_1',\n",
       " '220017450-1_9_1',\n",
       " '000101229-1_2_2',\n",
       " '220018352-1_1_1',\n",
       " '211005424-1_1_2',\n",
       " '000108632-1_1_1',\n",
       " '220014808-1_1_1',\n",
       " '211006124-1_1_1',\n",
       " '000102007-1_1_1',\n",
       " '110003033-1_1_1',\n",
       " '000106321-1_1_1',\n",
       " '000115770-1_1_1',\n",
       " '211004425-1_2_1',\n",
       " '212003714-1_2_1',\n",
       " '150200119-1_1_1',\n",
       " '100016044-1_1_1',\n",
       " '150201004-1_1_1',\n",
       " '000104443-1_1_1',\n",
       " '220013177-1_1_1',\n",
       " '220000305-1_6_1',\n",
       " '000114814-1_2_2',\n",
       " '000121398-1_1_2',\n",
       " '150205976-1_1_1',\n",
       " '211001896-1_2_1',\n",
       " '190005954-1_1_1',\n",
       " '000125147-1_1_1',\n",
       " '000140483-1_1_1',\n",
       " '220015055-1_1_1',\n",
       " '000101881-1_1_2',\n",
       " '000110964-1_1_1',\n",
       " '150203727-1_1_1',\n",
       " '211004785-1_2_1',\n",
       " '000130355-1_1_1',\n",
       " '190005058-1_1_1',\n",
       " '201008547-1_1_1',\n",
       " '201000098-1_1_1',\n",
       " '000122880-1_1_1',\n",
       " '000104304-1_1_1',\n",
       " '000108137-1_1_2',\n",
       " '150205392-1_1_1',\n",
       " '211010410-1_39_1',\n",
       " '190009666-1_1_1',\n",
       " '170000214-1_1_1',\n",
       " '100015911-1_2_1',\n",
       " '211008253-1_11_1',\n",
       " '220014898-1_1_1',\n",
       " '200039464-1_2_1',\n",
       " '211000202-1_1_1',\n",
       " '000100379-1_2_1',\n",
       " '211008131-1_1_1',\n",
       " '000109703-1_1_1',\n",
       " '000106778-1_1_1',\n",
       " '190004661-1_1_2',\n",
       " '000115607-1_1_1',\n",
       " '000135384-1_1_1',\n",
       " '220010591-1_4_2',\n",
       " '000115897-1_1_2',\n",
       " '000114269-1_1_1',\n",
       " '201002423-1_1_2',\n",
       " '230000164-1_9_1',\n",
       " '211004522-1_7_1',\n",
       " '190024144-1_1_1',\n",
       " '211003538-1_3_1',\n",
       " '000126756-1_1_1',\n",
       " '160000134-1_1_1',\n",
       " '210000130-1_1_1',\n",
       " '190024186-1_1_1',\n",
       " '000122792-1_1_2',\n",
       " '201004256-1_9_1',\n",
       " '000124556-1_1_1',\n",
       " '100030292-1_1_1',\n",
       " '212003726-1_2_1',\n",
       " '000126911-1_1_1',\n",
       " '220015945-1_1_1',\n",
       " '000122966-1_1_1',\n",
       " '100029620-1_1_1',\n",
       " '000113563-1_1_1',\n",
       " '110001827-1_1_1',\n",
       " '220011109-1_1_2',\n",
       " '000103743-1_1_1',\n",
       " '100500951-1_1_2',\n",
       " '000126885-1_1_2',\n",
       " '190026625-1_1_1',\n",
       " '220017472-1_4_1',\n",
       " '000122187-1_1_1',\n",
       " '000104014-1_2_1',\n",
       " '211003726-1_1_1',\n",
       " '230005391-1_1_1',\n",
       " '211002526-1_1_1',\n",
       " '000105605-1_1_1',\n",
       " '220011023-1_2_1',\n",
       " '000118654-1_1_1',\n",
       " '000107646-1_2_1',\n",
       " '150203295-1_1_1',\n",
       " '190012128-1_1_1',\n",
       " '220010589-1_3_1',\n",
       " '000128853-1_2_1',\n",
       " '212003076-1_1_1',\n",
       " '211002631-1_1_1',\n",
       " '212003631-1_4_1',\n",
       " '000138689-1_1_1',\n",
       " '200043755-1_20_1',\n",
       " '000114324-1_1_1',\n",
       " '230005884-1_2_1',\n",
       " '201004977-1_2_1',\n",
       " '190014493-1_1_1',\n",
       " '211006771-1_1_1',\n",
       " '230002485-1_2_1',\n",
       " '100016433-1_2_1',\n",
       " '211010448-1_3_1',\n",
       " '000121546-1_1_1',\n",
       " '000125732-1_1_1',\n",
       " '000128400-1_2_1',\n",
       " '000132083-1_2_1',\n",
       " '220031597-1_4_1',\n",
       " '000140852-1_1_1',\n",
       " '110001200-1_1_1',\n",
       " '190003544-1_1_1',\n",
       " '000124346-1_1_1',\n",
       " '000136873-1_7_1',\n",
       " '000107442-1_1_1',\n",
       " '230003277-1_2_1',\n",
       " '000118404-1_2_2',\n",
       " '000127224-1_1_1',\n",
       " '000113180-1_1_1',\n",
       " '190023126-1_1_1',\n",
       " '201007161-1_24_1',\n",
       " '000117341-1_1_1',\n",
       " '201009257-1_55_1',\n",
       " '190024345-1_1_1',\n",
       " '211001817-1_3_1',\n",
       " '220000223-1_2_1',\n",
       " '220016890-1_8_2',\n",
       " '000102196-1_2_1',\n",
       " '000116286-13_1_1',\n",
       " '000137169-1_1_1',\n",
       " '000112469-1_1_1',\n",
       " '190014619-1_1_1',\n",
       " '000121190-1_1_2',\n",
       " '000118853-1_1_1',\n",
       " '150202959-1_1_2',\n",
       " '190001037-1_1_1',\n",
       " '211010129-1_10_1',\n",
       " '200020893-1_1_1',\n",
       " '230001387-1_1_1',\n",
       " '230000892-1_1_1',\n",
       " '000122073-1_1_2',\n",
       " '000108563-1_2_1',\n",
       " '220013346-1_3_1',\n",
       " '201007034-1_2_1',\n",
       " '190014415-1_1_1',\n",
       " '190013895-1_1_1',\n",
       " '220001305-1_1_2',\n",
       " '190014111-1_1_1',\n",
       " '150205044-2_1_1',\n",
       " '000107878-1_1_1',\n",
       " '000130816-1_1_1',\n",
       " '201007016-1_2_2',\n",
       " '000132533-1_1_1',\n",
       " '211005980-1_1_1',\n",
       " '000107567-1_1_1',\n",
       " '220034102-1_3_1',\n",
       " '000140838-1_1_2',\n",
       " '212002981-1_1_1',\n",
       " '212001299-1_3_1',\n",
       " '000115061-1_1_1',\n",
       " '220034022-1_6_1',\n",
       " '000113749-1_1_1',\n",
       " '211003842-1_1_2',\n",
       " '201004660-1_4_2',\n",
       " '000122098-1_1_2',\n",
       " '190022126-1_1_1',\n",
       " '201004188-1_5_1',\n",
       " '220018275-1_1_1',\n",
       " '211004842-1_1_1',\n",
       " '211005501-1_4_1',\n",
       " '220017351-1_5_1',\n",
       " '211010170-1_2_1',\n",
       " '100501192-1_2_1',\n",
       " '110002244-1_1_2',\n",
       " '000138913-1_1_2',\n",
       " '110002958-1_66_1',\n",
       " '200044259-1_1_1',\n",
       " '220001526-1_1_1',\n",
       " '211004298-1_2_1',\n",
       " '225001152-1_1_1',\n",
       " '170000092-1_1_1',\n",
       " '000135229-1_1_1',\n",
       " '000117833-1_1_1',\n",
       " '211005251-1_1_1',\n",
       " '100198491-1_1_1',\n",
       " '212001905-1_4_1',\n",
       " '210097099-1_5_1',\n",
       " '000131772-1_1_1',\n",
       " '190005768-1_1_1',\n",
       " '212003611-1_1_1',\n",
       " '000127428-1_1_1',\n",
       " '000108877-1_1_1',\n",
       " '000138498-1_3_1',\n",
       " '000121803-1_1_1',\n",
       " '211000332-1_1_1',\n",
       " '000140579-1_3_1',\n",
       " '201004265-1_1_1',\n",
       " '000122340-1_1_1',\n",
       " '200044668-1_42_2',\n",
       " '000124752-1_1_1',\n",
       " '220010566-1_1_1',\n",
       " '212001892-1_4_1',\n",
       " '220018798-1_1_1',\n",
       " '100016538-1_1_1',\n",
       " '000140179-1_1_1',\n",
       " '000109539-1_1_1',\n",
       " '000125567-1_1_1',\n",
       " '000130439-1_1_1',\n",
       " '000123996-1_1_1',\n",
       " '000124519-1_1_1',\n",
       " '220019702-1_1_1',\n",
       " '190001835-1_1_1',\n",
       " '000128392-1_1_1',\n",
       " '211004343-1_1_2',\n",
       " '000102600-1_1_1',\n",
       " '201004292-1_1_1',\n",
       " '000106425-1_1_1',\n",
       " '000101476-1_2_1',\n",
       " '000119194-1_1_2',\n",
       " '211004870-1_5_1',\n",
       " '000120720-1_2_2',\n",
       " '000108382-1_1_2',\n",
       " '000103661-1_1_1',\n",
       " '000123954-1_1_2',\n",
       " '200043718-1_22_1',\n",
       " '000138463-1_2_1',\n",
       " '230001505-1_1_1',\n",
       " '000123199-1_1_1',\n",
       " '000112926-1_1_1',\n",
       " '212003209-1_3_1',\n",
       " '000114792-1_1_1',\n",
       " '150201011-1_1_1',\n",
       " '211004521-1_5_2',\n",
       " '000132014-1_1_1',\n",
       " '220000831-1_5_1',\n",
       " '220017014-1_16_1',\n",
       " '150203120-1_1_1',\n",
       " '230004559-1_1_1',\n",
       " '225001739-1_3_1',\n",
       " '000141142-1_1_1',\n",
       " '000100111-1_1_1',\n",
       " '220016971-1_1_1',\n",
       " '212001218-1_2_1',\n",
       " '220019324-1_1_1',\n",
       " '000137085-1_1_1',\n",
       " '000128290-1_1_1',\n",
       " '201007052-1_4_1',\n",
       " '000100299-1_1_1',\n",
       " '211006359-1_1_1',\n",
       " '000115864-1_1_1',\n",
       " '000123838-1_1_1',\n",
       " '220015514-1_1_1',\n",
       " '000100604-1_2_2',\n",
       " '230002366-1_4_2',\n",
       " '000103779-1_1_1',\n",
       " '000125088-17_1_1',\n",
       " '000111835-1_2_1',\n",
       " '100029578-1_1_1',\n",
       " '220014860-1_1_2',\n",
       " '000126837-1_1_1',\n",
       " '000141563-1_1_1',\n",
       " '190018046-1_1_1',\n",
       " '000140114-1_3_1',\n",
       " '230003609-1_4_1',\n",
       " '201002901-1_2_2',\n",
       " '212001239-1_3_1',\n",
       " '000100964-1_1_1',\n",
       " '000103842-1_1_1',\n",
       " '000103483-1_1_1',\n",
       " '211002166-1_1_1',\n",
       " '201001180-1_1_1',\n",
       " '100501138-1_1_2',\n",
       " '000135924-1_1_1',\n",
       " '220017872-1_1_1',\n",
       " '000126479-1_2_1',\n",
       " '150207073-1_1_1',\n",
       " '000112204-1_1_1',\n",
       " '230005102-1_5_1',\n",
       " '220010212-1_1_2',\n",
       " '220034812-1_6_2',\n",
       " '000135754-1_2_1',\n",
       " '000111116-1_1_1',\n",
       " '150202721-1_1_1',\n",
       " '000123158-1_1_1',\n",
       " '000119599-1_1_1',\n",
       " '220030519-1_1_2',\n",
       " '201007161-1_33_1',\n",
       " '000111424-1_2_1',\n",
       " '000128925-1_1_1',\n",
       " '110002384-3_1_1',\n",
       " '201002716-1_1_1',\n",
       " '000117503-1_1_1',\n",
       " '211004884-1_6_2',\n",
       " '000127871-1_1_2',\n",
       " '190001669-1_1_1',\n",
       " '120000104-1_7_1',\n",
       " '225001308-1_1_1',\n",
       " '000120712-1_1_1',\n",
       " '000112054-1_1_1',\n",
       " '100017141-1_1_1',\n",
       " '212003752-1_1_1',\n",
       " '220018445-1_1_1',\n",
       " '220010822-1_7_1',\n",
       " '000112325-1_1_1',\n",
       " '211003882-1_12_1',\n",
       " '212001395-1_3_1',\n",
       " '220015397-1_1_1',\n",
       " '000117296-1_1_2',\n",
       " '230002224-1_1_2',\n",
       " '000114318-1_1_1',\n",
       " '000122833-1_1_2',\n",
       " '230006128-1_1_1',\n",
       " '000116344-1_1_1',\n",
       " '000118229-1_1_1',\n",
       " '000140739-1_3_1',\n",
       " '211002969-1_5_1',\n",
       " '201004228-1_1_1',\n",
       " '201002081-1_1_2',\n",
       " '000135667-1_3_1',\n",
       " '220034070-1_1_1',\n",
       " '225000009-1_2_1',\n",
       " '000101006-1_1_2',\n",
       " '000128062-1_1_1',\n",
       " '100500772-1_2_1',\n",
       " '000109853-1_1_2',\n",
       " '000132948-1_6_1',\n",
       " '000116849-2_1_1',\n",
       " '212002052-1_2_1',\n",
       " '000106546-1_1_1',\n",
       " '000123045-1_1_2',\n",
       " '000107033-1_15_2',\n",
       " '220013283-1_1_1',\n",
       " '000114652-1_1_2',\n",
       " '000125402-1_1_1',\n",
       " '211005544-1_7_1',\n",
       " '000120635-1_1_1',\n",
       " '000110535-1_2_1',\n",
       " '000119294-1_1_1',\n",
       " '000111708-1_3_1',\n",
       " '000137460-1_1_1',\n",
       " '211003759-1_1_1',\n",
       " '000112141-1_1_1',\n",
       " '000101975-1_1_2',\n",
       " '211004449-1_1_1',\n",
       " '000128914-1_9_1',\n",
       " '190100769-1_1_1',\n",
       " '190021936-1_1_1',\n",
       " '190024273-1_1_1',\n",
       " '212002802-1_4_1',\n",
       " '211005307-1_14_1',\n",
       " '000108891-1_1_1',\n",
       " '000107782-1_2_1',\n",
       " '000107223-1_1_1',\n",
       " '220011042-1_1_1',\n",
       " '000116593-3_1_1',\n",
       " '211004343-1_10_2',\n",
       " '100015377-1_1_1',\n",
       " '000100272-1_1_1',\n",
       " '230000097-1_16_2',\n",
       " '225002050-1_4_1',\n",
       " '000140705-1_2_1',\n",
       " '220034370-1_2_1',\n",
       " '000112626-1_1_1',\n",
       " '000109905-1_1_1',\n",
       " '000111780-1_1_1',\n",
       " '230004894-1_2_1',\n",
       " '220010065-1_8_1',\n",
       " '230006415-1_1_1',\n",
       " '000124969-1_1_1',\n",
       " '000132097-1_1_1',\n",
       " '220010552-1_1_1',\n",
       " '201003531-1_1_1',\n",
       " '230000795-1_1_1',\n",
       " '000139275-1_1_1',\n",
       " '000108391-1_1_2',\n",
       " '220000243-1_1_1',\n",
       " '000109342-1_1_1',\n",
       " '000121224-5_1_1',\n",
       " '000126939-1_3_1',\n",
       " '000101254-1_1_1',\n",
       " '220020016-1_5_1',\n",
       " '000111355-1_1_1',\n",
       " '211010341-1_2_1',\n",
       " '100029697-1_1_1',\n",
       " '000107724-1_1_1',\n",
       " '220017043-1_3_1',\n",
       " '200022664-1_57_2',\n",
       " '211002398-1_1_1',\n",
       " '100501110-1_1_1',\n",
       " '220000601-1_3_1',\n",
       " '211007181-1_17_1',\n",
       " '000107032-11_1_2',\n",
       " '230006267-1_4_1',\n",
       " '211002065-1_1_1',\n",
       " '000111149-1_1_1',\n",
       " '000113197-1_1_1',\n",
       " '230006392-1_2_1',\n",
       " '150205293-1_1_1',\n",
       " '000112358-1_1_1',\n",
       " '100029613-1_3_1',\n",
       " '000120571-1_1_1',\n",
       " '180000123-1_1_1',\n",
       " '230005110-1_4_1',\n",
       " '230000092-1_4_1',\n",
       " '220011276-1_1_1',\n",
       " '000111010-1_1_1',\n",
       " '000140442-1_1_1',\n",
       " '230001140-1_2_1',\n",
       " '000103931-1_1_1',\n",
       " '000124941-1_1_1',\n",
       " '000113406-1_1_1',\n",
       " '220034009-1_5_1',\n",
       " '100016176-1_1_1',\n",
       " '220000444-1_1_1',\n",
       " '000100934-1_1_1',\n",
       " '000142094-1_2_1',\n",
       " '000105805-1_1_1',\n",
       " '000114600-1_1_1',\n",
       " '000102391-1_1_1',\n",
       " '000104336-1_1_1',\n",
       " '230000438-1_1_1',\n",
       " '000121393-1_1_2',\n",
       " '210000120-1_2_1',\n",
       " '211007216-1_20_1',\n",
       " '200021502-1_45_1',\n",
       " '000136406-1_1_1',\n",
       " '201008826-1_1_1',\n",
       " '230002018-1_5_1',\n",
       " '211004334-1_5_1',\n",
       " '211010031-1_1_1',\n",
       " '100016221-1_1_1',\n",
       " '150203594-1_1_1',\n",
       " '000121043-1_1_1',\n",
       " '000129084-1_1_1',\n",
       " '000107032-24_1_2',\n",
       " '000103783-1_1_1',\n",
       " '000123663-1_1_1',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "corpus = './Data/package'# PATH\n",
    "set = 'Data/train.txt' \n",
    "vocabulary = 'Data/vocabulary_semantic.txt'  \n",
    "save_model = './trained_\\semantic_model'\n",
    "\n",
    "primus = CTC_PriMuS(corpus, set, vocabulary, semantic = True, val_split = 0.1)\n",
    "primus.training_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "823f429c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/myranda/Documents/DSI/ML/OMR'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae0e1f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/package/000118390-1_1_2/000118390-1_1_2\n",
      "(155, 1639)\n"
     ]
    }
   ],
   "source": [
    "#IMAGE DEBUGGING\n",
    "sample_filepath = primus.training_list[0]\n",
    "sample_fullpath = corpus + '/' + sample_filepath + '/' + sample_filepath\n",
    "print(sample_fullpath)\n",
    "\n",
    "# Get image\n",
    "sample_img = cv2.imread(sample_fullpath + '.png', 0)\n",
    "print(sample_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d729f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "# IMAGE DEBUGGING - MPL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "PATH = './Data/package/' + sample_filepath + '/' + sample_filepath\n",
    "\n",
    "img = mpimg.imread(PATH + '.png')\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROP IMAGES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b454e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 128\n",
    "max_epochs = 1\n",
    "dropout = 0.5\n",
    "\n",
    "batch_size = 16\n",
    "vocabulary_size = primus.vocabulary_size\n",
    "model_cnn = cnn_model(batch_size)\n",
    "model_rnn = rnn_model(embed_size = 512, hidden_size = 512, vocab_size = primus.vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1088440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "\n",
    "learning_rate = 0.001\n",
    "criterion = torch.nn.CTCLoss()\n",
    "optimizer_cnn = optim.Adam(model_cnn.parameters(), lr = learning_rate) ## ADD MODEL PARAMS\n",
    "optimizer_rnn = optim.Adam(model_rnn.parameters(), lr = learning_rate)\n",
    "optimizer = optim.Adam(list(model_cnn.parameters()) + list(model_rnn.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e02315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d6430af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default params\n",
    "# With image height of 128, width will be 1870\n",
    "params = dict()\n",
    "params['img_height'] = img_height\n",
    "params['img_width'] = None\n",
    "params['batch_size'] = 16\n",
    "params['img_channels'] = 1\n",
    "params['conv_blocks'] = 4\n",
    "params['conv_filter_n'] = [32, 64, 128, 256]\n",
    "params['conv_filter_size'] = [ [3,3], [3,3], [3,3], [3,3] ]\n",
    "params['conv_pooling_size'] = [ [2,2], [2,2], [2,2], [2,2] ]\n",
    "params['rnn_units'] = 512\n",
    "params['rnn_layers'] = 2\n",
    "params['vocabulary_size'] = vocabulary_size\n",
    "params['max_width'] = 1500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bfc69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape for CTC loss\n",
    "input_shape = (None, params['img_height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8a60b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 128, 2153, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aac1d6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 2417, 1])\n",
      "torch.Size([16, 64, 14, 300])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (14336x300 and 896x2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27213/1342245661.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#features = torch.permute(output, (3, 0, 2, 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#features = torch.reshape(features, (16, features.shape[0], 64 * 14)) # width, batch, features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moutput_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#Input and target shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_27213/1962396934.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, input_size)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m         )\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (14336x300 and 896x2048)"
     ]
    }
   ],
   "source": [
    "# Train using model_rnn\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    \n",
    "    train_acc = 0.\n",
    "    valid_acc = 0.\n",
    "    \n",
    "    for i in range(0, 70880 + 7875, 16):\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs']\n",
    "\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        output = model_cnn(tensor_data_reshape)\n",
    "        print(output.shape)\n",
    "        #output_size = 64 * 14 * output.shape[3]\n",
    "        output_size = output.shape[3]\n",
    "        # Reshape output for RNN\n",
    "        output = output.view(output.size(0), output.size(3), -1)\n",
    "        output = output.permute(0,2,1)\n",
    "        #features = torch.permute(output, (3, 0, 2, 1))\n",
    "        #features = torch.reshape(features, (16, features.shape[0], 64 * 14)) # width, batch, features\n",
    "        output_rnn = model_rnn(output, input_size = 64*14)\n",
    "        \n",
    "        #Input and target shape\n",
    "        input_shape = (None, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        target_shape = batch['seq_lengths']\n",
    "        \n",
    "        loss = criterion(output, targets, input_shape, target_shape)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Calc loss\n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0 # ADD ACCURACY\n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5411d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE BATCH SIZE ALL IMAGES TO KEEP WIDTHS THE SAME\n",
    "# Train using model_rnn\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    \n",
    "    train_acc = 0.\n",
    "    valid_acc = 0.\n",
    "    \n",
    "    for i in range(0, 70880 + 7875, 16):\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs']\n",
    "\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        output = model_cnn(tensor_data_reshape)\n",
    "        print(output.shape)\n",
    "        #output_size = 64 * 14 * output.shape[3]\n",
    "        output_size = output.shape[3]\n",
    "        # Reshape output for RNN\n",
    "        output = output.view(output.size(0), output.size(3), -1)\n",
    "        output = output.permute(0,2,1)\n",
    "        #features = torch.permute(output, (3, 0, 2, 1))\n",
    "        #features = torch.reshape(features, (16, features.shape[0], 64 * 14)) # width, batch, features\n",
    "        output_rnn = model_rnn(output, input_size = 64*14)\n",
    "        \n",
    "        #Input and target shape\n",
    "        input_shape = (None, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        target_shape = batch['seq_lengths']\n",
    "        \n",
    "        loss = criterion(output, targets, input_shape, target_shape)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Calc loss\n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0 # ADD ACCURACY\n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b9c4d355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14336/896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6cfba3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BasicRNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3405/265409066.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mN_INPUTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m896\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mbasic_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_INPUTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_NEURONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_OUTPUTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlen_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BasicRNN' is not defined"
     ]
    }
   ],
   "source": [
    "# Train using Basic RNN\n",
    "\n",
    "# Setup\n",
    "BATCH_SIZE = 16\n",
    "IMG_HEIGHT = img_height\n",
    "N_EPOCHS = 1\n",
    "N_OUTPUTS = vocabulary_size + 1\n",
    "N_NEURONS = 512\n",
    "#N_INPUTS = 512\n",
    "N_INPUTS = 896\n",
    "model_cnn = cnn_model(BATCH_SIZE)\n",
    "basic_rnn = BasicRNN(BATCH_SIZE, 1, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
    "optimizer = optim.Adam(list(model_cnn.parameters()) + list(basic_rnn.parameters()))\n",
    "len_data = len(primus.training_list) + len(primus.validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57ff5bbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 14, 230])\n",
      "torch.Size([14, 230])\n",
      "torch.Size([230, 16, 896])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27213/2840740796.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# width, batch, features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mrnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq_lengths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_27213/135853732.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#lstm_out, self.hidden = self.basic_rnn(X, self.hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    model_cnn.train()\n",
    "    basic_rnn.train()\n",
    "    \n",
    "    for i in range(0, len_data, BATCH_SIZE):\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        basic_rnn.hidden = basic_rnn.init_hidden()\n",
    "        \n",
    "        # Get inputs\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs'] # size (batch, height, width, channels)\n",
    "        #print(data)\n",
    "        #print(data.shape)\n",
    "        max_input_length = data.shape[2]\n",
    "        \n",
    "        # list of indices, values, shape\n",
    "        seq_len = int(batch['seq_lengths'][0])\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        #print(tuple(targets[2]))\n",
    "        #print(type(t[0]) for t in targets)\n",
    "        #targets = torch.sparse_coo_tensor(targets[0], targets[1], tuple(targets[2]))\n",
    "        targets_0 = torch.as_tensor((targets[0]))\n",
    "        #print(targets.shape)\n",
    "        #targets = torch.reshape(targets, (16, 1))\n",
    "        padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=max_input_length)\n",
    "        padded_targets_tensor = torch.tensor(padded_targets)\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        #print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        # forward, backward, optim\n",
    "        cnn_output = model_cnn(tensor_data_reshape)\n",
    "        output_size = 64 * 14 * cnn_output.shape[3]\n",
    "        #print(cnn_output.shape)\n",
    "        #print(cnn_output[0])\n",
    "        print(cnn_output[0].shape)\n",
    "        print(cnn_output[0][0].shape)\n",
    "        \n",
    "        # Change shape for rnn\n",
    "        output = torch.reshape(cnn_output, (cnn_output.shape[3], 16, 64 * 14)) # width, batch, features\n",
    "        print(output.shape)\n",
    "        rnn_output = basic_rnn(output)\n",
    "        print(rnn_output[0].shape)\n",
    "        print(batch['seq_lengths'])\n",
    "        \n",
    "        #rnn_output_reshape = torch.reshape(rnn_output, (cnn_output[0].shape[2], BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = torch.reshape(rnn_output[0], (1, BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = rnn_output[0].view(-1, BATCH_SIZE, N_OUTPUTS)\n",
    "        \n",
    "        \n",
    "        log_probs = nn.functional.log_softmax(rnn_output)\n",
    "        #Input and target shape\n",
    "        #print(rnn_output_reshape.shape)\n",
    "        input_shape = (BATCH_SIZE, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        input_len = tuple([1 for i in range (0, BATCH_SIZE)])\n",
    "        #print(input_shape)\n",
    "        target_shape = tuple(int(b) for b in batch['seq_lengths'])\n",
    "        \n",
    "        # MUST BE TENSOR, TENSOR, TUPLE, TUPLE OR TENSOR TENSOR TENSOR TENSOR\n",
    "        #loss = criterion(rnn_output_reshape, padded_targets_tensor, input_len, target_shape)\n",
    "        #loss = criterion(log_probs, padded_targets_tensor, input_len, target_shape)\n",
    "        loss = criterion(log_probs, padded_targets_tensor, target_shape, tuple(lengths))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0\n",
    "        print(\"Loss: %f\", train_loss)\n",
    "        \n",
    "    #model.eval()\n",
    "    print('training loss:')\n",
    "    print(train_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "11b7aba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4a28be57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782.0"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28512/16\n",
    "# 16 times seq_len * n_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c1d7cf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128 * data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "92d2ff50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "df5cd8cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 26 at dim 1 (got 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7287/2267183817.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 26 at dim 1 (got 20)"
     ]
    }
   ],
   "source": [
    "torch.as_tensor(tuple(batch['targets']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "874aa002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 36, 24, 31, 21, 18, 27, 31, 15, 26, 26, 18, 17, 15, 18, 38])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=125)\n",
    "len(padded_targets)\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff4068c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 125])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(padded_targets).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "167e8b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.0000e+01, 2.3400e+02, 1.7790e+03, 1.5990e+03, 0.0000e+00, 1.0180e+03,\n",
       "          1.0180e+03, 1.0180e+03, 1.0180e+03, 1.6470e+03, 1.4830e+03, 1.2370e+03,\n",
       "          1.0360e+03, 0.0000e+00, 8.2300e+02, 6.0400e+02, 8.5300e+02, 4.0200e+02,\n",
       "          1.0180e+03, 6.0400e+02, 4.2600e+02, 1.6180e+03, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [7.0000e+00, 2.2800e+02, 1.7800e+03, 1.7220e+03, 9.8300e+02, 0.0000e+00,\n",
       "          9.8300e+02, 9.8300e+02, 0.0000e+00, 3.8100e+02, 5.6100e+02, 7.7900e+02,\n",
       "          0.0000e+00, 9.9200e+02, 7.9000e+02, 5.5600e+02, 0.0000e+00, 3.7400e+02,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.2900e+02, 1.7800e+03, 2.6600e+02, 0.0000e+00, 1.7270e+03,\n",
       "          1.5990e+03, 1.5990e+03, 8.2300e+02, 1.3030e+03, 1.0190e+03, 8.5300e+02,\n",
       "          0.0000e+00, 5.8100e+02, 1.5990e+03, 6.7800e+02, 8.2300e+02, 4.9000e+02,\n",
       "          1.5990e+03, 8.2400e+02, 1.0440e+03, 0.0000e+00, 5.9500e+02, 1.5990e+03,\n",
       "          1.5990e+03, 8.2300e+02, 1.3030e+03, 1.0190e+03, 1.4790e+03, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.3400e+02, 1.7570e+03, 5.6100e+02, 9.9200e+02, 1.6170e+03,\n",
       "          0.0000e+00, 1.1790e+03, 4.1800e+02, 0.0000e+00, 4.1800e+02, 1.6170e+03,\n",
       "          4.1800e+02, 0.0000e+00, 5.9000e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.3100e+02, 1.7790e+03, 4.3400e+02, 0.0000e+00, 4.3400e+02,\n",
       "          0.0000e+00, 4.3400e+02, 1.7410e+03, 0.0000e+00, 4.3400e+02, 0.0000e+00,\n",
       "          4.3400e+02, 0.0000e+00, 4.3400e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.2900e+02, 1.7800e+03, 1.7270e+03, 0.0000e+00, 2.6100e+02,\n",
       "          0.0000e+00, 1.3070e+03, 1.0360e+03, 8.4400e+02, 0.0000e+00, 8.2300e+02,\n",
       "          6.7800e+02, 6.8700e+02, 1.7220e+03, 0.0000e+00, 1.4610e+03, 1.3130e+03,\n",
       "          1.0360e+03, 0.0000e+00, 1.0180e+03, 8.2300e+02, 8.4400e+02, 1.7220e+03,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.3100e+02, 1.7790e+03, 2.6000e+02, 0.0000e+00, 8.3200e+02,\n",
       "          6.8200e+02, 0.0000e+00, 8.3200e+02, 1.0360e+03, 1.0360e+03, 0.0000e+00,\n",
       "          4.0800e+02, 4.1800e+02, 1.4260e+03, 0.0000e+00, 1.6060e+03, 1.4260e+03,\n",
       "          1.6170e+03, 0.0000e+00, 4.0800e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.2800e+02, 1.7800e+03, 1.0440e+03, 0.0000e+00, 1.0260e+03,\n",
       "          1.7410e+03, 1.0440e+03, 1.4330e+03, 1.6250e+03, 4.2600e+02, 6.0400e+02,\n",
       "          8.5100e+02, 1.0440e+03, 1.2320e+03, 0.0000e+00, 1.4590e+03, 1.7410e+03,\n",
       "          1.4770e+03, 4.2600e+02, 6.0400e+02, 8.5100e+02, 1.0440e+03, 1.2320e+03,\n",
       "          1.4770e+03, 1.6710e+03, 0.0000e+00, 4.4700e+02, 1.7410e+03, 4.4100e+02,\n",
       "          6.3100e+02, 4.6000e+02, 1.6710e+03, 1.4770e+03, 1.2320e+03, 1.0440e+03,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.2800e+02, 1.7570e+03, 6.2000e+02, 1.0750e+03, 8.8900e+02,\n",
       "          6.2000e+02, 6.2000e+02, 6.2000e+02, 6.2000e+02, 0.0000e+00, 6.2700e+02,\n",
       "          1.7270e+03, 1.7270e+03, 0.0000e+00, 8.7000e+02, 1.2520e+03, 8.8900e+02,\n",
       "          8.7000e+02, 8.7000e+02, 8.7000e+02, 8.7000e+02, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.2300e+02, 1.7510e+03, 1.4050e+03, 6.7800e+02, 1.4050e+03,\n",
       "          6.7800e+02, 0.0000e+00, 1.2400e+02, 8.5300e+02, 6.9200e+02, 8.5300e+02,\n",
       "          1.0440e+03, 8.4400e+02, 0.0000e+00, 1.4540e+03, 1.3030e+03, 8.2300e+02,\n",
       "          4.0200e+02, 0.0000e+00, 9.9000e+01, 6.9200e+02, 4.2600e+02, 6.9200e+02,\n",
       "          8.5300e+02, 6.8700e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [9.0000e+00, 2.3400e+02, 1.7570e+03, 1.6630e+03, 6.2700e+02, 6.3100e+02,\n",
       "          8.9100e+02, 1.0590e+03, 0.0000e+00, 6.2700e+02, 1.6630e+03, 4.5300e+02,\n",
       "          0.0000e+00, 6.2700e+02, 4.5300e+02, 1.6630e+03, 0.0000e+00, 1.4670e+03,\n",
       "          1.0360e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.2900e+02, 1.7510e+03, 2.8300e+02, 0.0000e+00, 1.3130e+03,\n",
       "          6.7900e+02, 6.9200e+02, 0.0000e+00, 1.6640e+03, 1.4790e+03, 1.3180e+03,\n",
       "          0.0000e+00, 8.2300e+02, 8.2300e+02, 1.7170e+03, 1.3030e+03, 0.0000e+00,\n",
       "          1.0360e+03, 1.7410e+03, 1.0440e+03, 5.1800e+02, 1.4790e+03, 1.0440e+03,\n",
       "          0.0000e+00, 1.3030e+03, 1.3030e+03, 1.7270e+03, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.2800e+02, 1.7510e+03, 1.0190e+03, 1.2320e+03, 1.4520e+03,\n",
       "          1.2320e+03, 0.0000e+00, 1.0180e+03, 4.0200e+02, 1.0180e+03, 1.7170e+03,\n",
       "          0.0000e+00, 1.4520e+03, 1.6710e+03, 4.4200e+02, 1.6710e+03, 0.0000e+00,\n",
       "          1.4510e+03, 1.0180e+03, 1.4510e+03, 1.7170e+03, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 1.7790e+03, 1.0270e+03, 8.4100e+02, 0.0000e+00, 1.0270e+03,\n",
       "          8.2300e+02, 5.8300e+02, 0.0000e+00, 8.3000e+02, 1.7270e+03, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [3.0000e+00, 1.7790e+03, 2.7200e+02, 0.0000e+00, 1.7220e+03, 1.7170e+03,\n",
       "          1.1740e+03, 4.0200e+02, 5.8300e+02, 0.0000e+00, 8.5300e+02, 4.2600e+02,\n",
       "          1.5960e+03, 4.2600e+02, 8.5300e+02, 5.8300e+02, 1.1740e+03, 1.7170e+03,\n",
       "          1.7270e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.2300e+02, 1.7800e+03, 2.6500e+02, 0.0000e+00, 1.7220e+03,\n",
       "          1.7270e+03, 1.6170e+03, 0.0000e+00, 8.2300e+02, 1.3030e+03, 1.0180e+03,\n",
       "          1.4540e+03, 1.3030e+03, 1.0180e+03, 0.0000e+00, 8.2300e+02, 6.7800e+02,\n",
       "          8.3200e+02, 6.7800e+02, 4.9000e+02, 0.0000e+00, 1.6170e+03, 1.4700e+03,\n",
       "          1.4700e+03, 1.0360e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " tensor([23, 18, 30, 15, 16, 25, 21, 37, 23, 27, 19, 29, 23, 11, 20, 27])]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_targets_list = [torch.tensor(padded_targets[i]) for i in range(0,len(padded_targets))]\n",
    "padded_targets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e491a1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29, 31, 23, 26, 37, 27, 22, 23, 13, 20, 20, 21, 17, 30, 24, 25])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "36ab3537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1743"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b683be28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1782])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7b5c5b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2c5bd16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1520"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(target_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca811e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "# num steps: IMAGE WIDTH\n",
    "# batch size 16\n",
    "# n_inputs 64 * 14 (from CNN output)\n",
    "# output of CNN: (64 by 14 by width) - width same across batch\n",
    "\n",
    "class ImageRNN(nn.Module):\n",
    "    def __init__(self, batch_size = 16, n_inputs = 896, n_neurons = 4, n_outputs = vocabulary_size +1): # N_ STEPS AFTER BATCH_SIZE\n",
    "        super(ImageRNN, self).__init__()\n",
    "        \n",
    "        self.n_neurons = n_neurons\n",
    "        #self.batch_size = batch_size\n",
    "        #self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n",
    "        \n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, batch_size, self.n_neurons))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        #X = X.permute(1, 0, 2) \n",
    "        # maybe batch size should be width\n",
    "        # each batch is 1 by 64 by 14\n",
    "        \n",
    "        self.batch_size = X.size(2)\n",
    "        self.hidden = self.init_hidden(self.batch_size)\n",
    "        \n",
    "        # try using a loop - delete this if it breaks\n",
    "        #lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
    "        #out = self.FC(self.hidden)\n",
    "        out = []\n",
    "        \n",
    "        for x in X:\n",
    "            lstm_out, self.hidden = self.basic_rnn(x, self.hidden)\n",
    "            out_step = self.FC(self.hidden)\n",
    "            out.append(out_step)\n",
    "            \n",
    "            \n",
    "        return out#.view(-1, self.n_outputs) # batch_size X n_output\n",
    "    #output represent log prob of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "207909e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 14, 252])\n",
      "torch.Size([14, 252])\n",
      "torch.Size([16, 1, 252, 896])\n",
      "torch.Size([1, 252, 1782])\n",
      "torch.Size([252, 1782])\n",
      "torch.Size([1782])\n",
      "[127.0625 127.0625 127.0625 127.0625 127.0625 127.0625 127.0625 127.0625\n",
      " 127.0625 127.0625 127.0625 127.0625 127.0625 127.0625 127.0625 127.0625]\n",
      "252\n",
      "(252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252, 252)\n",
      "torch.Size([252, 16, 1782])\n",
      "Loss: %f -9.19214916229248\n",
      "torch.Size([64, 14, 217])\n",
      "torch.Size([14, 217])\n",
      "torch.Size([16, 1, 217, 896])\n",
      "torch.Size([1, 217, 1782])\n",
      "torch.Size([217, 1782])\n",
      "torch.Size([1782])\n",
      "[109.6875 109.6875 109.6875 109.6875 109.6875 109.6875 109.6875 109.6875\n",
      " 109.6875 109.6875 109.6875 109.6875 109.6875 109.6875 109.6875 109.6875]\n",
      "217\n",
      "(217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217)\n",
      "torch.Size([217, 16, 1782])\n",
      "Loss: %f -17.41325283050537\n",
      "torch.Size([64, 14, 169])\n",
      "torch.Size([14, 169])\n",
      "torch.Size([16, 1, 169, 896])\n",
      "torch.Size([1, 169, 1782])\n",
      "torch.Size([169, 1782])\n",
      "torch.Size([1782])\n",
      "[85.5625 85.5625 85.5625 85.5625 85.5625 85.5625 85.5625 85.5625 85.5625\n",
      " 85.5625 85.5625 85.5625 85.5625 85.5625 85.5625 85.5625]\n",
      "169\n",
      "(169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169, 169)\n",
      "torch.Size([169, 16, 1782])\n",
      "Loss: %f -24.260910034179688\n",
      "torch.Size([64, 14, 217])\n",
      "torch.Size([14, 217])\n",
      "torch.Size([16, 1, 217, 896])\n",
      "torch.Size([1, 217, 1782])\n",
      "torch.Size([217, 1782])\n",
      "torch.Size([1782])\n",
      "[109.6875 109.6875 109.6875 109.6875 109.6875 109.6875 109.6875 109.6875\n",
      " 109.6875 109.6875 109.6875 109.6875 109.6875 109.6875 109.6875 109.6875]\n",
      "217\n",
      "(217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217, 217)\n",
      "torch.Size([217, 16, 1782])\n",
      "Loss: %f -32.26880359649658\n",
      "torch.Size([64, 14, 204])\n",
      "torch.Size([14, 204])\n",
      "torch.Size([16, 1, 204, 896])\n",
      "torch.Size([1, 204, 1782])\n",
      "torch.Size([204, 1782])\n",
      "torch.Size([1782])\n",
      "[103.3125 103.3125 103.3125 103.3125 103.3125 103.3125 103.3125 103.3125\n",
      " 103.3125 103.3125 103.3125 103.3125 103.3125 103.3125 103.3125 103.3125]\n",
      "204\n",
      "(204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204, 204)\n",
      "torch.Size([204, 16, 1782])\n",
      "Loss: %f -39.578590393066406\n",
      "torch.Size([64, 14, 250])\n",
      "torch.Size([14, 250])\n",
      "torch.Size([16, 1, 250, 896])\n",
      "torch.Size([1, 250, 1782])\n",
      "torch.Size([250, 1782])\n",
      "torch.Size([1782])\n",
      "[126.0625 126.0625 126.0625 126.0625 126.0625 126.0625 126.0625 126.0625\n",
      " 126.0625 126.0625 126.0625 126.0625 126.0625 126.0625 126.0625 126.0625]\n",
      "250\n",
      "(250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250)\n",
      "torch.Size([250, 16, 1782])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3405/4061597580.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m#loss = criterion(log_probs, padded_targets_tensor, input_len, target_shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_of_target_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train using ImageRNN\n",
    "\n",
    "# SETUP\n",
    "\n",
    "learning_rate = 0.000001\n",
    "criterion = torch.nn.CTCLoss()\n",
    "model_cnn = cnn_model(BATCH_SIZE)\n",
    "model_rnn = ImageRNN()\n",
    "optimizer = optim.Adam(list(model_cnn.parameters()) + list(model_rnn.parameters()), lr = learning_rate)\n",
    "len_data = len(primus.training_list) + len(primus.validation_list)\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    model_cnn.train()\n",
    "    model_rnn.train()\n",
    "    \n",
    "    for i in range(0, len_data, BATCH_SIZE):\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        # Get inputs\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs'] # size (batch, height, width, channels)\n",
    "        #print(data)\n",
    "        #print(data.shape)\n",
    "        max_input_length = data.shape[2]\n",
    "        \n",
    "        # list of indices, values, shape\n",
    "        seq_len = int(batch['seq_lengths'][0])\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        #print(tuple(targets[2]))\n",
    "        #print(type(t[0]) for t in targets)\n",
    "        #targets = torch.sparse_coo_tensor(targets[0], targets[1], tuple(targets[2]))\n",
    "        targets_0 = torch.as_tensor((targets[0]))\n",
    "        #print(targets.shape)\n",
    "        #targets = torch.reshape(targets, (16, 1))\n",
    "        padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=max_input_length)\n",
    "        padded_targets_tensor = torch.tensor(padded_targets)\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        #print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        # forward, backward, optim\n",
    "        cnn_output = model_cnn(tensor_data_reshape)\n",
    "        output_size = 64 * 14 * cnn_output.shape[3]\n",
    "        #print(cnn_output.shape)\n",
    "        #print(cnn_output[0])\n",
    "        print(cnn_output[0].shape)\n",
    "        print(cnn_output[0][0].shape)\n",
    "        \n",
    "        # Change shape for rnn\n",
    "        #output = torch.reshape(cnn_output, (cnn_output.shape[3], 16, 64 * 14)) # width, batch, features\n",
    "        \n",
    "        # SEE IF LOOP OVER OUTPUT\n",
    "        output = torch.reshape(cnn_output, (16, 1, cnn_output.shape[3], 64*14))\n",
    "        \n",
    "        print(output.shape)\n",
    "        \n",
    "        \n",
    "        # reset hidden states\n",
    "        model_rnn.hidden = model_rnn.init_hidden(BATCH_SIZE)\n",
    "        logits = model_rnn(output)\n",
    "        print(logits[0].shape) #1 by width by vocab size\n",
    "        print((logits[0][0].shape))\n",
    "        print(logits[0][0][0].shape) # this is logits for one column of picture\n",
    "        print(batch['seq_lengths'])\n",
    "        \n",
    "        for t in range(0,len(logits)):\n",
    "            logits[t] = torch.reshape(logits[t],(logits[t].size(1), logits[t].size(2)))\n",
    "        print(logits[0].shape[0])\n",
    "        \n",
    "        batch_size = logits[0].shape[0]\n",
    "        logits_tensor = torch.stack(logits)\n",
    "        logits_tensor = torch.permute(logits_tensor, (1,0,2))\n",
    "        \n",
    "        #rnn_output_reshape = torch.reshape(rnn_output, (cnn_output[0].shape[2], BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = torch.reshape(rnn_output[0], (1, BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = rnn_output[0].view(-1, BATCH_SIZE, N_OUTPUTS)\n",
    "        \n",
    "        # change targets to 1D tensor\n",
    "\n",
    "        list_of_target_tensors = []\n",
    "        lens = 0\n",
    "        for i in range(0,16):\n",
    "            list_of_target_tensors.append(torch.as_tensor(batch['targets'][i]))\n",
    "            lens += len(batch['targets'][i])\n",
    "        list_of_target_tensors\n",
    "        tensor_of_target_tensors = torch.cat(list_of_target_tensors)\n",
    "        #tensor_of_target_tensors.size() \n",
    "\n",
    "\n",
    "        #log_probs = nn.functional.log_softmax(rnn_output, dim=0)\n",
    "        #Input and target shape\n",
    "        #print(rnn_output_reshape.shape)\n",
    "        input_shape = (BATCH_SIZE, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        input_len = tuple([batch_size for i in range (0, 16)])\n",
    "        #print(input_shape)\n",
    "        print(input_len)\n",
    "        print(logits_tensor.shape)\n",
    "        target_shape = tuple(int(b) for b in batch['seq_lengths'])\n",
    "        \n",
    "        # MUST BE TENSOR, TENSOR, TUPLE, TUPLE OR TENSOR TENSOR TENSOR TENSOR\n",
    "        #loss = criterion(rnn_output_reshape, padded_targets_tensor, input_len, target_shape)\n",
    "        #loss = criterion(log_probs, padded_targets_tensor, input_len, target_shape)\n",
    "        loss = criterion(logits_tensor, tensor_of_target_tensors, input_len, tuple(lengths))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0\n",
    "        print(\"Loss: %f\", train_loss)\n",
    "        \n",
    "    #model.eval()\n",
    "    print('training loss:')\n",
    "    print(train_loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53649bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change targets to 1D tensor\n",
    "\n",
    "list_of_target_tensors = []\n",
    "lens = 0\n",
    "for i in range(0,16):\n",
    "    list_of_target_tensors.append(torch.as_tensor(batch['targets'][i]))\n",
    "    lens += len(batch['targets'][i])\n",
    "list_of_target_tensors\n",
    "tensor_of_target_tensors = torch.cat(list_of_target_tensors)\n",
    "tensor_of_target_tensors.size() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80261132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "40918e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([254, 16, 1782])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa615cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/myranda/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:106: UserWarning: \n",
      "NVIDIA GeForce RTX 3070 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-28c2ff9f7473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                         \u001b[0mnum_weights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                     torch._cudnn_rnn_flatten_weight(\n\u001b[0m\u001b[1;32m    176\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# Try to use GPU\n",
    "# Train using ImageRNN\n",
    "\n",
    "# SETUP\n",
    "model_cnn = cnn_model(BATCH_SIZE)\n",
    "model_rnn = ImageRNN()\n",
    "optimizer = optim.Adam(list(model_cnn.parameters()) + list(model_rnn.parameters()))\n",
    "len_data = len(primus.training_list) + len(primus.validation_list)\n",
    "\n",
    "model_cnn.to(device)\n",
    "model_rnn.to(device)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    model_cnn.train()\n",
    "    model_rnn.train()\n",
    "    \n",
    "    for i in range(0, len_data, BATCH_SIZE):\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        model_rnn.hidden = basic_rnn.init_hidden()\n",
    "        \n",
    "        # Get inputs\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs'] # size (batch, height, width, channels)\n",
    "        data = data.to(device)\n",
    "        #print(data)\n",
    "        #print(data.shape)\n",
    "        max_input_length = data.shape[2]\n",
    "        \n",
    "        # list of indices, values, shape\n",
    "        seq_len = int(batch['seq_lengths'][0])\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        #print(tuple(targets[2]))\n",
    "        #print(type(t[0]) for t in targets)\n",
    "        #targets = torch.sparse_coo_tensor(targets[0], targets[1], tuple(targets[2]))\n",
    "        targets_0 = torch.as_tensor((targets[0]))\n",
    "        #print(targets.shape)\n",
    "        #targets = torch.reshape(targets, (16, 1))\n",
    "        padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=max_input_length)\n",
    "        padded_targets_tensor = torch.tensor(padded_targets)\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        #print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        # forward, backward, optim\n",
    "        cnn_output = model_cnn(tensor_data_reshape)\n",
    "        output_size = 64 * 14 * cnn_output.shape[3]\n",
    "        #print(cnn_output.shape)\n",
    "        #print(cnn_output[0])\n",
    "        print(cnn_output[0].shape)\n",
    "        print(cnn_output[0][0].shape)\n",
    "        \n",
    "        # Change shape for rnn\n",
    "        #output = torch.reshape(cnn_output, (cnn_output.shape[3], 16, 64 * 14)) # width, batch, features\n",
    "        \n",
    "        # SEE IF LOOP OVER OUTPUT\n",
    "        output = torch.reshape(cnn_output, (16, 1, cnn_output.shape[3], 64*14))\n",
    "        \n",
    "        print(output.shape)\n",
    "        logits = model_rnn(output)\n",
    "        print(logits[0].shape) #1 by width by vocab size\n",
    "        print((logits[0][0].shape))\n",
    "        print(logits[0][0][0].shape) # this is logits for one column of picture\n",
    "        print(batch['seq_lengths'])\n",
    "        \n",
    "        for t in range(0,len(logits)):\n",
    "            logits[t] = torch.reshape(logits[t],(logits[t].size(1), logits[t].size(2)))\n",
    "        print(logits[0].shape[0])\n",
    "        \n",
    "        batch_size = logits[0].shape[0]\n",
    "        logits_tensor = torch.stack(logits)\n",
    "        logits_tensor = torch.permute(logits_tensor, (1,0,2))\n",
    "        \n",
    "        #rnn_output_reshape = torch.reshape(rnn_output, (cnn_output[0].shape[2], BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = torch.reshape(rnn_output[0], (1, BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = rnn_output[0].view(-1, BATCH_SIZE, N_OUTPUTS)\n",
    "        \n",
    "        \n",
    "        #log_probs = nn.functional.log_softmax(rnn_output, dim=0)\n",
    "        #Input and target shape\n",
    "        #print(rnn_output_reshape.shape)\n",
    "        input_shape = (BATCH_SIZE, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        input_len = tuple([batch_size for i in range (0, 16)])\n",
    "        #print(input_shape)\n",
    "        print(input_len)\n",
    "        print(logits_tensor.shape)\n",
    "        target_shape = tuple(int(b) for b in batch['seq_lengths'])\n",
    "        \n",
    "        # MUST BE TENSOR, TENSOR, TUPLE, TUPLE OR TENSOR TENSOR TENSOR TENSOR\n",
    "        #loss = criterion(rnn_output_reshape, padded_targets_tensor, input_len, target_shape)\n",
    "        #loss = criterion(log_probs, padded_targets_tensor, input_len, target_shape)\n",
    "        loss = criterion(logits_tensor, padded_targets_tensor, input_len, tuple(lengths))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0\n",
    "        print(\"Loss: %f\", train_loss)\n",
    "        \n",
    "    #model.eval()\n",
    "    print('training loss:')\n",
    "    print(train_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1364e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'torch.cuda' from '/home/myranda/.local/lib/python3.8/site-packages/torch/cuda/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d1e6e3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n"
     ]
    }
   ],
   "source": [
    "for x in output:\n",
    "    print(x.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc8a549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 2884])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27213/3229910390.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mrnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m#print(batch['seq_lengths'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_27213/135853732.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#lstm_out, self.hidden = self.basic_rnn(X, self.hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# DEBUGGING\n",
    "# Train\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    #model.train()\n",
    "    \n",
    "    for i in range(0, len_data, BATCH_SIZE):\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        basic_rnn.hidden = basic_rnn.init_hidden()\n",
    "        \n",
    "        # Get inputs\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs'] # size (batch, height, width, channels)\n",
    "        #print(data)\n",
    "        #print(data.shape)\n",
    "        max_input_length = data.shape[2]\n",
    "        \n",
    "        # list of indices, values, shape\n",
    "        seq_len = int(batch['seq_lengths'][0])\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        #print(tuple(targets[2]))\n",
    "        #print(type(t[0]) for t in targets)\n",
    "        #targets = torch.sparse_coo_tensor(targets[0], targets[1], tuple(targets[2]))\n",
    "        targets_0 = torch.as_tensor((targets[0]))\n",
    "        #print(targets.shape)\n",
    "        #targets = torch.reshape(targets, (16, 1))\n",
    "        padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=max_input_length)\n",
    "        padded_targets_tensor = torch.tensor(padded_targets)\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        #print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        # forward, backward, optim\n",
    "        cnn_output = model_cnn(tensor_data_reshape)\n",
    "        \n",
    "        # Change shape for rnn\n",
    "        output = cnn_output.view(cnn_output.size(0), cnn_output.size(1), -1)\n",
    "        print(output.shape)\n",
    "        output.permute(2,0,1)\n",
    "        rnn_output = basic_rnn(output)\n",
    "        print(rnn_output.shape)\n",
    "        #print(batch['seq_lengths'])\n",
    "        \n",
    "        #rnn_output_reshape = torch.reshape(rnn_output, (cnn_output[0].shape[2], BATCH_SIZE, N_OUTPUTS))\n",
    "        rnn_output_reshape = torch.reshape(rnn_output, (1, BATCH_SIZE, N_OUTPUTS))\n",
    "        \n",
    "        log_probs = nn.functional.log_softmax(rnn_output_reshape)\n",
    "        #Input and target shape\n",
    "        #print(rnn_output_reshape.shape)\n",
    "        input_shape = (BATCH_SIZE, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        input_len = tuple([1 for i in range (0, BATCH_SIZE)])\n",
    "        #print(input_shape)\n",
    "        target_shape = tuple(int(b) for b in batch['seq_lengths'])\n",
    "        \n",
    "        # MUST BE TENSOR, TENSOR, TUPLE, TUPLE OR TENSOR TENSOR TENSOR TENSOR\n",
    "        #loss = criterion(rnn_output_reshape, padded_targets_tensor, input_len, target_shape)\n",
    "        loss = criterion(log_probs, padded_targets_tensor, input_len, target_shape)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0\n",
    "        \n",
    "    #model.eval()\n",
    "    print('training loss:')\n",
    "    print(train_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "153dfbf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:115] . file in archive is not in a subdirectory: semantic_model.data-00000-of-00001",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9439/3612140687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Models/Semantic-Model.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;31m# reset back to the original position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                     warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:115] . file in archive is not in a subdirectory: semantic_model.data-00000-of-00001"
     ]
    }
   ],
   "source": [
    "torch.load('./Models/Semantic-Model.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
