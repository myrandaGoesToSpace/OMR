{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/myranda/miniconda3/envs/python38/bin/python\n",
      "3.8.12 (default, Oct 12 2021, 13:49:34) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/myranda/miniconda3/envs/python38\n",
      "\n",
      "  added / updated specs:\n",
      "    - opencv\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi            pkgs/main::certifi-2021.10.8-py38h06a~ --> conda-forge::certifi-2021.10.8-py38h578d9bd_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2021.10.26~ --> conda-forge::ca-certificates-2021.10.8-ha878542_0\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge opencv -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/myranda/miniconda3/envs/python38/lib/python3.8/site-packages (4.5.4.60)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/myranda/.local/lib/python3.8/site-packages (from opencv-python) (1.19.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMR Model \n",
    "# Goal: recognize images of music excerpts\n",
    "\n",
    "# Modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "class cnn_model(torch.nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(cnn_model, self).__init__()\n",
    "\n",
    "        kernel_size = [3,3]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size = kernel_size)\n",
    "        self.batch1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16,32, kernel_size = kernel_size)\n",
    "        self.batch2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size = kernel_size)\n",
    "        self.batch3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.act = nn.LeakyReLU()\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # FORWARD PASS\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        output = x\n",
    "\n",
    "        return x\n",
    "\n",
    "class rnn_model(torch.nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size):\n",
    "        super(rnn_model, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        #self.rnn = nn.LSTMCell(input_size = embed_size, hidden_size = hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size + 1)\n",
    "\n",
    "    def forward(self,x, input_size):\n",
    "\n",
    "        #h0 = torch.zeros(16, x.size(0), self.hidden_size).to(device)\n",
    "        #c0 = torch.zeros(16, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        h0 = torch.zeros(16,self.hidden_size,self.hidden_size)#.to(device)\n",
    "        c0 = torch.zeros(16, self.hidden_size,self.hidden_size)#.to(device)\n",
    "        \n",
    "        self.rnn = nn.LSTMCell(input_size = input_size, hidden_size = self.hidden_size)\n",
    "        out, _ = self.rnn(x, (h0, c0))\n",
    "\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super(BasicRNN, self).__init__()\n",
    "        \n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n",
    "        \n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        #X = X.permute(1, 0, 2) \n",
    "        \n",
    "        self.batch_size = X.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        # lstm_out => n_steps, batch_size, n_neurons (hidden states for each time step)\n",
    "        # self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\n",
    "        #lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
    "        out, self.hidden = self.basic_rnn(self.n_inputs, self.n_neurons)\n",
    "        out = self.FC(self.hidden)\n",
    "        \n",
    "        return out#.view(-1, self.n_outputs) # batch_size X n_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctc_utils\n",
    "from primus import CTC_PriMuS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 70880 and validating with 7875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['000122085-1_1_1',\n",
       " '000108307-1_1_1',\n",
       " '190026575-1_1_1',\n",
       " '100500154-1_3_1',\n",
       " '110001284-1_1_1',\n",
       " '220015352-1_1_1',\n",
       " '000112452-1_1_1',\n",
       " '220016330-1_1_1',\n",
       " '201004256-1_1_1',\n",
       " '190019752-1_1_1',\n",
       " '190007841-1_1_1',\n",
       " '211004761-1_3_1',\n",
       " '000104289-1_1_1',\n",
       " '000108649-1_1_1',\n",
       " '211006221-1_2_1',\n",
       " '000136718-1_11_1',\n",
       " '201001449-1_1_1',\n",
       " '000117599-1_1_1',\n",
       " '210097132-1_3_1',\n",
       " '220032200-1_1_1',\n",
       " '220034276-1_4_2',\n",
       " '220015165-1_1_1',\n",
       " '230002052-1_2_2',\n",
       " '000135762-1_1_1',\n",
       " '230000341-1_1_1',\n",
       " '000136904-1_3_1',\n",
       " '220032327-1_1_1',\n",
       " '000118938-1_1_2',\n",
       " '000102330-1_1_2',\n",
       " '211010663-1_11_2',\n",
       " '000111726-1_1_1',\n",
       " '110001544-1_1_1',\n",
       " '000115021-1_1_1',\n",
       " '000123981-1_1_1',\n",
       " '211008085-1_5_1',\n",
       " '201008534-1_12_2',\n",
       " '000108267-1_1_1',\n",
       " '000112093-1_1_1',\n",
       " '220001732-1_1_1',\n",
       " '100501259-1_4_1',\n",
       " '000120263-1_1_2',\n",
       " '100015945-1_4_1',\n",
       " '220001362-1_1_1',\n",
       " '230002781-1_1_2',\n",
       " '220018206-1_1_1',\n",
       " '211010082-1_1_2',\n",
       " '000125617-1_1_1',\n",
       " '100029145-1_4_1',\n",
       " '230002220-1_1_1',\n",
       " '225000422-1_1_1',\n",
       " '000103359-1_1_1',\n",
       " '000122998-1_1_1',\n",
       " '225002095-1_1_1',\n",
       " '000124342-1_1_1',\n",
       " '190007607-1_1_1',\n",
       " '211006321-1_1_1',\n",
       " '211006854-1_1_1',\n",
       " '190001360-1_1_1',\n",
       " '000117891-1_1_2',\n",
       " '190012697-1_1_1',\n",
       " '212003718-1_1_1',\n",
       " '150201929-1_1_1',\n",
       " '000108810-1_2_2',\n",
       " '000103503-1_1_2',\n",
       " '000102369-1_1_1',\n",
       " '220031495-1_1_1',\n",
       " '100016971-1_1_1',\n",
       " '211010628-1_1_1',\n",
       " '201002558-1_2_1',\n",
       " '220015141-1_1_1',\n",
       " '000130046-1_1_1',\n",
       " '000116821-1_1_1',\n",
       " '220015795-1_1_1',\n",
       " '220032440-1_1_2',\n",
       " '212003095-1_1_1',\n",
       " '000139210-1_2_1',\n",
       " '201008772-1_2_1',\n",
       " '211002883-1_1_1',\n",
       " '220012183-1_1_1',\n",
       " '150202529-1_1_2',\n",
       " '200021904-1_43_1',\n",
       " '201007042-1_25_1',\n",
       " '000130108-1_1_1',\n",
       " '220015290-1_1_1',\n",
       " '230005402-1_1_1',\n",
       " '210097330-1_9_1',\n",
       " '000132037-1_2_1',\n",
       " '000118628-1_1_2',\n",
       " '000135919-1_2_1',\n",
       " '190014748-1_1_1',\n",
       " '000103993-1_7_1',\n",
       " '220031046-1_6_1',\n",
       " '230005552-1_18_1',\n",
       " '110000981-3_1_1',\n",
       " '212003016-1_4_1',\n",
       " '000105593-1_1_1',\n",
       " '000107567-1_1_1',\n",
       " '211008211-1_1_2',\n",
       " '000109527-1_1_2',\n",
       " '000104646-1_1_1',\n",
       " '190002381-1_1_1',\n",
       " '230000848-1_1_1',\n",
       " '000138183-1_1_1',\n",
       " '000111377-1_1_1',\n",
       " '230005101-1_33_2',\n",
       " '000114153-1_1_1',\n",
       " '190003777-1_1_1',\n",
       " '000109256-1_1_1',\n",
       " '000137631-1_1_2',\n",
       " '000120734-1_1_2',\n",
       " '201004091-1_1_1',\n",
       " '201001271-1_1_1',\n",
       " '212002860-1_1_1',\n",
       " '210237495-1_3_1',\n",
       " '000117641-1_1_1',\n",
       " '000115689-1_1_2',\n",
       " '110003170-1_6_1',\n",
       " '230001281-1_6_1',\n",
       " '110002292-1_1_1',\n",
       " '110000153-1_1_1',\n",
       " '000124576-1_2_2',\n",
       " '220001665-1_2_1',\n",
       " '220030559-1_1_2',\n",
       " '201009166-1_1_1',\n",
       " '211005516-1_2_1',\n",
       " '211010440-1_18_2',\n",
       " '230002232-1_1_2',\n",
       " '000127081-1_1_1',\n",
       " '230006363-1_2_1',\n",
       " '220011746-1_1_2',\n",
       " '000108055-1_1_1',\n",
       " '230005665-1_3_1',\n",
       " '000124999-8_1_1',\n",
       " '000100714-1_1_1',\n",
       " '110003149-1_3_1',\n",
       " '201008582-1_3_1',\n",
       " '000128862-1_1_1',\n",
       " '000130177-10_1_1',\n",
       " '000120017-1_1_1',\n",
       " '201009210-1_2_1',\n",
       " '211007215-1_19_1',\n",
       " '220012756-1_1_1',\n",
       " '000123034-1_1_1',\n",
       " '220000833-1_2_1',\n",
       " '190018779-1_1_1',\n",
       " '220000978-1_4_1',\n",
       " '000127436-1_1_1',\n",
       " '000127045-1_1_1',\n",
       " '220010545-1_1_2',\n",
       " '000115575-1_1_1',\n",
       " '000142095-1_2_1',\n",
       " '000105840-1_1_1',\n",
       " '211005535-1_1_1',\n",
       " '000107784-1_1_1',\n",
       " '201008529-1_1_1',\n",
       " '230002375-1_1_1',\n",
       " '000102534-1_1_1',\n",
       " '000141854-1_1_1',\n",
       " '000105878-1_1_1',\n",
       " '100016918-1_1_1',\n",
       " '225000499-1_1_1',\n",
       " '201002871-1_3_1',\n",
       " '000125710-1_1_1',\n",
       " '201004337-1_1_1',\n",
       " '190001635-1_1_1',\n",
       " '000125608-1_1_1',\n",
       " '110000921-1_1_1',\n",
       " '220019778-1_1_1',\n",
       " '000105544-1_2_1',\n",
       " '000124838-1_1_1',\n",
       " '230002503-1_3_1',\n",
       " '220011930-1_3_1',\n",
       " '211010168-1_1_1',\n",
       " '190023688-1_2_1',\n",
       " '000126045-1_1_1',\n",
       " '190020614-1_1_1',\n",
       " '211000549-1_1_1',\n",
       " '220032142-1_4_1',\n",
       " '000126811-1_1_1',\n",
       " '201002468-1_5_1',\n",
       " '000100126-5_1_1',\n",
       " '190009174-1_3_1',\n",
       " '000102832-1_1_1',\n",
       " '220034199-1_3_1',\n",
       " '230000739-1_1_1',\n",
       " '000103839-1_1_1',\n",
       " '000104473-1_1_2',\n",
       " '000115043-1_1_1',\n",
       " '220011003-1_8_1',\n",
       " '230001287-1_1_2',\n",
       " '210097319-1_10_1',\n",
       " '000100490-1_1_1',\n",
       " '100029594-1_1_1',\n",
       " '000126337-1_1_1',\n",
       " '100501254-1_7_1',\n",
       " '000112315-1_1_1',\n",
       " '220010218-1_5_1',\n",
       " '000138617-1_3_1',\n",
       " '210017588-1_35_1',\n",
       " '000120005-12_1_1',\n",
       " '220000572-1_1_1',\n",
       " '220030475-1_1_1',\n",
       " '230002036-1_1_1',\n",
       " '211004665-1_3_1',\n",
       " '201008976-1_12_1',\n",
       " '150201505-1_1_1',\n",
       " '211010689-1_1_1',\n",
       " '000112739-1_1_1',\n",
       " '000111986-1_1_1',\n",
       " '190027209-1_1_1',\n",
       " '000119274-1_1_1',\n",
       " '225000248-1_1_1',\n",
       " '000124419-1_1_1',\n",
       " '230006506-1_7_2',\n",
       " '211010664-1_5_1',\n",
       " '190002130-1_1_1',\n",
       " '150203394-1_9_1',\n",
       " '212003412-1_5_1',\n",
       " '220010531-1_1_1',\n",
       " '000116826-9_1_1',\n",
       " '000110743-1_1_1',\n",
       " '000107729-1_1_1',\n",
       " '000107901-1_1_2',\n",
       " '230001896-1_2_1',\n",
       " '160000090-1_1_1',\n",
       " '201009256-1_88_2',\n",
       " '110002771-1_1_2',\n",
       " '230000246-1_35_2',\n",
       " '210000198-1_2_1',\n",
       " '210097300-1_5_1',\n",
       " '190003925-1_1_1',\n",
       " '000111335-1_1_1',\n",
       " '000139007-1_1_1',\n",
       " '000103286-1_1_2',\n",
       " '220000388-1_1_2',\n",
       " '190012218-1_1_1',\n",
       " '000117284-1_1_1',\n",
       " '110000755-1_1_1',\n",
       " '000109277-1_1_1',\n",
       " '000108733-1_1_1',\n",
       " '201004073-1_2_1',\n",
       " '000115434-1_1_1',\n",
       " '201009316-1_27_1',\n",
       " '000124669-1_1_1',\n",
       " '110000527-1_1_1',\n",
       " '000105173-1_1_1',\n",
       " '210097071-1_4_1',\n",
       " '211017897-1_1_1',\n",
       " '110003572-1_1_1',\n",
       " '000121801-1_1_1',\n",
       " '000122968-1_1_2',\n",
       " '000122783-1_1_2',\n",
       " '000121391-1_1_1',\n",
       " '230001316-1_1_1',\n",
       " '000140588-1_1_1',\n",
       " '211001892-1_2_2',\n",
       " '000125802-1_1_1',\n",
       " '100029648-1_1_1',\n",
       " '211003713-1_1_1',\n",
       " '100030944-1_1_1',\n",
       " '000104978-1_1_1',\n",
       " '220018884-1_1_1',\n",
       " '200043792-1_28_2',\n",
       " '000129003-1_1_1',\n",
       " '000117167-1_1_1',\n",
       " '000111143-1_1_1',\n",
       " '000112025-1_1_1',\n",
       " '100500903-1_2_1',\n",
       " '220001167-1_7_2',\n",
       " '230006613-1_4_1',\n",
       " '201009010-1_1_2',\n",
       " '000122825-1_1_1',\n",
       " '000128087-1_1_1',\n",
       " '000136575-1_2_1',\n",
       " '200022048-1_3_2',\n",
       " '000109198-1_2_1',\n",
       " '000110282-1_1_1',\n",
       " '000105799-1_1_1',\n",
       " '220030368-1_1_2',\n",
       " '100500548-1_9_1',\n",
       " '000100283-1_1_1',\n",
       " '000126204-1_2_2',\n",
       " '000108119-1_1_1',\n",
       " '000116053-1_1_1',\n",
       " '000114113-1_2_1',\n",
       " '000135754-1_2_1',\n",
       " '000111659-1_1_1',\n",
       " '000125063-11_1_1',\n",
       " '110002347-1_9_1',\n",
       " '000127679-1_1_1',\n",
       " '000131584-1_1_2',\n",
       " '000101997-1_1_1',\n",
       " '220001285-1_1_1',\n",
       " '201004744-1_4_1',\n",
       " '000116369-1_1_1',\n",
       " '211006215-1_1_1',\n",
       " '000100141-1_1_1',\n",
       " '220015125-1_4_2',\n",
       " '201000304-1_1_1',\n",
       " '000111892-1_1_1',\n",
       " '000124025-1_2_1',\n",
       " '150205081-1_1_1',\n",
       " '000102328-1_1_2',\n",
       " '230001153-1_2_2',\n",
       " '000107845-1_1_2',\n",
       " '000115978-3_1_1',\n",
       " '000101834-1_1_1',\n",
       " '000115959-1_2_1',\n",
       " '000124826-1_1_1',\n",
       " '220001665-1_1_2',\n",
       " '211010557-1_1_1',\n",
       " '211007186-1_3_1',\n",
       " '000136409-1_1_1',\n",
       " '000132527-1_1_1',\n",
       " '000107433-1_2_1',\n",
       " '100500447-1_1_1',\n",
       " '000107804-1_1_2',\n",
       " '000126158-1_1_2',\n",
       " '211008102-1_4_1',\n",
       " '150203021-1_2_1',\n",
       " '220012244-1_1_2',\n",
       " '220031894-1_1_1',\n",
       " '230003605-1_3_1',\n",
       " '000121797-14_1_1',\n",
       " '000105813-1_1_1',\n",
       " '000102011-6_1_1',\n",
       " '190010235-1_1_1',\n",
       " '211010445-1_4_1',\n",
       " '201004527-1_9_2',\n",
       " '201008640-1_1_1',\n",
       " '220034212-1_2_2',\n",
       " '220013283-1_1_1',\n",
       " '000130505-1_1_1',\n",
       " '201005066-1_2_1',\n",
       " '000116879-1_1_2',\n",
       " '220015434-1_1_1',\n",
       " '000141211-1_1_1',\n",
       " '150203574-1_1_1',\n",
       " '230001336-1_5_2',\n",
       " '190012599-1_1_1',\n",
       " '190021025-1_1_1',\n",
       " '220015085-1_1_2',\n",
       " '220013845-1_1_1',\n",
       " '201002859-1_1_1',\n",
       " '000129009-13_1_1',\n",
       " '220013549-1_1_1',\n",
       " '211000643-1_1_1',\n",
       " '000124713-1_1_1',\n",
       " '220018256-1_1_1',\n",
       " '190019513-1_2_1',\n",
       " '190010459-1_1_1',\n",
       " '220017781-1_1_1',\n",
       " '000110735-1_1_1',\n",
       " '212002058-1_5_1',\n",
       " '211004679-1_1_1',\n",
       " '190004591-1_1_1',\n",
       " '212002829-1_6_1',\n",
       " '000110337-1_1_1',\n",
       " '000121109-1_1_1',\n",
       " '000106410-1_1_2',\n",
       " '220001706-1_3_1',\n",
       " '230005872-1_3_1',\n",
       " '220014323-1_1_2',\n",
       " '201009316-1_36_2',\n",
       " '100198470-1_1_1',\n",
       " '100501168-1_1_2',\n",
       " '150206124-1_1_1',\n",
       " '200231002-1_1_1',\n",
       " '220019244-1_1_2',\n",
       " '230002400-1_3_2',\n",
       " '230006060-1_1_1',\n",
       " '220016553-1_1_1',\n",
       " '220016912-1_3_2',\n",
       " '000124010-1_1_1',\n",
       " '100501246-1_1_1',\n",
       " '000135917-1_4_2',\n",
       " '190101764-1_1_1',\n",
       " '000107033-1_12_1',\n",
       " '230001570-1_1_1',\n",
       " '150200961-1_1_1',\n",
       " '000137650-1_2_2',\n",
       " '000102130-1_2_2',\n",
       " '211010129-1_7_1',\n",
       " '225003120-1_3_1',\n",
       " '201008156-1_2_1',\n",
       " '000119288-1_1_1',\n",
       " '000113905-1_1_2',\n",
       " '000141705-1_1_1',\n",
       " '200043749-1_38_1',\n",
       " '212002999-1_3_1',\n",
       " '000107956-1_1_1',\n",
       " '000111386-1_1_1',\n",
       " '230001223-1_1_2',\n",
       " '220013436-1_1_1',\n",
       " '220034299-1_3_2',\n",
       " '200043759-1_1_1',\n",
       " '110002366-1_3_1',\n",
       " '211004465-1_1_1',\n",
       " '000102288-3_1_1',\n",
       " '210097182-1_2_1',\n",
       " '000123909-1_1_1',\n",
       " '220019046-1_1_1',\n",
       " '190023887-1_1_1',\n",
       " '000115976-4_1_1',\n",
       " '000104503-1_1_1',\n",
       " '100029972-1_1_2',\n",
       " '190013444-1_1_1',\n",
       " '210097193-1_1_1',\n",
       " '000117754-1_1_1',\n",
       " '140000062-1_1_1',\n",
       " '100017035-1_4_1',\n",
       " '000116882-1_1_1',\n",
       " '000100467-1_1_1',\n",
       " '230005739-1_1_1',\n",
       " '190100746-1_1_1',\n",
       " '230001382-1_1_1',\n",
       " '225001130-1_1_1',\n",
       " '230001414-1_3_1',\n",
       " '000114875-1_1_1',\n",
       " '000107733-1_1_2',\n",
       " '230000880-1_1_1',\n",
       " '000101518-1_10_1',\n",
       " '000117697-1_1_1',\n",
       " '000114487-1_1_2',\n",
       " '212001987-1_3_1',\n",
       " '000107271-1_1_1',\n",
       " '000105498-1_1_1',\n",
       " '100017499-1_2_1',\n",
       " '220031063-1_4_1',\n",
       " '100028786-1_2_1',\n",
       " '000125333-1_1_1',\n",
       " '230002792-1_3_2',\n",
       " '000120166-1_1_1',\n",
       " '225001103-1_31_1',\n",
       " '000110935-1_2_1',\n",
       " '000121006-1_1_1',\n",
       " '000101766-1_3_1',\n",
       " '000130717-1_1_1',\n",
       " '212001517-1_1_1',\n",
       " '230003197-1_1_1',\n",
       " '000118700-1_2_1',\n",
       " '190004097-1_1_1',\n",
       " '220030746-1_3_1',\n",
       " '211006955-1_2_1',\n",
       " '000123662-1_1_2',\n",
       " '000130017-1_1_2',\n",
       " '220000051-1_1_1',\n",
       " '000119047-1_1_1',\n",
       " '000109412-1_1_1',\n",
       " '230005039-1_21_2',\n",
       " '000130802-1_1_2',\n",
       " '212001235-1_1_1',\n",
       " '000114534-1_1_1',\n",
       " '150204413-1_1_1',\n",
       " '000109935-1_1_1',\n",
       " '110001547-1_1_1',\n",
       " '000113217-1_1_1',\n",
       " '190006127-1_1_1',\n",
       " '201001684-1_1_1',\n",
       " '201009226-1_2_1',\n",
       " '000135718-1_1_1',\n",
       " '000131978-1_1_1',\n",
       " '211005330-1_7_1',\n",
       " '230005363-1_2_1',\n",
       " '000141936-1_1_1',\n",
       " '220012567-1_10_1',\n",
       " '190101571-1_1_1',\n",
       " '220030651-1_1_2',\n",
       " '220000105-1_3_1',\n",
       " '201007179-1_5_1',\n",
       " '160000293-1_1_1',\n",
       " '230003436-1_5_1',\n",
       " '000125157-1_1_1',\n",
       " '201004332-1_64_2',\n",
       " '000103021-1_1_1',\n",
       " '000117618-1_1_1',\n",
       " '000122854-1_1_1',\n",
       " '190011400-1_1_1',\n",
       " '000107745-1_1_2',\n",
       " '200021224-1_1_1',\n",
       " '150201764-1_1_1',\n",
       " '150200212-1_1_1',\n",
       " '190001339-1_1_1',\n",
       " '220018344-1_1_1',\n",
       " '000100036-1_1_1',\n",
       " '000124982-1_1_2',\n",
       " '190024365-1_1_1',\n",
       " '000126309-12_1_1',\n",
       " '000138997-1_1_1',\n",
       " '201009318-1_59_2',\n",
       " '000112311-1_1_1',\n",
       " '211006331-1_1_1',\n",
       " '000136219-1_1_1',\n",
       " '000132429-1_1_1',\n",
       " '000120296-1_1_1',\n",
       " '190020073-1_1_1',\n",
       " '220018202-1_3_1',\n",
       " '150204647-1_1_1',\n",
       " '200021893-1_39_1',\n",
       " '201009257-1_42_2',\n",
       " '211004858-1_2_2',\n",
       " '150205764-1_1_1',\n",
       " '000101502-1_2_1',\n",
       " '000113983-1_1_1',\n",
       " '000135130-1_1_1',\n",
       " '000114224-1_1_1',\n",
       " '200044357-1_32_1',\n",
       " '000107800-3_1_1',\n",
       " '220019655-1_3_1',\n",
       " '220018055-1_1_2',\n",
       " '000101277-1_1_1',\n",
       " '230003209-1_1_1',\n",
       " '000105564-1_2_1',\n",
       " '200021895-1_16_2',\n",
       " '211006048-1_3_1',\n",
       " '000106847-1_1_1',\n",
       " '220030332-1_1_1',\n",
       " '190016813-1_1_1',\n",
       " '000101548-1_1_1',\n",
       " '220018897-1_1_1',\n",
       " '000126997-1_1_2',\n",
       " '000116530-1_1_1',\n",
       " '000117551-1_2_1',\n",
       " '000104397-1_1_1',\n",
       " '190101069-1_3_1',\n",
       " '000111425-1_1_1',\n",
       " '000119195-1_1_1',\n",
       " '100501225-1_6_1',\n",
       " '000135504-1_1_1',\n",
       " '000116779-1_1_1',\n",
       " '211008358-1_1_1',\n",
       " '230006345-1_1_1',\n",
       " '100000010-1_2_1',\n",
       " '201004711-1_32_1',\n",
       " '230005394-1_2_1',\n",
       " '190026529-1_1_1',\n",
       " '230002499-1_8_1',\n",
       " '000100934-1_1_1',\n",
       " '000125764-8_1_1',\n",
       " '201010238-1_1_1',\n",
       " '000114465-1_1_1',\n",
       " '000123265-1_1_2',\n",
       " '000110265-1_1_1',\n",
       " '000142616-1_3_1',\n",
       " '150201021-1_1_1',\n",
       " '000106930-1_1_1',\n",
       " '000126159-1_1_1',\n",
       " '000120619-1_1_1',\n",
       " '000115654-1_1_2',\n",
       " '190009516-1_1_1',\n",
       " '000104651-1_2_2',\n",
       " '211004931-1_1_1',\n",
       " '220031680-1_1_1',\n",
       " '230000106-1_7_1',\n",
       " '000109720-1_1_1',\n",
       " '000115093-1_1_1',\n",
       " '220020071-1_1_1',\n",
       " '220016535-1_1_1',\n",
       " '220011007-1_30_1',\n",
       " '212000251-1_1_1',\n",
       " '000126346-1_1_2',\n",
       " '000130986-1_1_1',\n",
       " '212003384-1_1_1',\n",
       " '201009206-1_2_2',\n",
       " '230002833-1_2_2',\n",
       " '190004224-1_1_1',\n",
       " '190007137-2_1_1',\n",
       " '000111362-1_2_1',\n",
       " '000106540-1_1_1',\n",
       " '000139718-1_1_1',\n",
       " '000109240-1_1_1',\n",
       " '000122164-1_2_2',\n",
       " '201008563-1_7_1',\n",
       " '212001218-1_5_1',\n",
       " '220001273-1_1_1',\n",
       " '210097145-1_2_1',\n",
       " '000116448-1_1_1',\n",
       " '000131665-1_2_1',\n",
       " '150200905-1_1_1',\n",
       " '000105764-1_1_1',\n",
       " '000115117-1_1_2',\n",
       " '000125737-5_1_1',\n",
       " '000116449-1_1_1',\n",
       " '201001163-1_1_2',\n",
       " '000102480-1_1_1',\n",
       " '200021300-1_6_1',\n",
       " '190002668-1_1_1',\n",
       " '000121335-1_1_1',\n",
       " '000120005-4_1_1',\n",
       " '000113963-1_1_1',\n",
       " '225000868-1_1_1',\n",
       " '000139392-1_1_1',\n",
       " '230003592-1_2_1',\n",
       " '000101053-1_1_2',\n",
       " '100029528-1_1_1',\n",
       " '212003345-1_1_1',\n",
       " '230005850-1_3_1',\n",
       " '000121759-1_1_1',\n",
       " '000115998-1_1_1',\n",
       " '220034661-1_1_1',\n",
       " '212001555-1_1_1',\n",
       " '000104658-1_1_1',\n",
       " '201009167-1_4_2',\n",
       " '000105353-1_1_1',\n",
       " '230002864-1_2_1',\n",
       " '150200018-1_1_1',\n",
       " '000122995-1_1_2',\n",
       " '000117244-1_1_1',\n",
       " '000101505-1_1_1',\n",
       " '000126728-1_1_1',\n",
       " '201009114-1_1_1',\n",
       " '000123136-1_1_1',\n",
       " '000111687-1_1_1',\n",
       " '000140595-1_1_1',\n",
       " '000122632-1_1_1',\n",
       " '220014508-1_1_1',\n",
       " '220030857-1_1_1',\n",
       " '150204184-1_1_1',\n",
       " '000103163-1_1_1',\n",
       " '212000222-1_3_1',\n",
       " '190004186-1_1_1',\n",
       " '000119384-1_2_1',\n",
       " '211004544-1_12_1',\n",
       " '000115309-1_1_1',\n",
       " '000101652-1_1_1',\n",
       " '211005470-1_1_1',\n",
       " '000121999-1_2_1',\n",
       " '000105382-1_1_1',\n",
       " '000100126-27_1_1',\n",
       " '000135151-2_1_1',\n",
       " '000119511-1_1_1',\n",
       " '220000570-1_3_2',\n",
       " '000100688-1_1_1',\n",
       " '211006312-1_2_1',\n",
       " '220000460-1_5_1',\n",
       " '100500124-1_8_3',\n",
       " '000116406-1_1_1',\n",
       " '190022778-1_1_1',\n",
       " '000127945-1_1_1',\n",
       " '110003879-1_1_1',\n",
       " '000112034-1_1_1',\n",
       " '000100609-1_2_1',\n",
       " '110002976-1_1_1',\n",
       " '201007613-1_1_1',\n",
       " '212001986-1_3_1',\n",
       " '230005667-1_2_1',\n",
       " '000130426-1_1_1',\n",
       " '000108583-1_1_1',\n",
       " '000110388-1_1_2',\n",
       " '190026572-1_1_1',\n",
       " '100501232-1_4_1',\n",
       " '210000007-1_1_2',\n",
       " '000123782-1_1_2',\n",
       " '211006241-1_1_1',\n",
       " '212001762-1_1_1',\n",
       " '212001339-1_1_1',\n",
       " '000107236-1_1_1',\n",
       " '220013733-1_1_1',\n",
       " '000112926-1_1_2',\n",
       " '220017044-1_2_1',\n",
       " '000110690-1_1_2',\n",
       " '000123332-1_1_1',\n",
       " '211004695-1_6_1',\n",
       " '212000443-1_1_1',\n",
       " '220013719-1_1_1',\n",
       " '230005823-1_1_1',\n",
       " '212001351-1_3_1',\n",
       " '190019795-1_1_1',\n",
       " '201002934-1_3_2',\n",
       " '211008425-1_5_1',\n",
       " '220030951-1_10_1',\n",
       " '225000537-1_1_1',\n",
       " '220019491-1_1_1',\n",
       " '000100207-1_1_1',\n",
       " '201001025-1_1_1',\n",
       " '230001883-1_28_1',\n",
       " '220001164-1_2_1',\n",
       " '000137243-1_1_1',\n",
       " '000101187-1_1_2',\n",
       " '000126156-1_1_2',\n",
       " '201002693-1_1_1',\n",
       " '211004928-1_5_1',\n",
       " '000127109-1_1_1',\n",
       " '000100850-1_1_2',\n",
       " '211007228-1_9_2',\n",
       " '100017335-1_2_1',\n",
       " '000101508-1_2_2',\n",
       " '212003537-1_3_1',\n",
       " '000120211-1_1_1',\n",
       " '212001353-1_7_1',\n",
       " '000110383-1_1_1',\n",
       " '220010820-1_9_2',\n",
       " '000136294-1_1_1',\n",
       " '110002167-1_1_1',\n",
       " '211000700-1_3_1',\n",
       " '100029503-1_2_1',\n",
       " '000106259-1_1_1',\n",
       " '000110137-1_1_1',\n",
       " '212003210-1_3_1',\n",
       " '230000028-1_1_1',\n",
       " '201009259-1_34_1',\n",
       " '230001890-1_4_1',\n",
       " '110003214-1_1_1',\n",
       " '000103136-1_1_1',\n",
       " '000105062-10_1_1',\n",
       " '220014262-1_2_1',\n",
       " '211004287-1_1_1',\n",
       " '000138139-1_2_1',\n",
       " '000113748-1_1_1',\n",
       " '000114018-1_1_2',\n",
       " '190015057-1_1_1',\n",
       " '000114372-1_1_1',\n",
       " '000100135-1_1_2',\n",
       " '220000689-1_1_1',\n",
       " '000135460-1_1_1',\n",
       " '200035720-1_1_1',\n",
       " '220000815-1_1_1',\n",
       " '000135488-1_1_1',\n",
       " '000117282-1_1_1',\n",
       " '170000143-1_1_1',\n",
       " '190003692-1_2_1',\n",
       " '225001917-1_1_1',\n",
       " '211010562-1_1_1',\n",
       " '220012794-1_1_1',\n",
       " '210000153-1_22_2',\n",
       " '160000151-1_1_1',\n",
       " '211002654-1_1_1',\n",
       " '211004719-1_5_1',\n",
       " '220011528-1_1_1',\n",
       " '220011001-1_1_2',\n",
       " '000138509-1_1_1',\n",
       " '230003573-1_4_1',\n",
       " '000102064-1_1_1',\n",
       " '000127376-1_1_1',\n",
       " '201009254-1_22_2',\n",
       " '190020644-1_1_1',\n",
       " '110001956-1_1_1',\n",
       " '212003758-1_1_1',\n",
       " '220032170-1_1_2',\n",
       " '100015375-1_1_1',\n",
       " '200021502-1_48_1',\n",
       " '000123230-1_1_2',\n",
       " '000135194-1_1_2',\n",
       " '230003696-1_1_1',\n",
       " '201007878-1_3_2',\n",
       " '212002016-1_2_1',\n",
       " '100029048-1_1_1',\n",
       " '000113553-1_1_1',\n",
       " '000117155-1_1_1',\n",
       " '220017813-1_1_1',\n",
       " '220000532-1_1_2',\n",
       " '000131612-1_1_1',\n",
       " '230002722-1_1_2',\n",
       " '000132299-1_1_1',\n",
       " '100030613-1_1_1',\n",
       " '230002657-1_3_2',\n",
       " '150201552-1_1_1',\n",
       " '000127968-1_1_2',\n",
       " '220000220-1_1_2',\n",
       " '110002232-1_1_1',\n",
       " '230002691-1_31_2',\n",
       " '000125295-1_2_1',\n",
       " '000109199-1_1_1',\n",
       " '000111162-1_1_1',\n",
       " '000138060-1_3_1',\n",
       " '225000027-1_14_1',\n",
       " '100015578-1_1_1',\n",
       " '000102081-1_2_1',\n",
       " '000130501-1_1_1',\n",
       " '000135345-1_1_1',\n",
       " '000128319-1_1_1',\n",
       " '170000293-1_2_1',\n",
       " '190009580-1_1_2',\n",
       " '000110654-1_1_1',\n",
       " '110002306-1_1_1',\n",
       " '201009257-1_21_1',\n",
       " '210097293-1_40_1',\n",
       " '000109435-1_1_1',\n",
       " '000102523-1_1_2',\n",
       " '000120321-1_1_1',\n",
       " '220010905-1_4_2',\n",
       " '000142614-1_1_1',\n",
       " '000128933-1_1_1',\n",
       " '000115955-1_2_1',\n",
       " '000126131-1_1_1',\n",
       " '000127861-1_1_1',\n",
       " '000102072-1_1_2',\n",
       " '000103317-1_1_1',\n",
       " '201000086-1_2_1',\n",
       " '000140510-1_1_1',\n",
       " '220014568-1_2_1',\n",
       " '220011795-1_4_2',\n",
       " '220010252-1_3_1',\n",
       " '000119693-1_1_1',\n",
       " '000102524-1_1_2',\n",
       " '000119249-1_2_1',\n",
       " '190002000-1_1_1',\n",
       " '000104072-1_1_1',\n",
       " '000127340-1_1_1',\n",
       " '000126504-1_1_1',\n",
       " '000115599-1_1_1',\n",
       " '190001255-1_1_1',\n",
       " '000136431-1_1_1',\n",
       " '212000159-1_2_1',\n",
       " '220010596-1_3_2',\n",
       " '190004583-1_1_1',\n",
       " '220019309-1_1_1',\n",
       " '000116029-1_1_1',\n",
       " '000109569-1_1_2',\n",
       " '000107752-1_1_1',\n",
       " '190011839-1_1_1',\n",
       " '000117097-1_2_2',\n",
       " '000128174-1_1_2',\n",
       " '000141886-1_1_1',\n",
       " '000131063-1_1_2',\n",
       " '000118233-1_1_1',\n",
       " '230000813-1_1_1',\n",
       " '100501287-1_2_1',\n",
       " '000113631-1_1_1',\n",
       " '000125039-1_1_2',\n",
       " '210017840-1_41_2',\n",
       " '000108882-1_1_2',\n",
       " '000101190-1_1_1',\n",
       " '000108869-1_1_1',\n",
       " '230003551-1_1_2',\n",
       " '110002589-1_1_1',\n",
       " '230002266-1_1_2',\n",
       " '000107637-1_2_2',\n",
       " '201005457-1_1_2',\n",
       " '000122807-1_1_1',\n",
       " '230000498-1_1_1',\n",
       " '220016284-1_1_1',\n",
       " '212001466-1_3_1',\n",
       " '201003447-1_1_1',\n",
       " '100016645-1_2_1',\n",
       " '000118605-1_1_1',\n",
       " '212001010-1_2_1',\n",
       " '220030540-1_1_1',\n",
       " '211006017-1_1_1',\n",
       " '000116586-1_1_1',\n",
       " '000106907-1_1_1',\n",
       " '212003720-1_3_2',\n",
       " '000100678-1_1_1',\n",
       " '211010038-1_1_1',\n",
       " '000101003-1_1_2',\n",
       " '000123553-1_1_1',\n",
       " '000110720-1_1_1',\n",
       " '190005467-1_2_1',\n",
       " '000138198-1_1_1',\n",
       " '000103218-1_1_1',\n",
       " '000107033-1_8_1',\n",
       " '201004223-1_13_1',\n",
       " '000107919-1_1_2',\n",
       " '225000023-1_1_1',\n",
       " '220001000-1_4_1',\n",
       " '210097453-1_1_1',\n",
       " '211002548-1_1_1',\n",
       " '220018578-1_1_1',\n",
       " '201007285-1_1_2',\n",
       " '000101333-1_1_2',\n",
       " '150201402-1_1_1',\n",
       " '211010574-1_2_1',\n",
       " '220032140-1_2_1',\n",
       " '220030048-1_1_1',\n",
       " '211005897-1_1_1',\n",
       " '220016192-1_1_1',\n",
       " '225003986-1_1_1',\n",
       " '201007210-1_2_1',\n",
       " '000101014-1_1_2',\n",
       " '000141830-1_1_1',\n",
       " '000104291-1_1_1',\n",
       " '000132177-1_1_1',\n",
       " '000124256-1_1_1',\n",
       " '100029115-1_1_1',\n",
       " '230005208-1_2_1',\n",
       " '200021985-1_3_2',\n",
       " '211002441-1_2_1',\n",
       " '000115537-1_1_2',\n",
       " '000114891-1_1_1',\n",
       " '211003354-1_1_1',\n",
       " '000130499-1_1_1',\n",
       " '190007462-1_1_1',\n",
       " '220001106-1_8_1',\n",
       " '150200130-1_1_1',\n",
       " '000131004-1_2_1',\n",
       " '150201171-1_1_1',\n",
       " '212003063-1_4_1',\n",
       " '230000099-1_7_2',\n",
       " '201007798-1_1_1',\n",
       " '190101408-1_1_1',\n",
       " '110003369-1_1_1',\n",
       " '000132880-1_1_1',\n",
       " '211010130-1_59_1',\n",
       " '211006579-1_5_1',\n",
       " '211004857-1_3_2',\n",
       " '190021067-1_1_1',\n",
       " '000107940-1_1_1',\n",
       " '000122996-1_1_1',\n",
       " '000126331-1_1_1',\n",
       " '000102269-1_1_1',\n",
       " '000109025-1_1_1',\n",
       " '000116780-1_1_1',\n",
       " '210000106-1_1_2',\n",
       " '000107894-1_1_1',\n",
       " '220017023-1_2_1',\n",
       " '190017440-1_1_1',\n",
       " '230004206-1_1_1',\n",
       " '100500724-1_11_1',\n",
       " '000100623-1_1_1',\n",
       " '201008589-1_2_2',\n",
       " '100017530-1_1_1',\n",
       " '000113550-1_1_1',\n",
       " '211010314-1_1_1',\n",
       " '000102476-1_1_1',\n",
       " '000118845-1_1_1',\n",
       " '000108906-1_1_2',\n",
       " '000111322-1_1_2',\n",
       " '000102284-1_1_1',\n",
       " '150200799-1_1_1',\n",
       " '220015396-1_1_2',\n",
       " '201004908-1_3_1',\n",
       " '190001848-1_1_1',\n",
       " '100029050-1_1_1',\n",
       " '211006475-1_1_1',\n",
       " '000131671-1_1_1',\n",
       " '201003503-1_1_1',\n",
       " '190006233-1_1_1',\n",
       " '000138463-1_2_1',\n",
       " '220010223-1_1_2',\n",
       " '211004389-1_5_1',\n",
       " '210237628-1_3_1',\n",
       " '000118853-1_1_2',\n",
       " '100029504-1_1_2',\n",
       " '000101264-1_1_1',\n",
       " '000128356-1_1_1',\n",
       " '000101982-1_1_1',\n",
       " '100016385-1_1_1',\n",
       " '000136455-1_1_1',\n",
       " '000125773-1_1_1',\n",
       " '211001882-1_9_2',\n",
       " '000127811-1_1_1',\n",
       " '000113228-1_1_1',\n",
       " '150203546-1_1_1',\n",
       " '210000005-1_5_1',\n",
       " '000107489-1_1_1',\n",
       " '230002356-1_4_1',\n",
       " '225001083-1_41_1',\n",
       " '220001102-1_2_1',\n",
       " '210097346-1_1_1',\n",
       " '100017508-1_2_1',\n",
       " '000139626-1_1_2',\n",
       " '220016763-1_1_1',\n",
       " '000100133-1_1_1',\n",
       " '000113554-1_1_1',\n",
       " '000138822-1_3_1',\n",
       " '000117271-1_1_1',\n",
       " '000117798-1_2_1',\n",
       " '000108726-1_1_1',\n",
       " '000136963-1_1_2',\n",
       " '100501162-1_1_1',\n",
       " '200185305-1_8_1',\n",
       " '211010701-1_11_1',\n",
       " '000101020-1_1_1',\n",
       " '000118213-1_1_1',\n",
       " '000121790-8_1_1',\n",
       " '201007875-1_1_1',\n",
       " '000102011-3_2_1',\n",
       " '225000017-1_2_1',\n",
       " '000117615-1_1_1',\n",
       " '230005552-1_14_2',\n",
       " '220010357-1_14_1',\n",
       " '230006247-1_3_1',\n",
       " '000119026-1_1_1',\n",
       " '000114129-1_1_1',\n",
       " '201002030-1_4_1',\n",
       " '000112199-1_1_1',\n",
       " '000117236-1_1_2',\n",
       " '190010767-1_1_1',\n",
       " '211001818-1_3_2',\n",
       " '210000084-1_5_1',\n",
       " '000117664-1_1_1',\n",
       " '100500743-1_7_1',\n",
       " '220017883-1_1_1',\n",
       " '150206047-1_1_1',\n",
       " '220034204-1_1_1',\n",
       " '211003398-1_4_1',\n",
       " '201004397-1_29_1',\n",
       " '100017189-1_1_1',\n",
       " '000108565-1_1_1',\n",
       " '000121244-1_1_1',\n",
       " '000130878-1_1_1',\n",
       " '000100747-1_1_1',\n",
       " '000122136-1_1_2',\n",
       " '000131073-1_1_1',\n",
       " '201004816-1_30_1',\n",
       " '220032462-1_2_1',\n",
       " '000126351-1_1_1',\n",
       " '110001872-1_1_1',\n",
       " '220015038-1_1_1',\n",
       " '000123649-1_1_1',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "corpus = './Data/package'# PATH\n",
    "set = 'Data/train.txt' \n",
    "vocabulary = 'Data/vocabulary_semantic.txt'  \n",
    "save_model = './trained_\\semantic_model'\n",
    "\n",
    "primus = CTC_PriMuS(corpus, set, vocabulary, semantic = True, val_split = 0.1)\n",
    "primus.training_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/myranda/Documents/DSI/ML/OMR'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/package/000118390-1_1_2/000118390-1_1_2\n",
      "(155, 1639)\n"
     ]
    }
   ],
   "source": [
    "#IMAGE DEBUGGING\n",
    "sample_filepath = primus.training_list[0]\n",
    "sample_fullpath = corpus + '/' + sample_filepath + '/' + sample_filepath\n",
    "print(sample_fullpath)\n",
    "\n",
    "# Get image\n",
    "sample_img = cv2.imread(sample_fullpath + '.png', 0)\n",
    "print(sample_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "# IMAGE DEBUGGING - MPL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "PATH = './Data/package/' + sample_filepath + '/' + sample_filepath\n",
    "\n",
    "img = mpimg.imread(PATH + '.png')\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROP IMAGES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 128\n",
    "max_epochs = 1\n",
    "dropout = 0.5\n",
    "\n",
    "batch_size = 16\n",
    "vocabulary_size = primus.vocabulary_size\n",
    "model_cnn = cnn_model(batch_size)\n",
    "model_rnn = rnn_model(embed_size = 512, hidden_size = 512, vocab_size = primus.vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "\n",
    "learning_rate = 0.001\n",
    "criterion = torch.nn.CTCLoss()\n",
    "optimizer_cnn = optim.Adam(model_cnn.parameters(), lr = learning_rate) ## ADD MODEL PARAMS\n",
    "optimizer_rnn = optim.Adam(model_rnn.parameters(), lr = learning_rate)\n",
    "optimizer = optim.Adam(list(model_cnn.parameters()) + list(model_rnn.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default params\n",
    "# With image height of 128, width will be 1870\n",
    "params = dict()\n",
    "params['img_height'] = img_height\n",
    "params['img_width'] = None\n",
    "params['batch_size'] = 16\n",
    "params['img_channels'] = 1\n",
    "params['conv_blocks'] = 4\n",
    "params['conv_filter_n'] = [32, 64, 128, 256]\n",
    "params['conv_filter_size'] = [ [3,3], [3,3], [3,3], [3,3] ]\n",
    "params['conv_pooling_size'] = [ [2,2], [2,2], [2,2], [2,2] ]\n",
    "params['rnn_units'] = 512\n",
    "params['rnn_layers'] = 2\n",
    "params['vocabulary_size'] = vocabulary_size\n",
    "params['max_width'] = 1500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape for CTC loss\n",
    "input_shape = (None, params['img_height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 128, 2153, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 2417, 1])\n",
      "torch.Size([16, 64, 14, 300])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (14336x300 and 896x2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27213/1342245661.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#features = torch.permute(output, (3, 0, 2, 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#features = torch.reshape(features, (16, features.shape[0], 64 * 14)) # width, batch, features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moutput_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#Input and target shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_27213/1962396934.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, input_size)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m         )\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (14336x300 and 896x2048)"
     ]
    }
   ],
   "source": [
    "# Train using model_rnn\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    \n",
    "    train_acc = 0.\n",
    "    valid_acc = 0.\n",
    "    \n",
    "    for i in range(0, 70880 + 7875, 16):\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs']\n",
    "\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        output = model_cnn(tensor_data_reshape)\n",
    "        print(output.shape)\n",
    "        #output_size = 64 * 14 * output.shape[3]\n",
    "        output_size = output.shape[3]\n",
    "        # Reshape output for RNN\n",
    "        output = output.view(output.size(0), output.size(3), -1)\n",
    "        output = output.permute(0,2,1)\n",
    "        #features = torch.permute(output, (3, 0, 2, 1))\n",
    "        #features = torch.reshape(features, (16, features.shape[0], 64 * 14)) # width, batch, features\n",
    "        output_rnn = model_rnn(output, input_size = 64*14)\n",
    "        \n",
    "        #Input and target shape\n",
    "        input_shape = (None, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        target_shape = batch['seq_lengths']\n",
    "        \n",
    "        loss = criterion(output, targets, input_shape, target_shape)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Calc loss\n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0 # ADD ACCURACY\n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE BATCH SIZE ALL IMAGES TO KEEP WIDTHS THE SAME\n",
    "# Train using model_rnn\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    \n",
    "    train_acc = 0.\n",
    "    valid_acc = 0.\n",
    "    \n",
    "    for i in range(0, 70880 + 7875, 16):\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs']\n",
    "\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        output = model_cnn(tensor_data_reshape)\n",
    "        print(output.shape)\n",
    "        #output_size = 64 * 14 * output.shape[3]\n",
    "        output_size = output.shape[3]\n",
    "        # Reshape output for RNN\n",
    "        output = output.view(output.size(0), output.size(3), -1)\n",
    "        output = output.permute(0,2,1)\n",
    "        #features = torch.permute(output, (3, 0, 2, 1))\n",
    "        #features = torch.reshape(features, (16, features.shape[0], 64 * 14)) # width, batch, features\n",
    "        output_rnn = model_rnn(output, input_size = 64*14)\n",
    "        \n",
    "        #Input and target shape\n",
    "        input_shape = (None, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        target_shape = batch['seq_lengths']\n",
    "        \n",
    "        loss = criterion(output, targets, input_shape, target_shape)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Calc loss\n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0 # ADD ACCURACY\n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14336/896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BasicRNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-47023bb71e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mN_INPUTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m896\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mbasic_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_INPUTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_NEURONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_OUTPUTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlen_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BasicRNN' is not defined"
     ]
    }
   ],
   "source": [
    "# Train using Basic RNN\n",
    "\n",
    "# Setup\n",
    "BATCH_SIZE = 16\n",
    "IMG_HEIGHT = img_height\n",
    "N_EPOCHS = 1\n",
    "N_OUTPUTS = vocabulary_size + 1\n",
    "N_NEURONS = 512\n",
    "#N_INPUTS = 512\n",
    "N_INPUTS = 896\n",
    "model_cnn = cnn_model(BATCH_SIZE)\n",
    "basic_rnn = BasicRNN(BATCH_SIZE, 1, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
    "optimizer = optim.Adam(list(model_cnn.parameters()) + list(basic_rnn.parameters()))\n",
    "len_data = len(primus.training_list) + len(primus.validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 14, 230])\n",
      "torch.Size([14, 230])\n",
      "torch.Size([230, 16, 896])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27213/2840740796.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# width, batch, features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mrnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq_lengths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_27213/135853732.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#lstm_out, self.hidden = self.basic_rnn(X, self.hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    model_cnn.train()\n",
    "    basic_rnn.train()\n",
    "    \n",
    "    for i in range(0, len_data, BATCH_SIZE):\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        basic_rnn.hidden = basic_rnn.init_hidden()\n",
    "        \n",
    "        # Get inputs\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs'] # size (batch, height, width, channels)\n",
    "        #print(data)\n",
    "        #print(data.shape)\n",
    "        max_input_length = data.shape[2]\n",
    "        \n",
    "        # list of indices, values, shape\n",
    "        seq_len = int(batch['seq_lengths'][0])\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        #print(tuple(targets[2]))\n",
    "        #print(type(t[0]) for t in targets)\n",
    "        #targets = torch.sparse_coo_tensor(targets[0], targets[1], tuple(targets[2]))\n",
    "        targets_0 = torch.as_tensor((targets[0]))\n",
    "        #print(targets.shape)\n",
    "        #targets = torch.reshape(targets, (16, 1))\n",
    "        padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=max_input_length)\n",
    "        padded_targets_tensor = torch.tensor(padded_targets)\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        #print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        # forward, backward, optim\n",
    "        cnn_output = model_cnn(tensor_data_reshape)\n",
    "        output_size = 64 * 14 * cnn_output.shape[3]\n",
    "        #print(cnn_output.shape)\n",
    "        #print(cnn_output[0])\n",
    "        print(cnn_output[0].shape)\n",
    "        print(cnn_output[0][0].shape)\n",
    "        \n",
    "        # Change shape for rnn\n",
    "        output = torch.reshape(cnn_output, (cnn_output.shape[3], 16, 64 * 14)) # width, batch, features\n",
    "        print(output.shape)\n",
    "        rnn_output = basic_rnn(output)\n",
    "        print(rnn_output[0].shape)\n",
    "        print(batch['seq_lengths'])\n",
    "        \n",
    "        #rnn_output_reshape = torch.reshape(rnn_output, (cnn_output[0].shape[2], BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = torch.reshape(rnn_output[0], (1, BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = rnn_output[0].view(-1, BATCH_SIZE, N_OUTPUTS)\n",
    "        \n",
    "        \n",
    "        log_probs = nn.functional.log_softmax(rnn_output)\n",
    "        #Input and target shape\n",
    "        #print(rnn_output_reshape.shape)\n",
    "        input_shape = (BATCH_SIZE, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        input_len = tuple([1 for i in range (0, BATCH_SIZE)])\n",
    "        #print(input_shape)\n",
    "        target_shape = tuple(int(b) for b in batch['seq_lengths'])\n",
    "        \n",
    "        # MUST BE TENSOR, TENSOR, TUPLE, TUPLE OR TENSOR TENSOR TENSOR TENSOR\n",
    "        #loss = criterion(rnn_output_reshape, padded_targets_tensor, input_len, target_shape)\n",
    "        #loss = criterion(log_probs, padded_targets_tensor, input_len, target_shape)\n",
    "        loss = criterion(log_probs, padded_targets_tensor, target_shape, tuple(lengths))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0\n",
    "        print(\"Loss: %f\", train_loss)\n",
    "        \n",
    "    #model.eval()\n",
    "    print('training loss:')\n",
    "    print(train_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782.0"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28512/16\n",
    "# 16 times seq_len * n_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128 * data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 26 at dim 1 (got 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7287/2267183817.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 26 at dim 1 (got 20)"
     ]
    }
   ],
   "source": [
    "torch.as_tensor(tuple(batch['targets']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 36, 24, 31, 21, 18, 27, 31, 15, 26, 26, 18, 17, 15, 18, 38])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=125)\n",
    "len(padded_targets)\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 125])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(padded_targets).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.0000e+01, 2.3400e+02, 1.7790e+03, 1.5990e+03, 0.0000e+00, 1.0180e+03,\n",
       "          1.0180e+03, 1.0180e+03, 1.0180e+03, 1.6470e+03, 1.4830e+03, 1.2370e+03,\n",
       "          1.0360e+03, 0.0000e+00, 8.2300e+02, 6.0400e+02, 8.5300e+02, 4.0200e+02,\n",
       "          1.0180e+03, 6.0400e+02, 4.2600e+02, 1.6180e+03, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [7.0000e+00, 2.2800e+02, 1.7800e+03, 1.7220e+03, 9.8300e+02, 0.0000e+00,\n",
       "          9.8300e+02, 9.8300e+02, 0.0000e+00, 3.8100e+02, 5.6100e+02, 7.7900e+02,\n",
       "          0.0000e+00, 9.9200e+02, 7.9000e+02, 5.5600e+02, 0.0000e+00, 3.7400e+02,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.2900e+02, 1.7800e+03, 2.6600e+02, 0.0000e+00, 1.7270e+03,\n",
       "          1.5990e+03, 1.5990e+03, 8.2300e+02, 1.3030e+03, 1.0190e+03, 8.5300e+02,\n",
       "          0.0000e+00, 5.8100e+02, 1.5990e+03, 6.7800e+02, 8.2300e+02, 4.9000e+02,\n",
       "          1.5990e+03, 8.2400e+02, 1.0440e+03, 0.0000e+00, 5.9500e+02, 1.5990e+03,\n",
       "          1.5990e+03, 8.2300e+02, 1.3030e+03, 1.0190e+03, 1.4790e+03, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.3400e+02, 1.7570e+03, 5.6100e+02, 9.9200e+02, 1.6170e+03,\n",
       "          0.0000e+00, 1.1790e+03, 4.1800e+02, 0.0000e+00, 4.1800e+02, 1.6170e+03,\n",
       "          4.1800e+02, 0.0000e+00, 5.9000e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.3100e+02, 1.7790e+03, 4.3400e+02, 0.0000e+00, 4.3400e+02,\n",
       "          0.0000e+00, 4.3400e+02, 1.7410e+03, 0.0000e+00, 4.3400e+02, 0.0000e+00,\n",
       "          4.3400e+02, 0.0000e+00, 4.3400e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.2900e+02, 1.7800e+03, 1.7270e+03, 0.0000e+00, 2.6100e+02,\n",
       "          0.0000e+00, 1.3070e+03, 1.0360e+03, 8.4400e+02, 0.0000e+00, 8.2300e+02,\n",
       "          6.7800e+02, 6.8700e+02, 1.7220e+03, 0.0000e+00, 1.4610e+03, 1.3130e+03,\n",
       "          1.0360e+03, 0.0000e+00, 1.0180e+03, 8.2300e+02, 8.4400e+02, 1.7220e+03,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.3100e+02, 1.7790e+03, 2.6000e+02, 0.0000e+00, 8.3200e+02,\n",
       "          6.8200e+02, 0.0000e+00, 8.3200e+02, 1.0360e+03, 1.0360e+03, 0.0000e+00,\n",
       "          4.0800e+02, 4.1800e+02, 1.4260e+03, 0.0000e+00, 1.6060e+03, 1.4260e+03,\n",
       "          1.6170e+03, 0.0000e+00, 4.0800e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.2800e+02, 1.7800e+03, 1.0440e+03, 0.0000e+00, 1.0260e+03,\n",
       "          1.7410e+03, 1.0440e+03, 1.4330e+03, 1.6250e+03, 4.2600e+02, 6.0400e+02,\n",
       "          8.5100e+02, 1.0440e+03, 1.2320e+03, 0.0000e+00, 1.4590e+03, 1.7410e+03,\n",
       "          1.4770e+03, 4.2600e+02, 6.0400e+02, 8.5100e+02, 1.0440e+03, 1.2320e+03,\n",
       "          1.4770e+03, 1.6710e+03, 0.0000e+00, 4.4700e+02, 1.7410e+03, 4.4100e+02,\n",
       "          6.3100e+02, 4.6000e+02, 1.6710e+03, 1.4770e+03, 1.2320e+03, 1.0440e+03,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.2800e+02, 1.7570e+03, 6.2000e+02, 1.0750e+03, 8.8900e+02,\n",
       "          6.2000e+02, 6.2000e+02, 6.2000e+02, 6.2000e+02, 0.0000e+00, 6.2700e+02,\n",
       "          1.7270e+03, 1.7270e+03, 0.0000e+00, 8.7000e+02, 1.2520e+03, 8.8900e+02,\n",
       "          8.7000e+02, 8.7000e+02, 8.7000e+02, 8.7000e+02, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.2300e+02, 1.7510e+03, 1.4050e+03, 6.7800e+02, 1.4050e+03,\n",
       "          6.7800e+02, 0.0000e+00, 1.2400e+02, 8.5300e+02, 6.9200e+02, 8.5300e+02,\n",
       "          1.0440e+03, 8.4400e+02, 0.0000e+00, 1.4540e+03, 1.3030e+03, 8.2300e+02,\n",
       "          4.0200e+02, 0.0000e+00, 9.9000e+01, 6.9200e+02, 4.2600e+02, 6.9200e+02,\n",
       "          8.5300e+02, 6.8700e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [9.0000e+00, 2.3400e+02, 1.7570e+03, 1.6630e+03, 6.2700e+02, 6.3100e+02,\n",
       "          8.9100e+02, 1.0590e+03, 0.0000e+00, 6.2700e+02, 1.6630e+03, 4.5300e+02,\n",
       "          0.0000e+00, 6.2700e+02, 4.5300e+02, 1.6630e+03, 0.0000e+00, 1.4670e+03,\n",
       "          1.0360e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.2900e+02, 1.7510e+03, 2.8300e+02, 0.0000e+00, 1.3130e+03,\n",
       "          6.7900e+02, 6.9200e+02, 0.0000e+00, 1.6640e+03, 1.4790e+03, 1.3180e+03,\n",
       "          0.0000e+00, 8.2300e+02, 8.2300e+02, 1.7170e+03, 1.3030e+03, 0.0000e+00,\n",
       "          1.0360e+03, 1.7410e+03, 1.0440e+03, 5.1800e+02, 1.4790e+03, 1.0440e+03,\n",
       "          0.0000e+00, 1.3030e+03, 1.3030e+03, 1.7270e+03, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 2.2800e+02, 1.7510e+03, 1.0190e+03, 1.2320e+03, 1.4520e+03,\n",
       "          1.2320e+03, 0.0000e+00, 1.0180e+03, 4.0200e+02, 1.0180e+03, 1.7170e+03,\n",
       "          0.0000e+00, 1.4520e+03, 1.6710e+03, 4.4200e+02, 1.6710e+03, 0.0000e+00,\n",
       "          1.4510e+03, 1.0180e+03, 1.4510e+03, 1.7170e+03, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+01, 1.7790e+03, 1.0270e+03, 8.4100e+02, 0.0000e+00, 1.0270e+03,\n",
       "          8.2300e+02, 5.8300e+02, 0.0000e+00, 8.3000e+02, 1.7270e+03, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [3.0000e+00, 1.7790e+03, 2.7200e+02, 0.0000e+00, 1.7220e+03, 1.7170e+03,\n",
       "          1.1740e+03, 4.0200e+02, 5.8300e+02, 0.0000e+00, 8.5300e+02, 4.2600e+02,\n",
       "          1.5960e+03, 4.2600e+02, 8.5300e+02, 5.8300e+02, 1.1740e+03, 1.7170e+03,\n",
       "          1.7270e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.0000e+00, 2.2300e+02, 1.7800e+03, 2.6500e+02, 0.0000e+00, 1.7220e+03,\n",
       "          1.7270e+03, 1.6170e+03, 0.0000e+00, 8.2300e+02, 1.3030e+03, 1.0180e+03,\n",
       "          1.4540e+03, 1.3030e+03, 1.0180e+03, 0.0000e+00, 8.2300e+02, 6.7800e+02,\n",
       "          8.3200e+02, 6.7800e+02, 4.9000e+02, 0.0000e+00, 1.6170e+03, 1.4700e+03,\n",
       "          1.4700e+03, 1.0360e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " tensor([23, 18, 30, 15, 16, 25, 21, 37, 23, 27, 19, 29, 23, 11, 20, 27])]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_targets_list = [torch.tensor(padded_targets[i]) for i in range(0,len(padded_targets))]\n",
    "padded_targets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29, 31, 23, 26, 37, 27, 22, 23, 13, 20, 20, 21, 17, 30, 24, 25])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1743"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1782])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1520"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(target_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "# num steps: IMAGE WIDTH\n",
    "# batch size 16\n",
    "# n_inputs 64 * 14 (from CNN output)\n",
    "# output of CNN: (64 by 14 by width) - width same across batch\n",
    "\n",
    "class ImageRNN(nn.Module):\n",
    "    def __init__(self, batch_size = 16, n_inputs = 896, n_neurons = 4, n_outputs = vocabulary_size +1): # N_ STEPS AFTER BATCH_SIZE\n",
    "        super(ImageRNN, self).__init__()\n",
    "        \n",
    "        self.n_neurons = n_neurons\n",
    "        #self.batch_size = batch_size\n",
    "        #self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n",
    "        \n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, batch_size, self.n_neurons))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        #X = X.permute(1, 0, 2) \n",
    "        # maybe batch size should be width\n",
    "        # each batch is 1 by 64 by 14\n",
    "        \n",
    "        self.batch_size = X.size(2)\n",
    "        self.hidden = self.init_hidden(self.batch_size)\n",
    "        \n",
    "        # try using a loop - delete this if it breaks\n",
    "        #lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
    "        #out = self.FC(self.hidden)\n",
    "        out = []\n",
    "        \n",
    "        for x in X:\n",
    "            lstm_out, self.hidden = self.basic_rnn(x, self.hidden)\n",
    "            out_step = self.FC(self.hidden)\n",
    "            out.append(out_step)\n",
    "            \n",
    "            \n",
    "        return out#.view(-1, self.n_outputs) # batch_size X n_output\n",
    "    #output represent log prob of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 14, 211])\n",
      "torch.Size([14, 211])\n",
      "torch.Size([16, 1, 211, 896])\n",
      "torch.Size([1, 211, 1782])\n",
      "torch.Size([211, 1782])\n",
      "torch.Size([1782])\n",
      "[106.75 106.75 106.75 106.75 106.75 106.75 106.75 106.75 106.75 106.75\n",
      " 106.75 106.75 106.75 106.75 106.75 106.75]\n",
      "211\n",
      "(211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211)\n",
      "torch.Size([211, 16, 1782])\n",
      "Loss: %f -6.995432376861572\n",
      "torch.Size([64, 14, 248])\n",
      "torch.Size([14, 248])\n",
      "torch.Size([16, 1, 248, 896])\n",
      "torch.Size([1, 248, 1782])\n",
      "torch.Size([248, 1782])\n",
      "torch.Size([1782])\n",
      "[125.125 125.125 125.125 125.125 125.125 125.125 125.125 125.125 125.125\n",
      " 125.125 125.125 125.125 125.125 125.125 125.125 125.125]\n",
      "248\n",
      "(248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248, 248)\n",
      "torch.Size([248, 16, 1782])\n",
      "Loss: %f -14.697241306304932\n",
      "torch.Size([64, 14, 195])\n",
      "torch.Size([14, 195])\n",
      "torch.Size([16, 1, 195, 896])\n",
      "torch.Size([1, 195, 1782])\n",
      "torch.Size([195, 1782])\n",
      "torch.Size([1782])\n",
      "[98.8125 98.8125 98.8125 98.8125 98.8125 98.8125 98.8125 98.8125 98.8125\n",
      " 98.8125 98.8125 98.8125 98.8125 98.8125 98.8125 98.8125]\n",
      "195\n",
      "(195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195, 195)\n",
      "torch.Size([195, 16, 1782])\n",
      "Loss: %f -21.753282070159912\n",
      "torch.Size([64, 14, 250])\n",
      "torch.Size([14, 250])\n",
      "torch.Size([16, 1, 250, 896])\n",
      "torch.Size([1, 250, 1782])\n",
      "torch.Size([250, 1782])\n",
      "torch.Size([1782])\n",
      "[126.0625 126.0625 126.0625 126.0625 126.0625 126.0625 126.0625 126.0625\n",
      " 126.0625 126.0625 126.0625 126.0625 126.0625 126.0625 126.0625 126.0625]\n",
      "250\n",
      "(250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250)\n",
      "torch.Size([250, 16, 1782])\n",
      "Loss: %f -29.43127679824829\n",
      "torch.Size([64, 14, 186])\n",
      "torch.Size([14, 186])\n",
      "torch.Size([16, 1, 186, 896])\n",
      "torch.Size([1, 186, 1782])\n",
      "torch.Size([186, 1782])\n",
      "torch.Size([1782])\n",
      "[94.1875 94.1875 94.1875 94.1875 94.1875 94.1875 94.1875 94.1875 94.1875\n",
      " 94.1875 94.1875 94.1875 94.1875 94.1875 94.1875 94.1875]\n",
      "186\n",
      "(186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186, 186)\n",
      "torch.Size([186, 16, 1782])\n",
      "Loss: %f -35.20119905471802\n",
      "torch.Size([64, 14, 265])\n",
      "torch.Size([14, 265])\n",
      "torch.Size([16, 1, 265, 896])\n",
      "torch.Size([1, 265, 1782])\n",
      "torch.Size([265, 1782])\n",
      "torch.Size([1782])\n",
      "[133.4375 133.4375 133.4375 133.4375 133.4375 133.4375 133.4375 133.4375\n",
      " 133.4375 133.4375 133.4375 133.4375 133.4375 133.4375 133.4375 133.4375]\n",
      "265\n",
      "(265, 265, 265, 265, 265, 265, 265, 265, 265, 265, 265, 265, 265, 265, 265, 265)\n",
      "torch.Size([265, 16, 1782])\n",
      "Loss: %f -42.728631019592285\n",
      "torch.Size([64, 14, 206])\n",
      "torch.Size([14, 206])\n",
      "torch.Size([16, 1, 206, 896])\n",
      "torch.Size([1, 206, 1782])\n",
      "torch.Size([206, 1782])\n",
      "torch.Size([1782])\n",
      "[104. 104. 104. 104. 104. 104. 104. 104. 104. 104. 104. 104. 104. 104.\n",
      " 104. 104.]\n",
      "206\n",
      "(206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206, 206)\n",
      "torch.Size([206, 16, 1782])\n",
      "Loss: %f -48.453718185424805\n",
      "torch.Size([64, 14, 198])\n",
      "torch.Size([14, 198])\n",
      "torch.Size([16, 1, 198, 896])\n",
      "torch.Size([1, 198, 1782])\n",
      "torch.Size([198, 1782])\n",
      "torch.Size([1782])\n",
      "[100.1875 100.1875 100.1875 100.1875 100.1875 100.1875 100.1875 100.1875\n",
      " 100.1875 100.1875 100.1875 100.1875 100.1875 100.1875 100.1875 100.1875]\n",
      "198\n",
      "(198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198, 198)\n",
      "torch.Size([198, 16, 1782])\n",
      "Loss: %f -55.21089506149292\n",
      "torch.Size([64, 14, 289])\n",
      "torch.Size([14, 289])\n",
      "torch.Size([16, 1, 289, 896])\n",
      "torch.Size([1, 289, 1782])\n",
      "torch.Size([289, 1782])\n",
      "torch.Size([1782])\n",
      "[145.5625 145.5625 145.5625 145.5625 145.5625 145.5625 145.5625 145.5625\n",
      " 145.5625 145.5625 145.5625 145.5625 145.5625 145.5625 145.5625 145.5625]\n",
      "289\n",
      "(289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289, 289)\n",
      "torch.Size([289, 16, 1782])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-e6e8ed1319fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m#loss = criterion(log_probs, padded_targets_tensor, input_len, target_shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_of_target_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train using ImageRNN\n",
    "\n",
    "# SETUP\n",
    "\n",
    "learning_rate = 0.000001\n",
    "criterion = torch.nn.CTCLoss()\n",
    "model_cnn = cnn_model(BATCH_SIZE)\n",
    "model_rnn = ImageRNN()\n",
    "optimizer = optim.Adam(list(model_cnn.parameters()) + list(model_rnn.parameters()), lr = learning_rate)\n",
    "len_data = len(primus.training_list) + len(primus.validation_list)\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    model_cnn.train()\n",
    "    model_rnn.train()\n",
    "    \n",
    "    for i in range(0, len_data, BATCH_SIZE):\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        # Get inputs\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs'] # size (batch, height, width, channels)\n",
    "        #print(data)\n",
    "        #print(data.shape)\n",
    "        max_input_length = data.shape[2]\n",
    "        \n",
    "        # list of indices, values, shape\n",
    "        seq_len = int(batch['seq_lengths'][0])\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        #print(tuple(targets[2]))\n",
    "        #print(type(t[0]) for t in targets)\n",
    "        #targets = torch.sparse_coo_tensor(targets[0], targets[1], tuple(targets[2]))\n",
    "        targets_0 = torch.as_tensor((targets[0]))\n",
    "        #print(targets.shape)\n",
    "        #targets = torch.reshape(targets, (16, 1))\n",
    "        padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=max_input_length)\n",
    "        padded_targets_tensor = torch.tensor(padded_targets)\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        #print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        # forward, backward, optim\n",
    "        cnn_output = model_cnn(tensor_data_reshape)\n",
    "        output_size = 64 * 14 * cnn_output.shape[3]\n",
    "        #print(cnn_output.shape)\n",
    "        #print(cnn_output[0])\n",
    "        print(cnn_output[0].shape)\n",
    "        print(cnn_output[0][0].shape)\n",
    "        \n",
    "        # Change shape for rnn\n",
    "        #output = torch.reshape(cnn_output, (cnn_output.shape[3], 16, 64 * 14)) # width, batch, features\n",
    "        \n",
    "        # SEE IF LOOP OVER OUTPUT\n",
    "        output = torch.reshape(cnn_output, (16, 1, cnn_output.shape[3], 64*14))\n",
    "        \n",
    "        print(output.shape)\n",
    "        \n",
    "        \n",
    "        # reset hidden states\n",
    "        model_rnn.hidden = model_rnn.init_hidden(BATCH_SIZE)\n",
    "        logits = model_rnn(output)\n",
    "        print(logits[0].shape) #1 by width by vocab size\n",
    "        print((logits[0][0].shape))\n",
    "        print(logits[0][0][0].shape) # this is logits for one column of picture\n",
    "        print(batch['seq_lengths'])\n",
    "        \n",
    "        for t in range(0,len(logits)):\n",
    "            logits[t] = torch.reshape(logits[t],(logits[t].size(1), logits[t].size(2)))\n",
    "        print(logits[0].shape[0])\n",
    "        \n",
    "        batch_size = logits[0].shape[0]\n",
    "        logits_tensor = torch.stack(logits)\n",
    "        logits_tensor = torch.permute(logits_tensor, (1,0,2))\n",
    "        \n",
    "        #rnn_output_reshape = torch.reshape(rnn_output, (cnn_output[0].shape[2], BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = torch.reshape(rnn_output[0], (1, BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = rnn_output[0].view(-1, BATCH_SIZE, N_OUTPUTS)\n",
    "        \n",
    "        # change targets to 1D tensor\n",
    "\n",
    "        list_of_target_tensors = []\n",
    "        lens = 0\n",
    "        for i in range(0,16):\n",
    "            list_of_target_tensors.append(torch.as_tensor(batch['targets'][i]))\n",
    "            lens += len(batch['targets'][i])\n",
    "        list_of_target_tensors\n",
    "        tensor_of_target_tensors = torch.cat(list_of_target_tensors)\n",
    "        #tensor_of_target_tensors.size() \n",
    "\n",
    "\n",
    "        #log_probs = nn.functional.log_softmax(rnn_output, dim=0)\n",
    "        #Input and target shape\n",
    "        #print(rnn_output_reshape.shape)\n",
    "        input_shape = (BATCH_SIZE, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        input_len = tuple([batch_size for i in range (0, 16)])\n",
    "        #print(input_shape)\n",
    "        print(input_len)\n",
    "        print(logits_tensor.shape)\n",
    "        target_shape = tuple(int(b) for b in batch['seq_lengths'])\n",
    "        \n",
    "        # MUST BE TENSOR, TENSOR, TUPLE, TUPLE OR TENSOR TENSOR TENSOR TENSOR\n",
    "        #loss = criterion(rnn_output_reshape, padded_targets_tensor, input_len, target_shape)\n",
    "        #loss = criterion(log_probs, padded_targets_tensor, input_len, target_shape)\n",
    "        loss = criterion(logits_tensor, tensor_of_target_tensors, input_len, tuple(lengths))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0\n",
    "        print(\"Loss: %f\", train_loss)\n",
    "        \n",
    "    #model.eval()\n",
    "    print('training loss:')\n",
    "    print(train_loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change targets to 1D tensor\n",
    "\n",
    "list_of_target_tensors = []\n",
    "lens = 0\n",
    "for i in range(0,16):\n",
    "    list_of_target_tensors.append(torch.as_tensor(batch['targets'][i]))\n",
    "    lens += len(batch['targets'][i])\n",
    "list_of_target_tensors\n",
    "tensor_of_target_tensors = torch.cat(list_of_target_tensors)\n",
    "tensor_of_target_tensors.size() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([254, 16, 1782])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/myranda/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:106: UserWarning: \n",
      "NVIDIA GeForce RTX 3070 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-28c2ff9f7473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                         \u001b[0mnum_weights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                     torch._cudnn_rnn_flatten_weight(\n\u001b[0m\u001b[1;32m    176\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# Try to use GPU\n",
    "# Train using ImageRNN\n",
    "\n",
    "# SETUP\n",
    "model_cnn = cnn_model(BATCH_SIZE)\n",
    "model_rnn = ImageRNN()\n",
    "optimizer = optim.Adam(list(model_cnn.parameters()) + list(model_rnn.parameters()))\n",
    "len_data = len(primus.training_list) + len(primus.validation_list)\n",
    "\n",
    "model_cnn.to(device)\n",
    "model_rnn.to(device)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    model_cnn.train()\n",
    "    model_rnn.train()\n",
    "    \n",
    "    for i in range(0, len_data, BATCH_SIZE):\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        model_rnn.hidden = basic_rnn.init_hidden()\n",
    "        \n",
    "        # Get inputs\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs'] # size (batch, height, width, channels)\n",
    "        data = data.to(device)\n",
    "        #print(data)\n",
    "        #print(data.shape)\n",
    "        max_input_length = data.shape[2]\n",
    "        \n",
    "        # list of indices, values, shape\n",
    "        seq_len = int(batch['seq_lengths'][0])\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        #print(tuple(targets[2]))\n",
    "        #print(type(t[0]) for t in targets)\n",
    "        #targets = torch.sparse_coo_tensor(targets[0], targets[1], tuple(targets[2]))\n",
    "        targets_0 = torch.as_tensor((targets[0]))\n",
    "        #print(targets.shape)\n",
    "        #targets = torch.reshape(targets, (16, 1))\n",
    "        padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=max_input_length)\n",
    "        padded_targets_tensor = torch.tensor(padded_targets)\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        #print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        # forward, backward, optim\n",
    "        cnn_output = model_cnn(tensor_data_reshape)\n",
    "        output_size = 64 * 14 * cnn_output.shape[3]\n",
    "        #print(cnn_output.shape)\n",
    "        #print(cnn_output[0])\n",
    "        print(cnn_output[0].shape)\n",
    "        print(cnn_output[0][0].shape)\n",
    "        \n",
    "        # Change shape for rnn\n",
    "        #output = torch.reshape(cnn_output, (cnn_output.shape[3], 16, 64 * 14)) # width, batch, features\n",
    "        \n",
    "        # SEE IF LOOP OVER OUTPUT\n",
    "        output = torch.reshape(cnn_output, (16, 1, cnn_output.shape[3], 64*14))\n",
    "        \n",
    "        print(output.shape)\n",
    "        logits = model_rnn(output)\n",
    "        print(logits[0].shape) #1 by width by vocab size\n",
    "        print((logits[0][0].shape))\n",
    "        print(logits[0][0][0].shape) # this is logits for one column of picture\n",
    "        print(batch['seq_lengths'])\n",
    "        \n",
    "        for t in range(0,len(logits)):\n",
    "            logits[t] = torch.reshape(logits[t],(logits[t].size(1), logits[t].size(2)))\n",
    "        print(logits[0].shape[0])\n",
    "        \n",
    "        batch_size = logits[0].shape[0]\n",
    "        logits_tensor = torch.stack(logits)\n",
    "        logits_tensor = torch.permute(logits_tensor, (1,0,2))\n",
    "        \n",
    "        #rnn_output_reshape = torch.reshape(rnn_output, (cnn_output[0].shape[2], BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = torch.reshape(rnn_output[0], (1, BATCH_SIZE, N_OUTPUTS))\n",
    "        #rnn_output_reshape = rnn_output[0].view(-1, BATCH_SIZE, N_OUTPUTS)\n",
    "        \n",
    "        \n",
    "        #log_probs = nn.functional.log_softmax(rnn_output, dim=0)\n",
    "        #Input and target shape\n",
    "        #print(rnn_output_reshape.shape)\n",
    "        input_shape = (BATCH_SIZE, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        input_len = tuple([batch_size for i in range (0, 16)])\n",
    "        #print(input_shape)\n",
    "        print(input_len)\n",
    "        print(logits_tensor.shape)\n",
    "        target_shape = tuple(int(b) for b in batch['seq_lengths'])\n",
    "        \n",
    "        # MUST BE TENSOR, TENSOR, TUPLE, TUPLE OR TENSOR TENSOR TENSOR TENSOR\n",
    "        #loss = criterion(rnn_output_reshape, padded_targets_tensor, input_len, target_shape)\n",
    "        #loss = criterion(log_probs, padded_targets_tensor, input_len, target_shape)\n",
    "        loss = criterion(logits_tensor, padded_targets_tensor, input_len, tuple(lengths))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0\n",
    "        print(\"Loss: %f\", train_loss)\n",
    "        \n",
    "    #model.eval()\n",
    "    print('training loss:')\n",
    "    print(train_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'torch.cuda' from '/home/myranda/.local/lib/python3.8/site-packages/torch/cuda/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n",
      "896\n"
     ]
    }
   ],
   "source": [
    "for x in output:\n",
    "    print(x.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 2884])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27213/3229910390.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mrnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m#print(batch['seq_lengths'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_27213/135853732.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#lstm_out, self.hidden = self.basic_rnn(X, self.hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# DEBUGGING\n",
    "# Train\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    #model.train()\n",
    "    \n",
    "    for i in range(0, len_data, BATCH_SIZE):\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # reset hidden states\n",
    "        basic_rnn.hidden = basic_rnn.init_hidden()\n",
    "        \n",
    "        # Get inputs\n",
    "        batch = primus.nextBatch(params)\n",
    "\n",
    "        data = batch['inputs'] # size (batch, height, width, channels)\n",
    "        #print(data)\n",
    "        #print(data.shape)\n",
    "        max_input_length = data.shape[2]\n",
    "        \n",
    "        # list of indices, values, shape\n",
    "        seq_len = int(batch['seq_lengths'][0])\n",
    "        targets = ctc_utils.sparse_tuple_from(batch['targets'])\n",
    "        #print(tuple(targets[2]))\n",
    "        #print(type(t[0]) for t in targets)\n",
    "        #targets = torch.sparse_coo_tensor(targets[0], targets[1], tuple(targets[2]))\n",
    "        targets_0 = torch.as_tensor((targets[0]))\n",
    "        #print(targets.shape)\n",
    "        #targets = torch.reshape(targets, (16, 1))\n",
    "        padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=max_input_length)\n",
    "        padded_targets_tensor = torch.tensor(padded_targets)\n",
    "        \n",
    "        tensor_data = torch.from_numpy(data)\n",
    "        #print(tensor_data.shape)\n",
    "        tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "        \n",
    "        # forward, backward, optim\n",
    "        cnn_output = model_cnn(tensor_data_reshape)\n",
    "        \n",
    "        # Change shape for rnn\n",
    "        output = cnn_output.view(cnn_output.size(0), cnn_output.size(1), -1)\n",
    "        print(output.shape)\n",
    "        output.permute(2,0,1)\n",
    "        rnn_output = basic_rnn(output)\n",
    "        print(rnn_output.shape)\n",
    "        #print(batch['seq_lengths'])\n",
    "        \n",
    "        #rnn_output_reshape = torch.reshape(rnn_output, (cnn_output[0].shape[2], BATCH_SIZE, N_OUTPUTS))\n",
    "        rnn_output_reshape = torch.reshape(rnn_output, (1, BATCH_SIZE, N_OUTPUTS))\n",
    "        \n",
    "        log_probs = nn.functional.log_softmax(rnn_output_reshape)\n",
    "        #Input and target shape\n",
    "        #print(rnn_output_reshape.shape)\n",
    "        input_shape = (BATCH_SIZE, params['img_height'], tensor_data_reshape.shape[3],1)\n",
    "        input_len = tuple([1 for i in range (0, BATCH_SIZE)])\n",
    "        #print(input_shape)\n",
    "        target_shape = tuple(int(b) for b in batch['seq_lengths'])\n",
    "        \n",
    "        # MUST BE TENSOR, TENSOR, TUPLE, TUPLE OR TENSOR TENSOR TENSOR TENSOR\n",
    "        #loss = criterion(rnn_output_reshape, padded_targets_tensor, input_len, target_shape)\n",
    "        loss = criterion(log_probs, padded_targets_tensor, input_len, target_shape)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.detach().item()\n",
    "        train_acc += 0\n",
    "        \n",
    "    #model.eval()\n",
    "    print('training loss:')\n",
    "    print(train_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:115] . file in archive is not in a subdirectory: semantic_model.data-00000-of-00001",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9439/3612140687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Models/Semantic-Model.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;31m# reset back to the original position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                     warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:115] . file in archive is not in a subdirectory: semantic_model.data-00000-of-00001"
     ]
    }
   ],
   "source": [
    "torch.load('./Models/Semantic-Model.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
