{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47884c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMR Model \n",
    "# Goal: recognize images of music excerpts\n",
    "\n",
    "# Modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import ctc_utils\n",
    "from primus import CTC_PriMuS\n",
    "from torch import cuda\n",
    "\n",
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02630ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 70880 and validating with 7875\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "corpus = './Data/package'# PATH\n",
    "set = 'Data/train.txt' \n",
    "vocabulary = 'Data/vocabulary_semantic.txt'  \n",
    "save_model = './trained_\\semantic_model'\n",
    "\n",
    "primus = CTC_PriMuS(corpus, set, vocabulary, semantic = True, val_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6657c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "img_height = 128\n",
    "N_EPOCHS = 10\n",
    "dropout = 0.5\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "vocabulary_size = primus.vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e353e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default params\n",
    "# With image height of 128, width will be 1870\n",
    "params = dict()\n",
    "params['img_height'] = img_height\n",
    "params['img_width'] = None\n",
    "params['batch_size'] = 16\n",
    "params['img_channels'] = 1\n",
    "params['conv_blocks'] = 4\n",
    "params['conv_filter_n'] = [32, 64, 128, 256]\n",
    "params['conv_filter_size'] = [ [3,3], [3,3], [3,3], [3,3] ]\n",
    "params['conv_pooling_size'] = [ [2,2], [2,2], [2,2], [2,2] ]\n",
    "params['rnn_units'] = 512\n",
    "params['rnn_layers'] = 2\n",
    "params['vocabulary_size'] = vocabulary_size\n",
    "params['max_width'] = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0779cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Classes\n",
    "\n",
    "class cnn_model(torch.nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(cnn_model, self).__init__()\n",
    "\n",
    "        kernel_size = [3,3]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size = kernel_size)\n",
    "        self.batch1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16,32, kernel_size = kernel_size)\n",
    "        self.batch2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size = kernel_size)\n",
    "        self.batch3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.act = nn.LeakyReLU()\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # FORWARD PASS\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        output = x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57b1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop RNN\n",
    "# num steps: IMAGE WIDTH\n",
    "# batch size 16\n",
    "# n_inputs 64 * 14 (from CNN output)\n",
    "# output of CNN: (64 by 14 by width) - width same across batch\n",
    "\n",
    "class LoopRNN(nn.Module):\n",
    "    def __init__(self, batch_size = 16, n_inputs = 896, n_neurons = 4, n_outputs = vocabulary_size +1): # N_ STEPS AFTER BATCH_SIZE\n",
    "        super(LoopRNN, self).__init__()\n",
    "        \n",
    "        self.n_neurons = n_neurons\n",
    "        #self.batch_size = batch_size\n",
    "        #self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n",
    "        \n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, batch_size, self.n_neurons))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        #X = X.permute(1, 0, 2) \n",
    "        # maybe batch size should be width\n",
    "        # each batch is 1 by 64 by 14\n",
    "        \n",
    "        self.batch_size = X.size(2)\n",
    "        self.hidden = self.init_hidden(self.batch_size)\n",
    "        \n",
    "        # try using a loop - delete this if it breaks\n",
    "        #lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
    "        #out = self.FC(self.hidden)\n",
    "        out = []\n",
    "        \n",
    "        for x in X:\n",
    "            lstm_out, self.hidden = self.basic_rnn(x, self.hidden)\n",
    "            out_step = self.FC(self.hidden)\n",
    "            out.append(out_step)\n",
    "\n",
    "            \n",
    "        return out#.view(-1, self.n_outputs) # batch_size X n_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f951988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTC Loss (homemade from Medium article recipe)\n",
    "\n",
    "def ctcloss_reference(log_probs, targets, input_lengths, target_lengths, blank=0, reduction='mean'):\n",
    "    \n",
    "    input_lengths = torch.as_tensor(input_lengths, dtype=torch.long)\n",
    "    target_lengths = torch.as_tensor(target_lengths, dtype=torch.long)\n",
    "    dt = log_probs.dtype\n",
    "    log_probs = log_probs.double()\n",
    "    targets = targets.long()\n",
    "    cum_target_lengths = target_lengths.cumsum(0)\n",
    "    losses = []\n",
    "    \n",
    "    for i in range(log_probs.size(1)):\n",
    "        input_length = input_lengths[i].item()\n",
    "        target_length = target_lengths[i].item()\n",
    "        cum_target_length = cum_target_lengths[i].item()\n",
    "        \n",
    "        # fill target sequences with blank symbol\n",
    "        targets_prime = targets.new_full((2 * target_length + 1,), blank)\n",
    "        \n",
    "        \n",
    "        # Then fill every odd value with target symbol\n",
    "        if targets.dim() ==2:\n",
    "                targets_prime[1::2] = targets[i, :target_length]\n",
    "                \n",
    "        else:\n",
    "            targets_prime[1::2] = targets[cum_target_length - target_length:cum_target_length]\n",
    "        \n",
    "        # convert original inputs from log space by exponentiating\n",
    "        probs = log_probs[:input_length, i].exp()\n",
    "        \n",
    "        # the length is the same as the target sequences\n",
    "        alpha = log_probs.new_zeros((target_length * 2 + 1,))\n",
    "        alpha[0] = probs[0, blank]\n",
    "        alpha[1] = probs[0, targets_prime[1]]\n",
    "        \n",
    "        # this mask is only true when a[current] != a[current - 2]\n",
    "        # please note that every odd element is blank, so this condition never holds for them\n",
    "        mask_third = (targets_prime[:-2] != targets_prime[2:])\n",
    "        \n",
    "        for t in range(1, input_length):\n",
    "            alpha_next = alpha.clone()\n",
    "            \n",
    "            # we always add a[current-1] to a[current]\n",
    "            alpha_next[1:] += alpha[:-1]\n",
    "            \n",
    "            # but we add a[current-2] to a[current] only when mask condition is true\n",
    "            alpha_next[2:] += torch.where(mask_third, alpha[:-2], alpha.new_zeros(1))\n",
    "            alpha = probs[t, targets_prime] * alpha_next\n",
    "            \n",
    "        # to evaluate maximum likelihodd error, we need the natural logs of the target labelling probs\n",
    "        losses.append(-alpha[-2:].sum().log()[None])\n",
    "        \n",
    "        output = torch.cat(losses, 0)\n",
    "        \n",
    "        if reduction == 'mean':\n",
    "            return (output / target_lengths.to(dtype=output.dtype, device=output.device)).mean()\n",
    "        \n",
    "        elif reduction == 'sum':\n",
    "            return output.sum()\n",
    "        \n",
    "        output = output.to(dt)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a010768",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "criterion = torch.nn.CTCLoss()\n",
    "model_cnn = cnn_model(BATCH_SIZE)\n",
    "model_rnn = LoopRNN()\n",
    "optimizer = optim.Adam(list(model_cnn.parameters()) + list(model_rnn.parameters()), lr = learning_rate)\n",
    "len_data = len(primus.training_list) + len(primus.validation_list)\n",
    "\n",
    "len_data_train = len(primus.training_list)\n",
    "len_data_valid = len(primus.validation_list)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "gpu = cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ade633d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/myranda/miniconda3/lib/python3.7/site-packages/torch/cuda/__init__.py:143: UserWarning: \n",
      "NVIDIA GeForce RTX 3070 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13660/1419429967.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mmodel_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mmodel_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mtensor_data_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_data_reshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                         self.batch_first, bool(self.bidirectional))\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    valid_loss = 0\n",
    "    \n",
    "    model_cnn.train()\n",
    "    model_rnn.train()\n",
    "    \n",
    "    for i in range(0, len_data, BATCH_SIZE):\n",
    "        \n",
    "        # Training\n",
    "        if i < len_data_train:\n",
    "            # zero parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get inputs\n",
    "            batch = primus.nextBatch(params)\n",
    "\n",
    "            data = batch['inputs'] # size (batch, height, width, channels)\n",
    "            max_input_length = data.shape[2]\n",
    "            padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=max_input_length)\n",
    "\n",
    "            tensor_data = torch.from_numpy(data)\n",
    "\n",
    "            tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "            \n",
    "            if gpu:\n",
    "                model_cnn = model_cnn.cuda()\n",
    "                model_rnn = model_rnn.cuda()\n",
    "                tensor_data_reshape = tensor_data_reshape.cuda()\n",
    "                \n",
    "\n",
    "            # forward, backward, optim\n",
    "            cnn_output = model_cnn(tensor_data_reshape)\n",
    "\n",
    "            output_to_loop = torch.reshape(cnn_output, (16, 1, cnn_output.shape[3], 64*14))\n",
    "\n",
    "            model_rnn.hidden = model_rnn.init_hidden(BATCH_SIZE)\n",
    "            loop_output = model_rnn(output_to_loop)\n",
    "\n",
    "            for t in range(0,len(loop_output)):\n",
    "                loop_output[t] = torch.reshape(loop_output[t],(loop_output[t].size(1), loop_output[t].size(2)))\n",
    "\n",
    "            loop_tensor = torch.stack(loop_output)\n",
    "\n",
    "            # Reshape to correct shape for Medium article\n",
    "            loop_tensor = torch.permute(loop_tensor, (1,0,2))\n",
    "\n",
    "\n",
    "            # Convert to log softmax\n",
    "            loop_logits = log_softmax(loop_tensor)\n",
    "\n",
    "            #Target to tensor\n",
    "            list_of_target_tensors = []\n",
    "            lens = 0\n",
    "            for i in range(0,16):\n",
    "                list_of_target_tensors.append(torch.as_tensor(batch['targets'][i]))\n",
    "                lens += len(batch['targets'][i])\n",
    "            tensor_of_target_tensors = torch.cat(list_of_target_tensors)\n",
    "            \n",
    "            if gpu:\n",
    "                tensor_of_target_tensors = tensor_of_target_tensors.cuda()\n",
    "\n",
    "            # Set parameters for loss\n",
    "            target_lengths = tuple(lengths)\n",
    "            input_lengths = tuple(int(b) for b in batch['seq_lengths'])\n",
    "            targets = tensor_of_target_tensors\n",
    "            log_probs = loop_logits\n",
    "\n",
    "            result = criterion(log_probs, targets, input_lengths, target_lengths)\n",
    "            \n",
    "            # Debugging statements to check CTC loss calculation\n",
    "            #expected = ctcloss_reference(log_probs, targets, input_lengths, target_lengths).float()\n",
    "\n",
    "            #print(\"Result from Torch: %f\" %result)\n",
    "            #print(\"Custom Function: %f\" %expected)\n",
    "\n",
    "            loss = result\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.detach().item()\n",
    "\n",
    "            #print(\"Loss: %f\", %train_loss)\n",
    "            \n",
    "        # Validation\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                model_cnn.eval()\n",
    "                model_rnn.eval()\n",
    "                \n",
    "                \n",
    "                # Get inputs\n",
    "                batch = primus.nextBatch(params)\n",
    "\n",
    "                data = batch['inputs'] # size (batch, height, width, channels)\n",
    "                max_input_length = data.shape[2]\n",
    "                padded_targets, lengths = ctc_utils.pad_sequences(batch['targets'], maxlen=max_input_length)\n",
    "\n",
    "                tensor_data = torch.from_numpy(data)\n",
    "\n",
    "                tensor_data_reshape = torch.permute(tensor_data,(0,3, 1, 2))\n",
    "                \n",
    "                if gpu:\n",
    "                    model_cnn = model_cnn.cuda()\n",
    "                    model_rnn = model_rnn.cuda()\n",
    "                    tensor_data_reshape = tensor_data_reshape.cuda()\n",
    "\n",
    "                # forward, backward, optim\n",
    "                cnn_output = model_cnn(tensor_data_reshape)\n",
    "\n",
    "                output_to_loop = torch.reshape(cnn_output, (16, 1, cnn_output.shape[3], 64*14))\n",
    "\n",
    "                model_rnn.hidden = model_rnn.init_hidden(BATCH_SIZE)\n",
    "                loop_output = model_rnn(output_to_loop)\n",
    "\n",
    "                for t in range(0,len(loop_output)):\n",
    "                    loop_output[t] = torch.reshape(loop_output[t],(loop_output[t].size(1), loop_output[t].size(2)))\n",
    "\n",
    "                loop_tensor = torch.stack(loop_output)\n",
    "\n",
    "                # Reshape to correct shape for Medium article\n",
    "                loop_tensor = torch.permute(loop_tensor, (1,0,2))\n",
    "\n",
    "\n",
    "                # Convert to log softmax\n",
    "                loop_logits = log_softmax(loop_tensor)\n",
    "\n",
    "                #Target to tensor\n",
    "                list_of_target_tensors = []\n",
    "                lens = 0\n",
    "                for i in range(0,16):\n",
    "                    list_of_target_tensors.append(torch.as_tensor(batch['targets'][i]))\n",
    "                    lens += len(batch['targets'][i])\n",
    "                tensor_of_target_tensors = torch.cat(list_of_target_tensors)\n",
    "                \n",
    "                if gpu:\n",
    "                    tensor_of_target_tensors = tensor_of_target_tensors.cuda()\n",
    "\n",
    "                # Set parameters for loss\n",
    "                target_lengths = tuple(lengths)\n",
    "                input_lengths = tuple(int(b) for b in batch['seq_lengths'])\n",
    "                targets = tensor_of_target_tensors\n",
    "                log_probs = loop_logits\n",
    "\n",
    "                result = criterion(log_probs, targets, input_lengths, target_lengths)\n",
    "                #expected = ctcloss_reference(log_probs, targets, input_lengths, target_lengths).float()\n",
    "\n",
    "                #print(\"Result from Torch: %f\" %result)\n",
    "                #print(\"Custom Function: %f\" %expected)\n",
    "\n",
    "                loss = result\n",
    "                \n",
    "                valid_loss += loss\n",
    "                \n",
    "    epoch_loss_train = train_loss/(len_data_train/BATCH_SIZE)\n",
    "    epoch_loss_valid = valid_loss/(len_data_valid/BATCH_SIZE)\n",
    "            \n",
    "    if epoch_loss_valid < valid_loss_min:\n",
    "        # Save model\n",
    "        torch.save(model_cnn.state_dict(), './model_cnn.pt')\n",
    "        torch.save(model_rnn.state_dict(), './model_rnn.pt')\n",
    "            \n",
    "        valid_loss_min = valid_loss\n",
    "                 \n",
    "        best_epoch = epoch\n",
    "        \n",
    "    print('training loss for epoch %d:' %epoch)\n",
    "    print(epoch_loss_train)\n",
    "    \n",
    "    print('validation loss for epoch %d:' %epoch)\n",
    "    print(epoch_loss_valid)\n",
    "    \n",
    "print(\"best epoch %d with loss %f\" %epoch %valid_loss_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0b1901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af948b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 70880 and validating with 7875\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15608189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
